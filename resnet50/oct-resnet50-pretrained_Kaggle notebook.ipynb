{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23942,"sourceType":"datasetVersion","datasetId":17839}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Import**","metadata":{}},{"cell_type":"code","source":"import torch\nprint('pytorch version: {}'.format(torch.__version__))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-03T05:50:30.447955Z","iopub.execute_input":"2024-05-03T05:50:30.448298Z","iopub.status.idle":"2024-05-03T05:50:33.952496Z","shell.execute_reply.started":"2024-05-03T05:50:30.448270Z","shell.execute_reply":"2024-05-03T05:50:33.951501Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"pytorch version: 2.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm.notebook import tqdm\n%matplotlib inline\n\nprint('pytorch version: {}'.format(torch.__version__))\nprint('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:50:52.790685Z","iopub.execute_input":"2024-05-03T05:50:52.791410Z","iopub.status.idle":"2024-05-03T05:50:52.800958Z","shell.execute_reply.started":"2024-05-03T05:50:52.791378Z","shell.execute_reply":"2024-05-03T05:50:52.799943Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"pytorch version: 2.1.2\nGPU 사용 가능 여부: True\n","output_type":"stream"}]},{"cell_type":"code","source":"# 이걸 해줘야 matplotlib 시행 시 에러가 안 남\nimport os    \nos.environ['KMP_DUPLICATE_LIB_OK']='True'","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:50:54.992209Z","iopub.execute_input":"2024-05-03T05:50:54.993001Z","iopub.status.idle":"2024-05-03T05:50:54.997088Z","shell.execute_reply.started":"2024-05-03T05:50:54.992970Z","shell.execute_reply":"2024-05-03T05:50:54.996066Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Setting hyperparameters**","metadata":{}},{"cell_type":"code","source":"batch_size = 64\nnum_epochs = 30\nlearning_rate = 0.001","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:09.287177Z","iopub.execute_input":"2024-05-03T05:51:09.287507Z","iopub.status.idle":"2024-05-03T05:51:09.292135Z","shell.execute_reply.started":"2024-05-03T05:51:09.287481Z","shell.execute_reply":"2024-05-03T05:51:09.290928Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Data loader**","metadata":{}},{"cell_type":"code","source":"#data_dir = '../data/OCT'  # 압축 해제된 데이터셋의 디렉토리 경로\n\n# For Kaggle notebook\ndata_dir = '/kaggle/input/kermany2018/OCT2017 /'","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:10.903284Z","iopub.execute_input":"2024-05-03T05:51:10.903645Z","iopub.status.idle":"2024-05-03T05:51:10.908245Z","shell.execute_reply.started":"2024-05-03T05:51:10.903617Z","shell.execute_reply":"2024-05-03T05:51:10.907181Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class OCTDataset(Dataset):\n    def __init__(self, data_dir, mode, transform=None):\n        self.all_data = sorted(glob.glob(os.path.join(data_dir, mode,'*', '*')))\n        self.transform = transform\n    \n    def __getitem__(self, index):\n        data_path = self.all_data[index]\n        img = Image.open(data_path)\n        if self.transform is not None:\n            img = self.transform(img)\n        img = img.squeeze()\n        img = torch.stack((img, img, img,), dim=0)  # VGG16이 3 channel이라 concat시키기\n        name = os.path.basename(data_path)\n        if name.startswith('NORMAL'):\n            label = 0\n        elif name.startswith('CNV'):\n            label = 1\n        elif name.startswith('DME'):\n            label = 2\n        elif name.startswith('DRUSEN'):\n            label = 3\n        return img, label\n    \n    def __len__(self):\n        length = len(self.all_data)\n        return length","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:14.574558Z","iopub.execute_input":"2024-05-03T05:51:14.575395Z","iopub.status.idle":"2024-05-03T05:51:14.583598Z","shell.execute_reply.started":"2024-05-03T05:51:14.575362Z","shell.execute_reply":"2024-05-03T05:51:14.582596Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomRotation(5),\n        transforms.RandomResizedCrop(224, scale=(0.96, 1.0), ratio=(0.95, 1.05)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize(0.1881,0.1850)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize([256]),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(0.1881,0.1850)\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:15.262350Z","iopub.execute_input":"2024-05-03T05:51:15.263157Z","iopub.status.idle":"2024-05-03T05:51:15.269478Z","shell.execute_reply.started":"2024-05-03T05:51:15.263122Z","shell.execute_reply":"2024-05-03T05:51:15.268532Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data = OCTDataset(data_dir=data_dir, mode='train', transform=data_transforms['train'])\nval_data = OCTDataset(data_dir=data_dir, mode='val', transform=data_transforms['val'])\ntest_data = OCTDataset(data_dir=data_dir, mode='test', transform=data_transforms['val'])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:15.985220Z","iopub.execute_input":"2024-05-03T05:51:15.985581Z","iopub.status.idle":"2024-05-03T05:51:17.578524Z","shell.execute_reply.started":"2024-05-03T05:51:15.985551Z","shell.execute_reply":"2024-05-03T05:51:17.577538Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=2)  # num_worker로 Multi Process Data Loading 구현\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2) # Kaggle CPU = 2 core\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:20.678293Z","iopub.execute_input":"2024-05-03T05:51:20.678946Z","iopub.status.idle":"2024-05-03T05:51:20.684330Z","shell.execute_reply.started":"2024-05-03T05:51:20.678915Z","shell.execute_reply":"2024-05-03T05:51:20.683373Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_mean = 0.1881\ntrain_std = 0.1850","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:21.463086Z","iopub.execute_input":"2024-05-03T05:51:21.463430Z","iopub.status.idle":"2024-05-03T05:51:21.467754Z","shell.execute_reply.started":"2024-05-03T05:51:21.463402Z","shell.execute_reply":"2024-05-03T05:51:21.466823Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**ResNet50 Transfer Learning**","metadata":{}},{"cell_type":"code","source":"class TransferResNet(nn.Module):\n    def __init__ (self):\n        super(TransferResNet, self).__init__()\n        self.ResNet50 = torchvision.models.resnet50(pretrained=True)\n        self.ResNet50.fc = nn.Linear(2048, 4)        # Final layer input = 512, Final layer output = 4 (num of classes) (original: 1000)\n    \n    def forward(self,x):\n        return self.ResNet50(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:23.512077Z","iopub.execute_input":"2024-05-03T05:51:23.512731Z","iopub.status.idle":"2024-05-03T05:51:23.518176Z","shell.execute_reply.started":"2024-05-03T05:51:23.512696Z","shell.execute_reply":"2024-05-03T05:51:23.517250Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"resnet50_transfer = TransferResNet().to(device)\nresnet50_transfer","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-03T05:51:25.809691Z","iopub.execute_input":"2024-05-03T05:51:25.810061Z","iopub.status.idle":"2024-05-03T05:51:27.391297Z","shell.execute_reply.started":"2024-05-03T05:51:25.810029Z","shell.execute_reply":"2024-05-03T05:51:27.390384Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 155MB/s] \n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TransferResNet(\n  (ResNet50): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=4, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"count = 0\nfor name, param in resnet50_transfer.named_parameters():\n    count += 1\n    print(f\"count:{count},\",name, param.requires_grad)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-03T05:51:27.866439Z","iopub.execute_input":"2024-05-03T05:51:27.866818Z","iopub.status.idle":"2024-05-03T05:51:27.875877Z","shell.execute_reply.started":"2024-05-03T05:51:27.866768Z","shell.execute_reply":"2024-05-03T05:51:27.874936Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"count:1, ResNet50.conv1.weight True\ncount:2, ResNet50.bn1.weight True\ncount:3, ResNet50.bn1.bias True\ncount:4, ResNet50.layer1.0.conv1.weight True\ncount:5, ResNet50.layer1.0.bn1.weight True\ncount:6, ResNet50.layer1.0.bn1.bias True\ncount:7, ResNet50.layer1.0.conv2.weight True\ncount:8, ResNet50.layer1.0.bn2.weight True\ncount:9, ResNet50.layer1.0.bn2.bias True\ncount:10, ResNet50.layer1.0.conv3.weight True\ncount:11, ResNet50.layer1.0.bn3.weight True\ncount:12, ResNet50.layer1.0.bn3.bias True\ncount:13, ResNet50.layer1.0.downsample.0.weight True\ncount:14, ResNet50.layer1.0.downsample.1.weight True\ncount:15, ResNet50.layer1.0.downsample.1.bias True\ncount:16, ResNet50.layer1.1.conv1.weight True\ncount:17, ResNet50.layer1.1.bn1.weight True\ncount:18, ResNet50.layer1.1.bn1.bias True\ncount:19, ResNet50.layer1.1.conv2.weight True\ncount:20, ResNet50.layer1.1.bn2.weight True\ncount:21, ResNet50.layer1.1.bn2.bias True\ncount:22, ResNet50.layer1.1.conv3.weight True\ncount:23, ResNet50.layer1.1.bn3.weight True\ncount:24, ResNet50.layer1.1.bn3.bias True\ncount:25, ResNet50.layer1.2.conv1.weight True\ncount:26, ResNet50.layer1.2.bn1.weight True\ncount:27, ResNet50.layer1.2.bn1.bias True\ncount:28, ResNet50.layer1.2.conv2.weight True\ncount:29, ResNet50.layer1.2.bn2.weight True\ncount:30, ResNet50.layer1.2.bn2.bias True\ncount:31, ResNet50.layer1.2.conv3.weight True\ncount:32, ResNet50.layer1.2.bn3.weight True\ncount:33, ResNet50.layer1.2.bn3.bias True\ncount:34, ResNet50.layer2.0.conv1.weight True\ncount:35, ResNet50.layer2.0.bn1.weight True\ncount:36, ResNet50.layer2.0.bn1.bias True\ncount:37, ResNet50.layer2.0.conv2.weight True\ncount:38, ResNet50.layer2.0.bn2.weight True\ncount:39, ResNet50.layer2.0.bn2.bias True\ncount:40, ResNet50.layer2.0.conv3.weight True\ncount:41, ResNet50.layer2.0.bn3.weight True\ncount:42, ResNet50.layer2.0.bn3.bias True\ncount:43, ResNet50.layer2.0.downsample.0.weight True\ncount:44, ResNet50.layer2.0.downsample.1.weight True\ncount:45, ResNet50.layer2.0.downsample.1.bias True\ncount:46, ResNet50.layer2.1.conv1.weight True\ncount:47, ResNet50.layer2.1.bn1.weight True\ncount:48, ResNet50.layer2.1.bn1.bias True\ncount:49, ResNet50.layer2.1.conv2.weight True\ncount:50, ResNet50.layer2.1.bn2.weight True\ncount:51, ResNet50.layer2.1.bn2.bias True\ncount:52, ResNet50.layer2.1.conv3.weight True\ncount:53, ResNet50.layer2.1.bn3.weight True\ncount:54, ResNet50.layer2.1.bn3.bias True\ncount:55, ResNet50.layer2.2.conv1.weight True\ncount:56, ResNet50.layer2.2.bn1.weight True\ncount:57, ResNet50.layer2.2.bn1.bias True\ncount:58, ResNet50.layer2.2.conv2.weight True\ncount:59, ResNet50.layer2.2.bn2.weight True\ncount:60, ResNet50.layer2.2.bn2.bias True\ncount:61, ResNet50.layer2.2.conv3.weight True\ncount:62, ResNet50.layer2.2.bn3.weight True\ncount:63, ResNet50.layer2.2.bn3.bias True\ncount:64, ResNet50.layer2.3.conv1.weight True\ncount:65, ResNet50.layer2.3.bn1.weight True\ncount:66, ResNet50.layer2.3.bn1.bias True\ncount:67, ResNet50.layer2.3.conv2.weight True\ncount:68, ResNet50.layer2.3.bn2.weight True\ncount:69, ResNet50.layer2.3.bn2.bias True\ncount:70, ResNet50.layer2.3.conv3.weight True\ncount:71, ResNet50.layer2.3.bn3.weight True\ncount:72, ResNet50.layer2.3.bn3.bias True\ncount:73, ResNet50.layer3.0.conv1.weight True\ncount:74, ResNet50.layer3.0.bn1.weight True\ncount:75, ResNet50.layer3.0.bn1.bias True\ncount:76, ResNet50.layer3.0.conv2.weight True\ncount:77, ResNet50.layer3.0.bn2.weight True\ncount:78, ResNet50.layer3.0.bn2.bias True\ncount:79, ResNet50.layer3.0.conv3.weight True\ncount:80, ResNet50.layer3.0.bn3.weight True\ncount:81, ResNet50.layer3.0.bn3.bias True\ncount:82, ResNet50.layer3.0.downsample.0.weight True\ncount:83, ResNet50.layer3.0.downsample.1.weight True\ncount:84, ResNet50.layer3.0.downsample.1.bias True\ncount:85, ResNet50.layer3.1.conv1.weight True\ncount:86, ResNet50.layer3.1.bn1.weight True\ncount:87, ResNet50.layer3.1.bn1.bias True\ncount:88, ResNet50.layer3.1.conv2.weight True\ncount:89, ResNet50.layer3.1.bn2.weight True\ncount:90, ResNet50.layer3.1.bn2.bias True\ncount:91, ResNet50.layer3.1.conv3.weight True\ncount:92, ResNet50.layer3.1.bn3.weight True\ncount:93, ResNet50.layer3.1.bn3.bias True\ncount:94, ResNet50.layer3.2.conv1.weight True\ncount:95, ResNet50.layer3.2.bn1.weight True\ncount:96, ResNet50.layer3.2.bn1.bias True\ncount:97, ResNet50.layer3.2.conv2.weight True\ncount:98, ResNet50.layer3.2.bn2.weight True\ncount:99, ResNet50.layer3.2.bn2.bias True\ncount:100, ResNet50.layer3.2.conv3.weight True\ncount:101, ResNet50.layer3.2.bn3.weight True\ncount:102, ResNet50.layer3.2.bn3.bias True\ncount:103, ResNet50.layer3.3.conv1.weight True\ncount:104, ResNet50.layer3.3.bn1.weight True\ncount:105, ResNet50.layer3.3.bn1.bias True\ncount:106, ResNet50.layer3.3.conv2.weight True\ncount:107, ResNet50.layer3.3.bn2.weight True\ncount:108, ResNet50.layer3.3.bn2.bias True\ncount:109, ResNet50.layer3.3.conv3.weight True\ncount:110, ResNet50.layer3.3.bn3.weight True\ncount:111, ResNet50.layer3.3.bn3.bias True\ncount:112, ResNet50.layer3.4.conv1.weight True\ncount:113, ResNet50.layer3.4.bn1.weight True\ncount:114, ResNet50.layer3.4.bn1.bias True\ncount:115, ResNet50.layer3.4.conv2.weight True\ncount:116, ResNet50.layer3.4.bn2.weight True\ncount:117, ResNet50.layer3.4.bn2.bias True\ncount:118, ResNet50.layer3.4.conv3.weight True\ncount:119, ResNet50.layer3.4.bn3.weight True\ncount:120, ResNet50.layer3.4.bn3.bias True\ncount:121, ResNet50.layer3.5.conv1.weight True\ncount:122, ResNet50.layer3.5.bn1.weight True\ncount:123, ResNet50.layer3.5.bn1.bias True\ncount:124, ResNet50.layer3.5.conv2.weight True\ncount:125, ResNet50.layer3.5.bn2.weight True\ncount:126, ResNet50.layer3.5.bn2.bias True\ncount:127, ResNet50.layer3.5.conv3.weight True\ncount:128, ResNet50.layer3.5.bn3.weight True\ncount:129, ResNet50.layer3.5.bn3.bias True\ncount:130, ResNet50.layer4.0.conv1.weight True\ncount:131, ResNet50.layer4.0.bn1.weight True\ncount:132, ResNet50.layer4.0.bn1.bias True\ncount:133, ResNet50.layer4.0.conv2.weight True\ncount:134, ResNet50.layer4.0.bn2.weight True\ncount:135, ResNet50.layer4.0.bn2.bias True\ncount:136, ResNet50.layer4.0.conv3.weight True\ncount:137, ResNet50.layer4.0.bn3.weight True\ncount:138, ResNet50.layer4.0.bn3.bias True\ncount:139, ResNet50.layer4.0.downsample.0.weight True\ncount:140, ResNet50.layer4.0.downsample.1.weight True\ncount:141, ResNet50.layer4.0.downsample.1.bias True\ncount:142, ResNet50.layer4.1.conv1.weight True\ncount:143, ResNet50.layer4.1.bn1.weight True\ncount:144, ResNet50.layer4.1.bn1.bias True\ncount:145, ResNet50.layer4.1.conv2.weight True\ncount:146, ResNet50.layer4.1.bn2.weight True\ncount:147, ResNet50.layer4.1.bn2.bias True\ncount:148, ResNet50.layer4.1.conv3.weight True\ncount:149, ResNet50.layer4.1.bn3.weight True\ncount:150, ResNet50.layer4.1.bn3.bias True\ncount:151, ResNet50.layer4.2.conv1.weight True\ncount:152, ResNet50.layer4.2.bn1.weight True\ncount:153, ResNet50.layer4.2.bn1.bias True\ncount:154, ResNet50.layer4.2.conv2.weight True\ncount:155, ResNet50.layer4.2.bn2.weight True\ncount:156, ResNet50.layer4.2.bn2.bias True\ncount:157, ResNet50.layer4.2.conv3.weight True\ncount:158, ResNet50.layer4.2.bn3.weight True\ncount:159, ResNet50.layer4.2.bn3.bias True\ncount:160, ResNet50.fc.weight True\ncount:161, ResNet50.fc.bias True\n","output_type":"stream"}]},{"cell_type":"code","source":"# Layer 4의 required_grad True로 바꾸기 (Layer 4의 시작: 130) -> 130 이전은 false, 이후는 True\ncount = 0\nfor param in resnet50_transfer.ResNet50.parameters():\n    count += 1\n    if count >= 130:\n        param.requires_grad = True\n    else:\n        param.requires_grad = False\n\nfor name, param in resnet50_transfer.named_parameters():\n    print(name, param.requires_grad)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-03T05:51:30.389460Z","iopub.execute_input":"2024-05-03T05:51:30.390194Z","iopub.status.idle":"2024-05-03T05:51:30.399243Z","shell.execute_reply.started":"2024-05-03T05:51:30.390157Z","shell.execute_reply":"2024-05-03T05:51:30.398314Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"ResNet50.conv1.weight False\nResNet50.bn1.weight False\nResNet50.bn1.bias False\nResNet50.layer1.0.conv1.weight False\nResNet50.layer1.0.bn1.weight False\nResNet50.layer1.0.bn1.bias False\nResNet50.layer1.0.conv2.weight False\nResNet50.layer1.0.bn2.weight False\nResNet50.layer1.0.bn2.bias False\nResNet50.layer1.0.conv3.weight False\nResNet50.layer1.0.bn3.weight False\nResNet50.layer1.0.bn3.bias False\nResNet50.layer1.0.downsample.0.weight False\nResNet50.layer1.0.downsample.1.weight False\nResNet50.layer1.0.downsample.1.bias False\nResNet50.layer1.1.conv1.weight False\nResNet50.layer1.1.bn1.weight False\nResNet50.layer1.1.bn1.bias False\nResNet50.layer1.1.conv2.weight False\nResNet50.layer1.1.bn2.weight False\nResNet50.layer1.1.bn2.bias False\nResNet50.layer1.1.conv3.weight False\nResNet50.layer1.1.bn3.weight False\nResNet50.layer1.1.bn3.bias False\nResNet50.layer1.2.conv1.weight False\nResNet50.layer1.2.bn1.weight False\nResNet50.layer1.2.bn1.bias False\nResNet50.layer1.2.conv2.weight False\nResNet50.layer1.2.bn2.weight False\nResNet50.layer1.2.bn2.bias False\nResNet50.layer1.2.conv3.weight False\nResNet50.layer1.2.bn3.weight False\nResNet50.layer1.2.bn3.bias False\nResNet50.layer2.0.conv1.weight False\nResNet50.layer2.0.bn1.weight False\nResNet50.layer2.0.bn1.bias False\nResNet50.layer2.0.conv2.weight False\nResNet50.layer2.0.bn2.weight False\nResNet50.layer2.0.bn2.bias False\nResNet50.layer2.0.conv3.weight False\nResNet50.layer2.0.bn3.weight False\nResNet50.layer2.0.bn3.bias False\nResNet50.layer2.0.downsample.0.weight False\nResNet50.layer2.0.downsample.1.weight False\nResNet50.layer2.0.downsample.1.bias False\nResNet50.layer2.1.conv1.weight False\nResNet50.layer2.1.bn1.weight False\nResNet50.layer2.1.bn1.bias False\nResNet50.layer2.1.conv2.weight False\nResNet50.layer2.1.bn2.weight False\nResNet50.layer2.1.bn2.bias False\nResNet50.layer2.1.conv3.weight False\nResNet50.layer2.1.bn3.weight False\nResNet50.layer2.1.bn3.bias False\nResNet50.layer2.2.conv1.weight False\nResNet50.layer2.2.bn1.weight False\nResNet50.layer2.2.bn1.bias False\nResNet50.layer2.2.conv2.weight False\nResNet50.layer2.2.bn2.weight False\nResNet50.layer2.2.bn2.bias False\nResNet50.layer2.2.conv3.weight False\nResNet50.layer2.2.bn3.weight False\nResNet50.layer2.2.bn3.bias False\nResNet50.layer2.3.conv1.weight False\nResNet50.layer2.3.bn1.weight False\nResNet50.layer2.3.bn1.bias False\nResNet50.layer2.3.conv2.weight False\nResNet50.layer2.3.bn2.weight False\nResNet50.layer2.3.bn2.bias False\nResNet50.layer2.3.conv3.weight False\nResNet50.layer2.3.bn3.weight False\nResNet50.layer2.3.bn3.bias False\nResNet50.layer3.0.conv1.weight False\nResNet50.layer3.0.bn1.weight False\nResNet50.layer3.0.bn1.bias False\nResNet50.layer3.0.conv2.weight False\nResNet50.layer3.0.bn2.weight False\nResNet50.layer3.0.bn2.bias False\nResNet50.layer3.0.conv3.weight False\nResNet50.layer3.0.bn3.weight False\nResNet50.layer3.0.bn3.bias False\nResNet50.layer3.0.downsample.0.weight False\nResNet50.layer3.0.downsample.1.weight False\nResNet50.layer3.0.downsample.1.bias False\nResNet50.layer3.1.conv1.weight False\nResNet50.layer3.1.bn1.weight False\nResNet50.layer3.1.bn1.bias False\nResNet50.layer3.1.conv2.weight False\nResNet50.layer3.1.bn2.weight False\nResNet50.layer3.1.bn2.bias False\nResNet50.layer3.1.conv3.weight False\nResNet50.layer3.1.bn3.weight False\nResNet50.layer3.1.bn3.bias False\nResNet50.layer3.2.conv1.weight False\nResNet50.layer3.2.bn1.weight False\nResNet50.layer3.2.bn1.bias False\nResNet50.layer3.2.conv2.weight False\nResNet50.layer3.2.bn2.weight False\nResNet50.layer3.2.bn2.bias False\nResNet50.layer3.2.conv3.weight False\nResNet50.layer3.2.bn3.weight False\nResNet50.layer3.2.bn3.bias False\nResNet50.layer3.3.conv1.weight False\nResNet50.layer3.3.bn1.weight False\nResNet50.layer3.3.bn1.bias False\nResNet50.layer3.3.conv2.weight False\nResNet50.layer3.3.bn2.weight False\nResNet50.layer3.3.bn2.bias False\nResNet50.layer3.3.conv3.weight False\nResNet50.layer3.3.bn3.weight False\nResNet50.layer3.3.bn3.bias False\nResNet50.layer3.4.conv1.weight False\nResNet50.layer3.4.bn1.weight False\nResNet50.layer3.4.bn1.bias False\nResNet50.layer3.4.conv2.weight False\nResNet50.layer3.4.bn2.weight False\nResNet50.layer3.4.bn2.bias False\nResNet50.layer3.4.conv3.weight False\nResNet50.layer3.4.bn3.weight False\nResNet50.layer3.4.bn3.bias False\nResNet50.layer3.5.conv1.weight False\nResNet50.layer3.5.bn1.weight False\nResNet50.layer3.5.bn1.bias False\nResNet50.layer3.5.conv2.weight False\nResNet50.layer3.5.bn2.weight False\nResNet50.layer3.5.bn2.bias False\nResNet50.layer3.5.conv3.weight False\nResNet50.layer3.5.bn3.weight False\nResNet50.layer3.5.bn3.bias False\nResNet50.layer4.0.conv1.weight True\nResNet50.layer4.0.bn1.weight True\nResNet50.layer4.0.bn1.bias True\nResNet50.layer4.0.conv2.weight True\nResNet50.layer4.0.bn2.weight True\nResNet50.layer4.0.bn2.bias True\nResNet50.layer4.0.conv3.weight True\nResNet50.layer4.0.bn3.weight True\nResNet50.layer4.0.bn3.bias True\nResNet50.layer4.0.downsample.0.weight True\nResNet50.layer4.0.downsample.1.weight True\nResNet50.layer4.0.downsample.1.bias True\nResNet50.layer4.1.conv1.weight True\nResNet50.layer4.1.bn1.weight True\nResNet50.layer4.1.bn1.bias True\nResNet50.layer4.1.conv2.weight True\nResNet50.layer4.1.bn2.weight True\nResNet50.layer4.1.bn2.bias True\nResNet50.layer4.1.conv3.weight True\nResNet50.layer4.1.bn3.weight True\nResNet50.layer4.1.bn3.bias True\nResNet50.layer4.2.conv1.weight True\nResNet50.layer4.2.bn1.weight True\nResNet50.layer4.2.bn1.bias True\nResNet50.layer4.2.conv2.weight True\nResNet50.layer4.2.bn2.weight True\nResNet50.layer4.2.bn2.bias True\nResNet50.layer4.2.conv3.weight True\nResNet50.layer4.2.bn3.weight True\nResNet50.layer4.2.bn3.bias True\nResNet50.fc.weight True\nResNet50.fc.bias True\n","output_type":"stream"}]},{"cell_type":"code","source":"# Layer 4의 Conv layer를 다시 initialization\nfor name, layer in resnet50_transfer.ResNet50.named_children():\n    if name == 'layer4':\n        bottleneck_index = 0\n        conv_index = 1\n        for name, param in resnet50_transfer.ResNet50.named_parameters():\n            # Layer 4의 Conv layer parameter initialization\n            if name == 'layer4.'+str(bottleneck_index)+'.conv'+str(conv_index)+'.weight':\n                print('layer4의 '+str(bottleneck_index)+'번째 bottleneck의 conv'+str(conv_index)+'.weight')\n                nn.init.xavier_uniform_(param)\n                print(name+'의 conv filter initialization setting 완료')\n                print()\n                conv_index += 1\n                if name == 'layer4.'+str(bottleneck_index)+'.conv3.weight':\n                    bottleneck_index += 1\n                    conv_index = 1","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:32.071640Z","iopub.execute_input":"2024-05-03T05:51:32.072284Z","iopub.status.idle":"2024-05-03T05:51:32.089994Z","shell.execute_reply.started":"2024-05-03T05:51:32.072251Z","shell.execute_reply":"2024-05-03T05:51:32.089034Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"layer4의 0번째 bottleneck의 conv1.weight\nlayer4.0.conv1.weight의 conv filter initialization setting 완료\n\nlayer4의 0번째 bottleneck의 conv2.weight\nlayer4.0.conv2.weight의 conv filter initialization setting 완료\n\nlayer4의 0번째 bottleneck의 conv3.weight\nlayer4.0.conv3.weight의 conv filter initialization setting 완료\n\nlayer4의 1번째 bottleneck의 conv1.weight\nlayer4.1.conv1.weight의 conv filter initialization setting 완료\n\nlayer4의 1번째 bottleneck의 conv2.weight\nlayer4.1.conv2.weight의 conv filter initialization setting 완료\n\nlayer4의 1번째 bottleneck의 conv3.weight\nlayer4.1.conv3.weight의 conv filter initialization setting 완료\n\nlayer4의 2번째 bottleneck의 conv1.weight\nlayer4.2.conv1.weight의 conv filter initialization setting 완료\n\nlayer4의 2번째 bottleneck의 conv2.weight\nlayer4.2.conv2.weight의 conv filter initialization setting 완료\n\nlayer4의 2번째 bottleneck의 conv3.weight\nlayer4.2.conv3.weight의 conv filter initialization setting 완료\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Layer 4의 batch normalization gamma, beta initialization\n# 전부 initialization시키므로 처음 시작을 0, 1로 시작, 만약 좀 더 뒤로 바꾸고 싶으면 초기 시작 값을 바꾸기\nbottleneck_index = 0\nbn_index = 1\nfor name, param in resnet50_transfer.ResNet50.named_parameters():          \n    if name == 'layer4.'+str(bottleneck_index)+'.'+'bn1.weight':\n        print('layer4의 '+str(bottleneck_index)+'번째 bottleneck의 '+'bn1.weight')\n        nn.init.ones_(param)\n        print(name+'의 gamma one setting 완료')\n        print()\n    elif name == 'layer4.'+str(bottleneck_index)+'.'+'bn2.weight':\n        print('layer4의 '+str(bottleneck_index)+'번째 bottleneck의 '+'bn2.weight')\n        nn.init.ones_(param)\n        print(name+'의 gamma one setting 완료')\n        print()\n    elif name == 'layer4.'+str(bottleneck_index)+'.'+'bn3.weight':\n        print('layer4의 '+str(bottleneck_index)+'번째 bottleneck의 '+'bn3.weight')\n        nn.init.zeros_(param)\n        print(name+'의 gamma zero setting 완료')    # residual block 마지막의 batchnorm의 gamma는 0으로, 나머지는 1로 초기화시킨다고 함\n        print()\n    elif name == 'layer4.'+str(bottleneck_index)+'.'+'bn'+str(bn_index)+'.bias':\n        print('layer4.'+str(bottleneck_index)+'.'+'bn'+str(bn_index)+'.bias')     # bias는 0으로 초기화\n        nn.init.zeros_(param)\n        bn_index += 1\n        print(name+'의 beta zero setting 완료')\n        if bn_index == 4:\n            bn_index=1\n            bottleneck_index += 1\n        print()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:34.151437Z","iopub.execute_input":"2024-05-03T05:51:34.152121Z","iopub.status.idle":"2024-05-03T05:51:34.180216Z","shell.execute_reply.started":"2024-05-03T05:51:34.152087Z","shell.execute_reply":"2024-05-03T05:51:34.179188Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"layer4의 0번째 bottleneck의 bn1.weight\nlayer4.0.bn1.weight의 gamma one setting 완료\n\nlayer4.0.bn1.bias\nlayer4.0.bn1.bias의 beta zero setting 완료\n\nlayer4의 0번째 bottleneck의 bn2.weight\nlayer4.0.bn2.weight의 gamma one setting 완료\n\nlayer4.0.bn2.bias\nlayer4.0.bn2.bias의 beta zero setting 완료\n\nlayer4의 0번째 bottleneck의 bn3.weight\nlayer4.0.bn3.weight의 gamma zero setting 완료\n\nlayer4.0.bn3.bias\nlayer4.0.bn3.bias의 beta zero setting 완료\n\nlayer4의 1번째 bottleneck의 bn1.weight\nlayer4.1.bn1.weight의 gamma one setting 완료\n\nlayer4.1.bn1.bias\nlayer4.1.bn1.bias의 beta zero setting 완료\n\nlayer4의 1번째 bottleneck의 bn2.weight\nlayer4.1.bn2.weight의 gamma one setting 완료\n\nlayer4.1.bn2.bias\nlayer4.1.bn2.bias의 beta zero setting 완료\n\nlayer4의 1번째 bottleneck의 bn3.weight\nlayer4.1.bn3.weight의 gamma zero setting 완료\n\nlayer4.1.bn3.bias\nlayer4.1.bn3.bias의 beta zero setting 완료\n\nlayer4의 2번째 bottleneck의 bn1.weight\nlayer4.2.bn1.weight의 gamma one setting 완료\n\nlayer4.2.bn1.bias\nlayer4.2.bn1.bias의 beta zero setting 완료\n\nlayer4의 2번째 bottleneck의 bn2.weight\nlayer4.2.bn2.weight의 gamma one setting 완료\n\nlayer4.2.bn2.bias\nlayer4.2.bn2.bias의 beta zero setting 완료\n\nlayer4의 2번째 bottleneck의 bn3.weight\nlayer4.2.bn3.weight의 gamma zero setting 완료\n\nlayer4.2.bn3.bias\nlayer4.2.bn3.bias의 beta zero setting 완료\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Saving models, Training, Validation, Test**","metadata":{}},{"cell_type":"code","source":"def save_model(model, epoch, optimizer, epoch_loss, val_accuracy, saved_dir):\n    os.makedirs(saved_dir, exist_ok=True)\n    check_point = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': epoch_loss\n    }\n    val_accuracy = round(val_accuracy,1)\n    file_name = str(f\"ckpoint_model_{epoch+1}_{val_accuracy}%.pt\")\n    output_path = os.path.join(saved_dir, file_name)\n    torch.save(check_point,output_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:38.464477Z","iopub.execute_input":"2024-05-03T05:51:38.465291Z","iopub.status.idle":"2024-05-03T05:51:38.470985Z","shell.execute_reply.started":"2024-05-03T05:51:38.465254Z","shell.execute_reply":"2024-05-03T05:51:38.470008Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"logs_base_dir = \"./logs/logs_transfer\"\nos.makedirs(logs_base_dir, exist_ok=True)\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter(logs_base_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:39.740374Z","iopub.execute_input":"2024-05-03T05:51:39.741195Z","iopub.status.idle":"2024-05-03T05:51:50.825910Z","shell.execute_reply.started":"2024-05-03T05:51:39.741159Z","shell.execute_reply":"2024-05-03T05:51:50.824912Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"2024-05-03 05:51:41.721955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-03 05:51:41.722083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-03 05:51:41.861992: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(num_epochs, model, data_loader, criterion, optimizer, scheduler, val_every, device, saved_dir, writer):\n    print('Start training..')\n    torch.cuda.empty_cache()\n    best_loss = 9999999\n    train_loss_list = []\n    val_loss_list = []\n    train_accuracy_list = []\n    val_accuracy_list = []\n    for epoch in tqdm(range(num_epochs), desc='epoch'):\n        count = 0.0\n        # running_loss = 0.0\n        for i, (imgs, labels) in tqdm(enumerate(data_loader), desc=\"in epoch\"):\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Saving train loss\n            train_loss_list.append(loss.item())\n            writer.add_scalar('Loss/Train', loss, i)\n\n            _, argmax = torch.max(outputs, 1)\n            accuracy = (labels == argmax).float().mean()\n            # Saving train accuracy\n            train_accuracy_list.append(accuracy)\n            writer.add_scalar('Accuracy/Train', accuracy, i)\n\n            if (i+1) % 30 == 0:\n                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n                    epoch+1, num_epochs, i+1, len(data_loader), loss.item(), accuracy.item() * 100))\n            #if i % 30 == 29:\n                #loss_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader) ]))\n                #running_loss = 0.0\n        if (epoch + 1) % val_every == 0:\n            avrg_loss, val_accuracy = validation(epoch + 1, model, val_loader, criterion, device)\n            # Saving validation loss and accuracy\n            val_loss_list.append(avrg_loss)\n            writer.add_scalar('Loss/Validation', avrg_loss, epoch+1)\n            val_accuracy_list.append(val_accuracy)\n            writer.add_scalar('Accuracy/Validation', val_accuracy, epoch+1)\n            if avrg_loss < best_loss:\n                print('Best performance at epoch: {}'.format(epoch + 1))\n                print('Save model in', saved_dir)\n                best_loss = avrg_loss\n                save_model(model, epoch, optimizer, avrg_loss, val_accuracy, saved_dir)\n            else:\n                count += 1\n                if count >= 10:\n                    print('Best performance does not occur within 10 epochs. Early stopping!!')\n                    scheduler.step()\n                    writer.flush()\n                    return train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list\n            ''' Only for local setting\n            loss_tracker(loss_plt, torch.Tensor([avrg_loss]), torch.Tensor([epoch]))'''\n    scheduler.step()\n    writer.flush()\n    return train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:50.827618Z","iopub.execute_input":"2024-05-03T05:51:50.828151Z","iopub.status.idle":"2024-05-03T05:51:50.842335Z","shell.execute_reply.started":"2024-05-03T05:51:50.828123Z","shell.execute_reply":"2024-05-03T05:51:50.841453Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def validation(epoch, model, data_loader, criterion, device):\n    print('Start validation #{}'.format(epoch) )\n    model.eval()\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        total_loss = 0\n        cnt = 0\n        for i, (imgs, labels) in enumerate(data_loader):\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            outputs = model(imgs)\n            loss = criterion(outputs,labels)\n            \n            total += imgs.size(0)\n            _, argmax = torch.max(outputs, 1)\n            correct += (labels == argmax).sum().item()\n            total_loss += loss\n            cnt += 1\n        avrg_loss = total_loss / cnt\n        val_accuracy = correct / total * 100\n        print('Validation #{}  Accuracy: {:.2f}%  Average Loss: {:.4f}'.format(epoch, val_accuracy, avrg_loss))\n    model.train()\n    return avrg_loss, val_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:50.843333Z","iopub.execute_input":"2024-05-03T05:51:50.843594Z","iopub.status.idle":"2024-05-03T05:51:51.108943Z","shell.execute_reply.started":"2024-05-03T05:51:50.843571Z","shell.execute_reply":"2024-05-03T05:51:51.108013Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def test(model, data_loader, device):\n    print('Start test..')\n    model.eval()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        answer_list = []\n        pred_list = []\n        pred_proba_list = []\n        \n        for i, (imgs, labels) in tqdm(enumerate(data_loader)):\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n\n            pred_probability = F.softmax(outputs, dim=1)\n            pred_proba_list.append(pred_probability.tolist())\n            \n            _, argmax = torch.max(outputs, 1)\n            pred_list.append(argmax.tolist())\n\n            total += imgs.size(0)\n            correct += (labels == argmax).sum().item()\n            \n            answer_list.append(labels.tolist())\n        \n        print('Test accuracy for {} images: {:.2f}%'.format(total, correct / total * 100))\n    model.train()        \n    return pred_list, answer_list, pred_proba_list","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:51.111137Z","iopub.execute_input":"2024-05-03T05:51:51.111760Z","iopub.status.idle":"2024-05-03T05:51:51.123461Z","shell.execute_reply.started":"2024-05-03T05:51:51.111731Z","shell.execute_reply":"2024-05-03T05:51:51.122597Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(7777)\n\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(resnet50_transfer.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.00001)\n\nval_every = 1\nsaved_dir = './saved'","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:51:51.124711Z","iopub.execute_input":"2024-05-03T05:51:51.125143Z","iopub.status.idle":"2024-05-03T05:51:51.143850Z","shell.execute_reply.started":"2024-05-03T05:51:51.125111Z","shell.execute_reply":"2024-05-03T05:51:51.143104Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list = train(num_epochs, resnet50_transfer, train_loader, criterion, optimizer, scheduler, val_every, device, saved_dir, writer)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:52:30.629852Z","iopub.execute_input":"2024-05-03T05:52:30.630488Z","iopub.status.idle":"2024-05-03T08:19:33.605352Z","shell.execute_reply.started":"2024-05-03T05:52:30.630453Z","shell.execute_reply":"2024-05-03T08:19:33.604318Z"},"scrolled":true,"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Start training..\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch:   0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b8c2c650bb5475cbef8cfa2b4683976"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68a49538756a4300995301692a28ff83"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/30], Step [30/1305], Loss: 0.5368, Accuracy: 78.12%\nEpoch [1/30], Step [60/1305], Loss: 0.2252, Accuracy: 89.06%\nEpoch [1/30], Step [90/1305], Loss: 0.4083, Accuracy: 87.50%\nEpoch [1/30], Step [120/1305], Loss: 0.5219, Accuracy: 79.69%\nEpoch [1/30], Step [150/1305], Loss: 0.3057, Accuracy: 89.06%\nEpoch [1/30], Step [180/1305], Loss: 0.2546, Accuracy: 89.06%\nEpoch [1/30], Step [210/1305], Loss: 0.2323, Accuracy: 93.75%\nEpoch [1/30], Step [240/1305], Loss: 0.2057, Accuracy: 90.62%\nEpoch [1/30], Step [270/1305], Loss: 0.1475, Accuracy: 95.31%\nEpoch [1/30], Step [300/1305], Loss: 0.1462, Accuracy: 96.88%\nEpoch [1/30], Step [330/1305], Loss: 0.2423, Accuracy: 87.50%\nEpoch [1/30], Step [360/1305], Loss: 0.1811, Accuracy: 92.19%\nEpoch [1/30], Step [390/1305], Loss: 0.1088, Accuracy: 95.31%\nEpoch [1/30], Step [420/1305], Loss: 0.0902, Accuracy: 96.88%\nEpoch [1/30], Step [450/1305], Loss: 0.2736, Accuracy: 90.62%\nEpoch [1/30], Step [480/1305], Loss: 0.1463, Accuracy: 93.75%\nEpoch [1/30], Step [510/1305], Loss: 0.2941, Accuracy: 92.19%\nEpoch [1/30], Step [540/1305], Loss: 0.1061, Accuracy: 98.44%\nEpoch [1/30], Step [570/1305], Loss: 0.2483, Accuracy: 90.62%\nEpoch [1/30], Step [600/1305], Loss: 0.2663, Accuracy: 87.50%\nEpoch [1/30], Step [630/1305], Loss: 0.2729, Accuracy: 90.62%\nEpoch [1/30], Step [660/1305], Loss: 0.2071, Accuracy: 89.06%\nEpoch [1/30], Step [690/1305], Loss: 0.3163, Accuracy: 92.19%\nEpoch [1/30], Step [720/1305], Loss: 0.1140, Accuracy: 93.75%\nEpoch [1/30], Step [750/1305], Loss: 0.3116, Accuracy: 92.19%\nEpoch [1/30], Step [780/1305], Loss: 0.2753, Accuracy: 87.50%\nEpoch [1/30], Step [810/1305], Loss: 0.1663, Accuracy: 95.31%\nEpoch [1/30], Step [840/1305], Loss: 0.0632, Accuracy: 98.44%\nEpoch [1/30], Step [870/1305], Loss: 0.2572, Accuracy: 93.75%\nEpoch [1/30], Step [900/1305], Loss: 0.1909, Accuracy: 95.31%\nEpoch [1/30], Step [930/1305], Loss: 0.2895, Accuracy: 89.06%\nEpoch [1/30], Step [960/1305], Loss: 0.1191, Accuracy: 98.44%\nEpoch [1/30], Step [990/1305], Loss: 0.1066, Accuracy: 96.88%\nEpoch [1/30], Step [1020/1305], Loss: 0.3967, Accuracy: 82.81%\nEpoch [1/30], Step [1050/1305], Loss: 0.0433, Accuracy: 100.00%\nEpoch [1/30], Step [1080/1305], Loss: 0.1943, Accuracy: 96.88%\nEpoch [1/30], Step [1110/1305], Loss: 0.0703, Accuracy: 98.44%\nEpoch [1/30], Step [1140/1305], Loss: 0.3289, Accuracy: 89.06%\nEpoch [1/30], Step [1170/1305], Loss: 0.1693, Accuracy: 90.62%\nEpoch [1/30], Step [1200/1305], Loss: 0.1437, Accuracy: 90.62%\nEpoch [1/30], Step [1230/1305], Loss: 0.1064, Accuracy: 96.88%\nEpoch [1/30], Step [1260/1305], Loss: 0.1554, Accuracy: 95.31%\nEpoch [1/30], Step [1290/1305], Loss: 0.2520, Accuracy: 89.06%\nStart validation #1\nValidation #1  Accuracy: 96.88%  Average Loss: 0.0865\nBest performance at epoch: 1\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90133bb0866a46f8bf8a4643a412aac2"}},"metadata":{}},{"name":"stdout","text":"Epoch [2/30], Step [30/1305], Loss: 0.2494, Accuracy: 92.19%\nEpoch [2/30], Step [60/1305], Loss: 0.1588, Accuracy: 90.62%\nEpoch [2/30], Step [90/1305], Loss: 0.1565, Accuracy: 92.19%\nEpoch [2/30], Step [120/1305], Loss: 0.2025, Accuracy: 93.75%\nEpoch [2/30], Step [150/1305], Loss: 0.1736, Accuracy: 95.31%\nEpoch [2/30], Step [180/1305], Loss: 0.0823, Accuracy: 96.88%\nEpoch [2/30], Step [210/1305], Loss: 0.1527, Accuracy: 96.88%\nEpoch [2/30], Step [240/1305], Loss: 0.0828, Accuracy: 95.31%\nEpoch [2/30], Step [270/1305], Loss: 0.1004, Accuracy: 96.88%\nEpoch [2/30], Step [300/1305], Loss: 0.1204, Accuracy: 96.88%\nEpoch [2/30], Step [330/1305], Loss: 0.0529, Accuracy: 100.00%\nEpoch [2/30], Step [360/1305], Loss: 0.1185, Accuracy: 95.31%\nEpoch [2/30], Step [390/1305], Loss: 0.1314, Accuracy: 96.88%\nEpoch [2/30], Step [420/1305], Loss: 0.1396, Accuracy: 93.75%\nEpoch [2/30], Step [450/1305], Loss: 0.1352, Accuracy: 95.31%\nEpoch [2/30], Step [480/1305], Loss: 0.0901, Accuracy: 96.88%\nEpoch [2/30], Step [510/1305], Loss: 0.1948, Accuracy: 90.62%\nEpoch [2/30], Step [540/1305], Loss: 0.0823, Accuracy: 95.31%\nEpoch [2/30], Step [570/1305], Loss: 0.1126, Accuracy: 96.88%\nEpoch [2/30], Step [600/1305], Loss: 0.1419, Accuracy: 93.75%\nEpoch [2/30], Step [630/1305], Loss: 0.3106, Accuracy: 87.50%\nEpoch [2/30], Step [660/1305], Loss: 0.1112, Accuracy: 93.75%\nEpoch [2/30], Step [690/1305], Loss: 0.0930, Accuracy: 96.88%\nEpoch [2/30], Step [720/1305], Loss: 0.1525, Accuracy: 93.75%\nEpoch [2/30], Step [750/1305], Loss: 0.1525, Accuracy: 95.31%\nEpoch [2/30], Step [780/1305], Loss: 0.1247, Accuracy: 95.31%\nEpoch [2/30], Step [810/1305], Loss: 0.0937, Accuracy: 96.88%\nEpoch [2/30], Step [840/1305], Loss: 0.1955, Accuracy: 90.62%\nEpoch [2/30], Step [870/1305], Loss: 0.1220, Accuracy: 96.88%\nEpoch [2/30], Step [900/1305], Loss: 0.1300, Accuracy: 93.75%\nEpoch [2/30], Step [930/1305], Loss: 0.2117, Accuracy: 92.19%\nEpoch [2/30], Step [960/1305], Loss: 0.2344, Accuracy: 89.06%\nEpoch [2/30], Step [990/1305], Loss: 0.3110, Accuracy: 95.31%\nEpoch [2/30], Step [1020/1305], Loss: 0.2429, Accuracy: 90.62%\nEpoch [2/30], Step [1050/1305], Loss: 0.1431, Accuracy: 95.31%\nEpoch [2/30], Step [1080/1305], Loss: 0.1827, Accuracy: 95.31%\nEpoch [2/30], Step [1110/1305], Loss: 0.2305, Accuracy: 93.75%\nEpoch [2/30], Step [1140/1305], Loss: 0.2918, Accuracy: 89.06%\nEpoch [2/30], Step [1170/1305], Loss: 0.1052, Accuracy: 96.88%\nEpoch [2/30], Step [1200/1305], Loss: 0.1293, Accuracy: 95.31%\nEpoch [2/30], Step [1230/1305], Loss: 0.1065, Accuracy: 96.88%\nEpoch [2/30], Step [1260/1305], Loss: 0.1587, Accuracy: 93.75%\nEpoch [2/30], Step [1290/1305], Loss: 0.3696, Accuracy: 89.06%\nStart validation #2\nValidation #2  Accuracy: 96.88%  Average Loss: 0.1084\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23cbd137cdcf48b2a65c40ce5dbc7ef9"}},"metadata":{}},{"name":"stdout","text":"Epoch [3/30], Step [30/1305], Loss: 0.1058, Accuracy: 95.31%\nEpoch [3/30], Step [60/1305], Loss: 0.0612, Accuracy: 96.88%\nEpoch [3/30], Step [90/1305], Loss: 0.1886, Accuracy: 93.75%\nEpoch [3/30], Step [120/1305], Loss: 0.1423, Accuracy: 93.75%\nEpoch [3/30], Step [150/1305], Loss: 0.0684, Accuracy: 98.44%\nEpoch [3/30], Step [180/1305], Loss: 0.0679, Accuracy: 98.44%\nEpoch [3/30], Step [210/1305], Loss: 0.0295, Accuracy: 100.00%\nEpoch [3/30], Step [240/1305], Loss: 0.1316, Accuracy: 93.75%\nEpoch [3/30], Step [270/1305], Loss: 0.1924, Accuracy: 95.31%\nEpoch [3/30], Step [300/1305], Loss: 0.2220, Accuracy: 93.75%\nEpoch [3/30], Step [330/1305], Loss: 0.0509, Accuracy: 98.44%\nEpoch [3/30], Step [360/1305], Loss: 0.2492, Accuracy: 92.19%\nEpoch [3/30], Step [390/1305], Loss: 0.1713, Accuracy: 95.31%\nEpoch [3/30], Step [420/1305], Loss: 0.0287, Accuracy: 100.00%\nEpoch [3/30], Step [450/1305], Loss: 0.2324, Accuracy: 92.19%\nEpoch [3/30], Step [480/1305], Loss: 0.1206, Accuracy: 95.31%\nEpoch [3/30], Step [510/1305], Loss: 0.1886, Accuracy: 93.75%\nEpoch [3/30], Step [540/1305], Loss: 0.1376, Accuracy: 93.75%\nEpoch [3/30], Step [570/1305], Loss: 0.1860, Accuracy: 92.19%\nEpoch [3/30], Step [600/1305], Loss: 0.1173, Accuracy: 95.31%\nEpoch [3/30], Step [630/1305], Loss: 0.1504, Accuracy: 95.31%\nEpoch [3/30], Step [660/1305], Loss: 0.1048, Accuracy: 98.44%\nEpoch [3/30], Step [690/1305], Loss: 0.2097, Accuracy: 93.75%\nEpoch [3/30], Step [720/1305], Loss: 0.1502, Accuracy: 95.31%\nEpoch [3/30], Step [750/1305], Loss: 0.0714, Accuracy: 96.88%\nEpoch [3/30], Step [780/1305], Loss: 0.0974, Accuracy: 93.75%\nEpoch [3/30], Step [810/1305], Loss: 0.1022, Accuracy: 96.88%\nEpoch [3/30], Step [840/1305], Loss: 0.1549, Accuracy: 93.75%\nEpoch [3/30], Step [870/1305], Loss: 0.0975, Accuracy: 96.88%\nEpoch [3/30], Step [900/1305], Loss: 0.1739, Accuracy: 93.75%\nEpoch [3/30], Step [930/1305], Loss: 0.1728, Accuracy: 92.19%\nEpoch [3/30], Step [960/1305], Loss: 0.1564, Accuracy: 92.19%\nEpoch [3/30], Step [990/1305], Loss: 0.1346, Accuracy: 95.31%\nEpoch [3/30], Step [1020/1305], Loss: 0.1922, Accuracy: 95.31%\nEpoch [3/30], Step [1050/1305], Loss: 0.1015, Accuracy: 95.31%\nEpoch [3/30], Step [1080/1305], Loss: 0.1524, Accuracy: 95.31%\nEpoch [3/30], Step [1110/1305], Loss: 0.1585, Accuracy: 96.88%\nEpoch [3/30], Step [1140/1305], Loss: 0.1409, Accuracy: 95.31%\nEpoch [3/30], Step [1170/1305], Loss: 0.1134, Accuracy: 96.88%\nEpoch [3/30], Step [1200/1305], Loss: 0.1478, Accuracy: 95.31%\nEpoch [3/30], Step [1230/1305], Loss: 0.1194, Accuracy: 95.31%\nEpoch [3/30], Step [1260/1305], Loss: 0.0498, Accuracy: 96.88%\nEpoch [3/30], Step [1290/1305], Loss: 0.1227, Accuracy: 90.62%\nStart validation #3\nValidation #3  Accuracy: 100.00%  Average Loss: 0.0793\nBest performance at epoch: 3\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdcb2111618d4e24a72a465385e71ef2"}},"metadata":{}},{"name":"stdout","text":"Epoch [4/30], Step [30/1305], Loss: 0.1888, Accuracy: 93.75%\nEpoch [4/30], Step [60/1305], Loss: 0.0522, Accuracy: 98.44%\nEpoch [4/30], Step [90/1305], Loss: 0.1852, Accuracy: 92.19%\nEpoch [4/30], Step [120/1305], Loss: 0.0852, Accuracy: 96.88%\nEpoch [4/30], Step [150/1305], Loss: 0.2968, Accuracy: 92.19%\nEpoch [4/30], Step [180/1305], Loss: 0.1336, Accuracy: 95.31%\nEpoch [4/30], Step [210/1305], Loss: 0.0348, Accuracy: 98.44%\nEpoch [4/30], Step [240/1305], Loss: 0.1414, Accuracy: 90.62%\nEpoch [4/30], Step [270/1305], Loss: 0.1392, Accuracy: 96.88%\nEpoch [4/30], Step [300/1305], Loss: 0.1452, Accuracy: 95.31%\nEpoch [4/30], Step [330/1305], Loss: 0.1895, Accuracy: 93.75%\nEpoch [4/30], Step [360/1305], Loss: 0.0693, Accuracy: 96.88%\nEpoch [4/30], Step [390/1305], Loss: 0.0928, Accuracy: 96.88%\nEpoch [4/30], Step [420/1305], Loss: 0.1376, Accuracy: 93.75%\nEpoch [4/30], Step [450/1305], Loss: 0.0714, Accuracy: 98.44%\nEpoch [4/30], Step [480/1305], Loss: 0.0651, Accuracy: 98.44%\nEpoch [4/30], Step [510/1305], Loss: 0.0689, Accuracy: 96.88%\nEpoch [4/30], Step [540/1305], Loss: 0.0260, Accuracy: 100.00%\nEpoch [4/30], Step [570/1305], Loss: 0.1133, Accuracy: 95.31%\nEpoch [4/30], Step [600/1305], Loss: 0.0847, Accuracy: 95.31%\nEpoch [4/30], Step [630/1305], Loss: 0.1736, Accuracy: 90.62%\nEpoch [4/30], Step [660/1305], Loss: 0.1639, Accuracy: 95.31%\nEpoch [4/30], Step [690/1305], Loss: 0.1823, Accuracy: 89.06%\nEpoch [4/30], Step [720/1305], Loss: 0.0303, Accuracy: 100.00%\nEpoch [4/30], Step [750/1305], Loss: 0.0717, Accuracy: 98.44%\nEpoch [4/30], Step [780/1305], Loss: 0.0919, Accuracy: 96.88%\nEpoch [4/30], Step [810/1305], Loss: 0.0924, Accuracy: 96.88%\nEpoch [4/30], Step [840/1305], Loss: 0.2174, Accuracy: 93.75%\nEpoch [4/30], Step [870/1305], Loss: 0.1157, Accuracy: 93.75%\nEpoch [4/30], Step [900/1305], Loss: 0.1238, Accuracy: 95.31%\nEpoch [4/30], Step [930/1305], Loss: 0.0473, Accuracy: 98.44%\nEpoch [4/30], Step [960/1305], Loss: 0.1145, Accuracy: 95.31%\nEpoch [4/30], Step [990/1305], Loss: 0.1940, Accuracy: 93.75%\nEpoch [4/30], Step [1020/1305], Loss: 0.0425, Accuracy: 98.44%\nEpoch [4/30], Step [1050/1305], Loss: 0.2214, Accuracy: 93.75%\nEpoch [4/30], Step [1080/1305], Loss: 0.0722, Accuracy: 98.44%\nEpoch [4/30], Step [1110/1305], Loss: 0.0605, Accuracy: 98.44%\nEpoch [4/30], Step [1140/1305], Loss: 0.1391, Accuracy: 96.88%\nEpoch [4/30], Step [1170/1305], Loss: 0.1011, Accuracy: 96.88%\nEpoch [4/30], Step [1200/1305], Loss: 0.0497, Accuracy: 98.44%\nEpoch [4/30], Step [1230/1305], Loss: 0.2024, Accuracy: 95.31%\nEpoch [4/30], Step [1260/1305], Loss: 0.1123, Accuracy: 96.88%\nEpoch [4/30], Step [1290/1305], Loss: 0.1166, Accuracy: 93.75%\nStart validation #4\nValidation #4  Accuracy: 100.00%  Average Loss: 0.0232\nBest performance at epoch: 4\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b53d498e191a41c5aa9483b521f2122e"}},"metadata":{}},{"name":"stdout","text":"Epoch [5/30], Step [30/1305], Loss: 0.1046, Accuracy: 95.31%\nEpoch [5/30], Step [60/1305], Loss: 0.0363, Accuracy: 98.44%\nEpoch [5/30], Step [90/1305], Loss: 0.0693, Accuracy: 96.88%\nEpoch [5/30], Step [120/1305], Loss: 0.0406, Accuracy: 100.00%\nEpoch [5/30], Step [150/1305], Loss: 0.1681, Accuracy: 93.75%\nEpoch [5/30], Step [180/1305], Loss: 0.1475, Accuracy: 92.19%\nEpoch [5/30], Step [210/1305], Loss: 0.1244, Accuracy: 95.31%\nEpoch [5/30], Step [240/1305], Loss: 0.1801, Accuracy: 96.88%\nEpoch [5/30], Step [270/1305], Loss: 0.0792, Accuracy: 95.31%\nEpoch [5/30], Step [300/1305], Loss: 0.0904, Accuracy: 96.88%\nEpoch [5/30], Step [330/1305], Loss: 0.0610, Accuracy: 96.88%\nEpoch [5/30], Step [360/1305], Loss: 0.1433, Accuracy: 96.88%\nEpoch [5/30], Step [390/1305], Loss: 0.1572, Accuracy: 96.88%\nEpoch [5/30], Step [420/1305], Loss: 0.2295, Accuracy: 92.19%\nEpoch [5/30], Step [450/1305], Loss: 0.0620, Accuracy: 95.31%\nEpoch [5/30], Step [480/1305], Loss: 0.1933, Accuracy: 95.31%\nEpoch [5/30], Step [510/1305], Loss: 0.1010, Accuracy: 96.88%\nEpoch [5/30], Step [540/1305], Loss: 0.1477, Accuracy: 93.75%\nEpoch [5/30], Step [570/1305], Loss: 0.0555, Accuracy: 98.44%\nEpoch [5/30], Step [600/1305], Loss: 0.0679, Accuracy: 96.88%\nEpoch [5/30], Step [630/1305], Loss: 0.1563, Accuracy: 96.88%\nEpoch [5/30], Step [660/1305], Loss: 0.0953, Accuracy: 96.88%\nEpoch [5/30], Step [690/1305], Loss: 0.1249, Accuracy: 95.31%\nEpoch [5/30], Step [720/1305], Loss: 0.0353, Accuracy: 100.00%\nEpoch [5/30], Step [750/1305], Loss: 0.0833, Accuracy: 98.44%\nEpoch [5/30], Step [780/1305], Loss: 0.2189, Accuracy: 93.75%\nEpoch [5/30], Step [810/1305], Loss: 0.2730, Accuracy: 87.50%\nEpoch [5/30], Step [840/1305], Loss: 0.1460, Accuracy: 95.31%\nEpoch [5/30], Step [870/1305], Loss: 0.0496, Accuracy: 98.44%\nEpoch [5/30], Step [900/1305], Loss: 0.0596, Accuracy: 98.44%\nEpoch [5/30], Step [930/1305], Loss: 0.0826, Accuracy: 96.88%\nEpoch [5/30], Step [960/1305], Loss: 0.2154, Accuracy: 93.75%\nEpoch [5/30], Step [990/1305], Loss: 0.1373, Accuracy: 95.31%\nEpoch [5/30], Step [1020/1305], Loss: 0.0986, Accuracy: 95.31%\nEpoch [5/30], Step [1050/1305], Loss: 0.2195, Accuracy: 92.19%\nEpoch [5/30], Step [1080/1305], Loss: 0.0532, Accuracy: 98.44%\nEpoch [5/30], Step [1110/1305], Loss: 0.1251, Accuracy: 96.88%\nEpoch [5/30], Step [1140/1305], Loss: 0.0719, Accuracy: 96.88%\nEpoch [5/30], Step [1170/1305], Loss: 0.2374, Accuracy: 92.19%\nEpoch [5/30], Step [1200/1305], Loss: 0.1412, Accuracy: 93.75%\nEpoch [5/30], Step [1230/1305], Loss: 0.0803, Accuracy: 96.88%\nEpoch [5/30], Step [1260/1305], Loss: 0.0524, Accuracy: 98.44%\nEpoch [5/30], Step [1290/1305], Loss: 0.0537, Accuracy: 98.44%\nStart validation #5\nValidation #5  Accuracy: 96.88%  Average Loss: 0.0388\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"308ec2efbc5640be94024daa22aa3ecf"}},"metadata":{}},{"name":"stdout","text":"Epoch [6/30], Step [30/1305], Loss: 0.0348, Accuracy: 98.44%\nEpoch [6/30], Step [60/1305], Loss: 0.0364, Accuracy: 98.44%\nEpoch [6/30], Step [90/1305], Loss: 0.2249, Accuracy: 92.19%\nEpoch [6/30], Step [120/1305], Loss: 0.1258, Accuracy: 92.19%\nEpoch [6/30], Step [150/1305], Loss: 0.1177, Accuracy: 93.75%\nEpoch [6/30], Step [180/1305], Loss: 0.0325, Accuracy: 100.00%\nEpoch [6/30], Step [210/1305], Loss: 0.0963, Accuracy: 96.88%\nEpoch [6/30], Step [240/1305], Loss: 0.0789, Accuracy: 98.44%\nEpoch [6/30], Step [270/1305], Loss: 0.0482, Accuracy: 98.44%\nEpoch [6/30], Step [300/1305], Loss: 0.0446, Accuracy: 98.44%\nEpoch [6/30], Step [330/1305], Loss: 0.0473, Accuracy: 98.44%\nEpoch [6/30], Step [360/1305], Loss: 0.1276, Accuracy: 92.19%\nEpoch [6/30], Step [390/1305], Loss: 0.1104, Accuracy: 96.88%\nEpoch [6/30], Step [420/1305], Loss: 0.0939, Accuracy: 96.88%\nEpoch [6/30], Step [450/1305], Loss: 0.1948, Accuracy: 95.31%\nEpoch [6/30], Step [480/1305], Loss: 0.1139, Accuracy: 98.44%\nEpoch [6/30], Step [510/1305], Loss: 0.0299, Accuracy: 100.00%\nEpoch [6/30], Step [540/1305], Loss: 0.0489, Accuracy: 98.44%\nEpoch [6/30], Step [570/1305], Loss: 0.2507, Accuracy: 90.62%\nEpoch [6/30], Step [600/1305], Loss: 0.1277, Accuracy: 95.31%\nEpoch [6/30], Step [630/1305], Loss: 0.1373, Accuracy: 92.19%\nEpoch [6/30], Step [660/1305], Loss: 0.0878, Accuracy: 95.31%\nEpoch [6/30], Step [690/1305], Loss: 0.0401, Accuracy: 98.44%\nEpoch [6/30], Step [720/1305], Loss: 0.0704, Accuracy: 96.88%\nEpoch [6/30], Step [750/1305], Loss: 0.0810, Accuracy: 96.88%\nEpoch [6/30], Step [780/1305], Loss: 0.0985, Accuracy: 93.75%\nEpoch [6/30], Step [810/1305], Loss: 0.1739, Accuracy: 93.75%\nEpoch [6/30], Step [840/1305], Loss: 0.0417, Accuracy: 96.88%\nEpoch [6/30], Step [870/1305], Loss: 0.0853, Accuracy: 96.88%\nEpoch [6/30], Step [900/1305], Loss: 0.1083, Accuracy: 95.31%\nEpoch [6/30], Step [930/1305], Loss: 0.1087, Accuracy: 95.31%\nEpoch [6/30], Step [960/1305], Loss: 0.0730, Accuracy: 96.88%\nEpoch [6/30], Step [990/1305], Loss: 0.1021, Accuracy: 96.88%\nEpoch [6/30], Step [1020/1305], Loss: 0.0393, Accuracy: 98.44%\nEpoch [6/30], Step [1050/1305], Loss: 0.0633, Accuracy: 96.88%\nEpoch [6/30], Step [1080/1305], Loss: 0.0926, Accuracy: 96.88%\nEpoch [6/30], Step [1110/1305], Loss: 0.1361, Accuracy: 92.19%\nEpoch [6/30], Step [1140/1305], Loss: 0.0884, Accuracy: 96.88%\nEpoch [6/30], Step [1170/1305], Loss: 0.1657, Accuracy: 93.75%\nEpoch [6/30], Step [1200/1305], Loss: 0.0589, Accuracy: 98.44%\nEpoch [6/30], Step [1230/1305], Loss: 0.1100, Accuracy: 95.31%\nEpoch [6/30], Step [1260/1305], Loss: 0.0393, Accuracy: 100.00%\nEpoch [6/30], Step [1290/1305], Loss: 0.0829, Accuracy: 96.88%\nStart validation #6\nValidation #6  Accuracy: 100.00%  Average Loss: 0.0315\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"323bc3e6589c4051b3b1e2acbb510a56"}},"metadata":{}},{"name":"stdout","text":"Epoch [7/30], Step [30/1305], Loss: 0.0922, Accuracy: 98.44%\nEpoch [7/30], Step [60/1305], Loss: 0.1428, Accuracy: 93.75%\nEpoch [7/30], Step [90/1305], Loss: 0.0665, Accuracy: 98.44%\nEpoch [7/30], Step [120/1305], Loss: 0.1493, Accuracy: 95.31%\nEpoch [7/30], Step [150/1305], Loss: 0.0777, Accuracy: 96.88%\nEpoch [7/30], Step [180/1305], Loss: 0.0957, Accuracy: 95.31%\nEpoch [7/30], Step [210/1305], Loss: 0.1588, Accuracy: 95.31%\nEpoch [7/30], Step [240/1305], Loss: 0.0765, Accuracy: 96.88%\nEpoch [7/30], Step [270/1305], Loss: 0.0960, Accuracy: 95.31%\nEpoch [7/30], Step [300/1305], Loss: 0.1348, Accuracy: 95.31%\nEpoch [7/30], Step [330/1305], Loss: 0.0966, Accuracy: 95.31%\nEpoch [7/30], Step [360/1305], Loss: 0.0137, Accuracy: 100.00%\nEpoch [7/30], Step [390/1305], Loss: 0.0970, Accuracy: 93.75%\nEpoch [7/30], Step [420/1305], Loss: 0.0315, Accuracy: 98.44%\nEpoch [7/30], Step [450/1305], Loss: 0.0971, Accuracy: 96.88%\nEpoch [7/30], Step [480/1305], Loss: 0.2318, Accuracy: 95.31%\nEpoch [7/30], Step [510/1305], Loss: 0.1620, Accuracy: 92.19%\nEpoch [7/30], Step [540/1305], Loss: 0.0488, Accuracy: 98.44%\nEpoch [7/30], Step [570/1305], Loss: 0.0957, Accuracy: 95.31%\nEpoch [7/30], Step [600/1305], Loss: 0.1810, Accuracy: 95.31%\nEpoch [7/30], Step [630/1305], Loss: 0.0923, Accuracy: 96.88%\nEpoch [7/30], Step [660/1305], Loss: 0.0997, Accuracy: 95.31%\nEpoch [7/30], Step [690/1305], Loss: 0.0275, Accuracy: 100.00%\nEpoch [7/30], Step [720/1305], Loss: 0.0482, Accuracy: 96.88%\nEpoch [7/30], Step [750/1305], Loss: 0.0206, Accuracy: 100.00%\nEpoch [7/30], Step [780/1305], Loss: 0.1640, Accuracy: 96.88%\nEpoch [7/30], Step [810/1305], Loss: 0.0917, Accuracy: 93.75%\nEpoch [7/30], Step [840/1305], Loss: 0.0492, Accuracy: 96.88%\nEpoch [7/30], Step [870/1305], Loss: 0.0980, Accuracy: 98.44%\nEpoch [7/30], Step [900/1305], Loss: 0.1467, Accuracy: 95.31%\nEpoch [7/30], Step [930/1305], Loss: 0.0302, Accuracy: 98.44%\nEpoch [7/30], Step [960/1305], Loss: 0.0716, Accuracy: 98.44%\nEpoch [7/30], Step [990/1305], Loss: 0.0835, Accuracy: 95.31%\nEpoch [7/30], Step [1020/1305], Loss: 0.1133, Accuracy: 95.31%\nEpoch [7/30], Step [1050/1305], Loss: 0.0316, Accuracy: 100.00%\nEpoch [7/30], Step [1080/1305], Loss: 0.2340, Accuracy: 89.06%\nEpoch [7/30], Step [1110/1305], Loss: 0.0436, Accuracy: 98.44%\nEpoch [7/30], Step [1140/1305], Loss: 0.0564, Accuracy: 98.44%\nEpoch [7/30], Step [1170/1305], Loss: 0.2850, Accuracy: 93.75%\nEpoch [7/30], Step [1200/1305], Loss: 0.0918, Accuracy: 98.44%\nEpoch [7/30], Step [1230/1305], Loss: 0.1311, Accuracy: 95.31%\nEpoch [7/30], Step [1260/1305], Loss: 0.0768, Accuracy: 96.88%\nEpoch [7/30], Step [1290/1305], Loss: 0.0283, Accuracy: 100.00%\nStart validation #7\nValidation #7  Accuracy: 100.00%  Average Loss: 0.0340\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e66d92ce03fa4fa880c2c50b7dfa634b"}},"metadata":{}},{"name":"stdout","text":"Epoch [8/30], Step [30/1305], Loss: 0.0347, Accuracy: 100.00%\nEpoch [8/30], Step [60/1305], Loss: 0.0610, Accuracy: 96.88%\nEpoch [8/30], Step [90/1305], Loss: 0.0246, Accuracy: 98.44%\nEpoch [8/30], Step [120/1305], Loss: 0.0381, Accuracy: 98.44%\nEpoch [8/30], Step [150/1305], Loss: 0.0832, Accuracy: 95.31%\nEpoch [8/30], Step [180/1305], Loss: 0.0563, Accuracy: 98.44%\nEpoch [8/30], Step [210/1305], Loss: 0.0468, Accuracy: 98.44%\nEpoch [8/30], Step [240/1305], Loss: 0.0637, Accuracy: 96.88%\nEpoch [8/30], Step [270/1305], Loss: 0.0796, Accuracy: 98.44%\nEpoch [8/30], Step [300/1305], Loss: 0.2034, Accuracy: 95.31%\nEpoch [8/30], Step [330/1305], Loss: 0.0955, Accuracy: 95.31%\nEpoch [8/30], Step [360/1305], Loss: 0.0199, Accuracy: 100.00%\nEpoch [8/30], Step [390/1305], Loss: 0.0353, Accuracy: 98.44%\nEpoch [8/30], Step [420/1305], Loss: 0.0117, Accuracy: 100.00%\nEpoch [8/30], Step [450/1305], Loss: 0.0925, Accuracy: 96.88%\nEpoch [8/30], Step [480/1305], Loss: 0.0170, Accuracy: 100.00%\nEpoch [8/30], Step [510/1305], Loss: 0.0665, Accuracy: 96.88%\nEpoch [8/30], Step [540/1305], Loss: 0.0829, Accuracy: 96.88%\nEpoch [8/30], Step [570/1305], Loss: 0.0937, Accuracy: 98.44%\nEpoch [8/30], Step [600/1305], Loss: 0.0333, Accuracy: 98.44%\nEpoch [8/30], Step [630/1305], Loss: 0.0526, Accuracy: 98.44%\nEpoch [8/30], Step [660/1305], Loss: 0.0591, Accuracy: 95.31%\nEpoch [8/30], Step [690/1305], Loss: 0.0675, Accuracy: 96.88%\nEpoch [8/30], Step [720/1305], Loss: 0.0603, Accuracy: 96.88%\nEpoch [8/30], Step [750/1305], Loss: 0.0192, Accuracy: 100.00%\nEpoch [8/30], Step [780/1305], Loss: 0.0891, Accuracy: 95.31%\nEpoch [8/30], Step [810/1305], Loss: 0.0656, Accuracy: 96.88%\nEpoch [8/30], Step [840/1305], Loss: 0.0729, Accuracy: 96.88%\nEpoch [8/30], Step [870/1305], Loss: 0.0406, Accuracy: 100.00%\nEpoch [8/30], Step [900/1305], Loss: 0.2024, Accuracy: 95.31%\nEpoch [8/30], Step [930/1305], Loss: 0.0748, Accuracy: 98.44%\nEpoch [8/30], Step [960/1305], Loss: 0.0188, Accuracy: 100.00%\nEpoch [8/30], Step [990/1305], Loss: 0.0539, Accuracy: 98.44%\nEpoch [8/30], Step [1020/1305], Loss: 0.1090, Accuracy: 98.44%\nEpoch [8/30], Step [1050/1305], Loss: 0.1015, Accuracy: 93.75%\nEpoch [8/30], Step [1080/1305], Loss: 0.0792, Accuracy: 96.88%\nEpoch [8/30], Step [1110/1305], Loss: 0.0876, Accuracy: 98.44%\nEpoch [8/30], Step [1140/1305], Loss: 0.0601, Accuracy: 96.88%\nEpoch [8/30], Step [1170/1305], Loss: 0.0157, Accuracy: 100.00%\nEpoch [8/30], Step [1200/1305], Loss: 0.2038, Accuracy: 92.19%\nEpoch [8/30], Step [1230/1305], Loss: 0.1001, Accuracy: 95.31%\nEpoch [8/30], Step [1260/1305], Loss: 0.0826, Accuracy: 98.44%\nEpoch [8/30], Step [1290/1305], Loss: 0.2437, Accuracy: 92.19%\nStart validation #8\nValidation #8  Accuracy: 93.75%  Average Loss: 0.1004\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4648ea7794334bd5bef47c153c8a45ad"}},"metadata":{}},{"name":"stdout","text":"Epoch [9/30], Step [30/1305], Loss: 0.0881, Accuracy: 96.88%\nEpoch [9/30], Step [60/1305], Loss: 0.1440, Accuracy: 93.75%\nEpoch [9/30], Step [90/1305], Loss: 0.0295, Accuracy: 98.44%\nEpoch [9/30], Step [120/1305], Loss: 0.2331, Accuracy: 95.31%\nEpoch [9/30], Step [150/1305], Loss: 0.0742, Accuracy: 96.88%\nEpoch [9/30], Step [180/1305], Loss: 0.0970, Accuracy: 95.31%\nEpoch [9/30], Step [210/1305], Loss: 0.0291, Accuracy: 98.44%\nEpoch [9/30], Step [240/1305], Loss: 0.0577, Accuracy: 98.44%\nEpoch [9/30], Step [270/1305], Loss: 0.0597, Accuracy: 96.88%\nEpoch [9/30], Step [300/1305], Loss: 0.1048, Accuracy: 95.31%\nEpoch [9/30], Step [330/1305], Loss: 0.1492, Accuracy: 95.31%\nEpoch [9/30], Step [360/1305], Loss: 0.0957, Accuracy: 96.88%\nEpoch [9/30], Step [390/1305], Loss: 0.1006, Accuracy: 96.88%\nEpoch [9/30], Step [420/1305], Loss: 0.0646, Accuracy: 98.44%\nEpoch [9/30], Step [450/1305], Loss: 0.1788, Accuracy: 92.19%\nEpoch [9/30], Step [480/1305], Loss: 0.0524, Accuracy: 96.88%\nEpoch [9/30], Step [510/1305], Loss: 0.1358, Accuracy: 93.75%\nEpoch [9/30], Step [540/1305], Loss: 0.0253, Accuracy: 100.00%\nEpoch [9/30], Step [570/1305], Loss: 0.0804, Accuracy: 98.44%\nEpoch [9/30], Step [600/1305], Loss: 0.0188, Accuracy: 100.00%\nEpoch [9/30], Step [630/1305], Loss: 0.0212, Accuracy: 100.00%\nEpoch [9/30], Step [660/1305], Loss: 0.0716, Accuracy: 96.88%\nEpoch [9/30], Step [690/1305], Loss: 0.1131, Accuracy: 95.31%\nEpoch [9/30], Step [720/1305], Loss: 0.2493, Accuracy: 95.31%\nEpoch [9/30], Step [750/1305], Loss: 0.0868, Accuracy: 96.88%\nEpoch [9/30], Step [780/1305], Loss: 0.0780, Accuracy: 98.44%\nEpoch [9/30], Step [810/1305], Loss: 0.1456, Accuracy: 96.88%\nEpoch [9/30], Step [840/1305], Loss: 0.0850, Accuracy: 95.31%\nEpoch [9/30], Step [870/1305], Loss: 0.0661, Accuracy: 96.88%\nEpoch [9/30], Step [900/1305], Loss: 0.0393, Accuracy: 98.44%\nEpoch [9/30], Step [930/1305], Loss: 0.0373, Accuracy: 98.44%\nEpoch [9/30], Step [960/1305], Loss: 0.0654, Accuracy: 96.88%\nEpoch [9/30], Step [990/1305], Loss: 0.0333, Accuracy: 98.44%\nEpoch [9/30], Step [1020/1305], Loss: 0.0121, Accuracy: 100.00%\nEpoch [9/30], Step [1050/1305], Loss: 0.1157, Accuracy: 95.31%\nEpoch [9/30], Step [1080/1305], Loss: 0.0277, Accuracy: 100.00%\nEpoch [9/30], Step [1110/1305], Loss: 0.0286, Accuracy: 100.00%\nEpoch [9/30], Step [1140/1305], Loss: 0.0724, Accuracy: 96.88%\nEpoch [9/30], Step [1170/1305], Loss: 0.0311, Accuracy: 98.44%\nEpoch [9/30], Step [1200/1305], Loss: 0.1074, Accuracy: 95.31%\nEpoch [9/30], Step [1230/1305], Loss: 0.0580, Accuracy: 96.88%\nEpoch [9/30], Step [1260/1305], Loss: 0.0255, Accuracy: 100.00%\nEpoch [9/30], Step [1290/1305], Loss: 0.0437, Accuracy: 98.44%\nStart validation #9\nValidation #9  Accuracy: 96.88%  Average Loss: 0.0597\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2eca0112ce4438e98bdcc9ab9e23583"}},"metadata":{}},{"name":"stdout","text":"Epoch [10/30], Step [30/1305], Loss: 0.2670, Accuracy: 92.19%\nEpoch [10/30], Step [60/1305], Loss: 0.0950, Accuracy: 96.88%\nEpoch [10/30], Step [90/1305], Loss: 0.0167, Accuracy: 100.00%\nEpoch [10/30], Step [120/1305], Loss: 0.1253, Accuracy: 96.88%\nEpoch [10/30], Step [150/1305], Loss: 0.1029, Accuracy: 95.31%\nEpoch [10/30], Step [180/1305], Loss: 0.1692, Accuracy: 95.31%\nEpoch [10/30], Step [210/1305], Loss: 0.0633, Accuracy: 96.88%\nEpoch [10/30], Step [240/1305], Loss: 0.0083, Accuracy: 100.00%\nEpoch [10/30], Step [270/1305], Loss: 0.1694, Accuracy: 93.75%\nEpoch [10/30], Step [300/1305], Loss: 0.1060, Accuracy: 96.88%\nEpoch [10/30], Step [330/1305], Loss: 0.0636, Accuracy: 98.44%\nEpoch [10/30], Step [360/1305], Loss: 0.0912, Accuracy: 96.88%\nEpoch [10/30], Step [390/1305], Loss: 0.0518, Accuracy: 98.44%\nEpoch [10/30], Step [420/1305], Loss: 0.0562, Accuracy: 98.44%\nEpoch [10/30], Step [450/1305], Loss: 0.0089, Accuracy: 100.00%\nEpoch [10/30], Step [480/1305], Loss: 0.0518, Accuracy: 98.44%\nEpoch [10/30], Step [510/1305], Loss: 0.0378, Accuracy: 98.44%\nEpoch [10/30], Step [540/1305], Loss: 0.0561, Accuracy: 98.44%\nEpoch [10/30], Step [570/1305], Loss: 0.0168, Accuracy: 100.00%\nEpoch [10/30], Step [600/1305], Loss: 0.0321, Accuracy: 96.88%\nEpoch [10/30], Step [630/1305], Loss: 0.0661, Accuracy: 96.88%\nEpoch [10/30], Step [660/1305], Loss: 0.0629, Accuracy: 96.88%\nEpoch [10/30], Step [690/1305], Loss: 0.0580, Accuracy: 98.44%\nEpoch [10/30], Step [720/1305], Loss: 0.0283, Accuracy: 100.00%\nEpoch [10/30], Step [750/1305], Loss: 0.0434, Accuracy: 98.44%\nEpoch [10/30], Step [780/1305], Loss: 0.0180, Accuracy: 100.00%\nEpoch [10/30], Step [810/1305], Loss: 0.1139, Accuracy: 95.31%\nEpoch [10/30], Step [840/1305], Loss: 0.0437, Accuracy: 100.00%\nEpoch [10/30], Step [870/1305], Loss: 0.0270, Accuracy: 100.00%\nEpoch [10/30], Step [900/1305], Loss: 0.1549, Accuracy: 95.31%\nEpoch [10/30], Step [930/1305], Loss: 0.0711, Accuracy: 96.88%\nEpoch [10/30], Step [960/1305], Loss: 0.0456, Accuracy: 98.44%\nEpoch [10/30], Step [990/1305], Loss: 0.0246, Accuracy: 100.00%\nEpoch [10/30], Step [1020/1305], Loss: 0.0720, Accuracy: 96.88%\nEpoch [10/30], Step [1050/1305], Loss: 0.0439, Accuracy: 98.44%\nEpoch [10/30], Step [1080/1305], Loss: 0.0624, Accuracy: 98.44%\nEpoch [10/30], Step [1110/1305], Loss: 0.1065, Accuracy: 93.75%\nEpoch [10/30], Step [1140/1305], Loss: 0.0428, Accuracy: 100.00%\nEpoch [10/30], Step [1170/1305], Loss: 0.1132, Accuracy: 96.88%\nEpoch [10/30], Step [1200/1305], Loss: 0.1312, Accuracy: 96.88%\nEpoch [10/30], Step [1230/1305], Loss: 0.0498, Accuracy: 98.44%\nEpoch [10/30], Step [1260/1305], Loss: 0.0623, Accuracy: 100.00%\nEpoch [10/30], Step [1290/1305], Loss: 0.0605, Accuracy: 98.44%\nStart validation #10\nValidation #10  Accuracy: 100.00%  Average Loss: 0.0231\nBest performance at epoch: 10\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13ec618c36cf41eea0e435da3b53047d"}},"metadata":{}},{"name":"stdout","text":"Epoch [11/30], Step [30/1305], Loss: 0.0535, Accuracy: 98.44%\nEpoch [11/30], Step [60/1305], Loss: 0.0483, Accuracy: 98.44%\nEpoch [11/30], Step [90/1305], Loss: 0.0125, Accuracy: 100.00%\nEpoch [11/30], Step [120/1305], Loss: 0.0520, Accuracy: 98.44%\nEpoch [11/30], Step [150/1305], Loss: 0.0907, Accuracy: 96.88%\nEpoch [11/30], Step [180/1305], Loss: 0.0209, Accuracy: 98.44%\nEpoch [11/30], Step [210/1305], Loss: 0.0466, Accuracy: 98.44%\nEpoch [11/30], Step [240/1305], Loss: 0.0353, Accuracy: 98.44%\nEpoch [11/30], Step [270/1305], Loss: 0.1007, Accuracy: 96.88%\nEpoch [11/30], Step [300/1305], Loss: 0.1566, Accuracy: 92.19%\nEpoch [11/30], Step [330/1305], Loss: 0.0834, Accuracy: 96.88%\nEpoch [11/30], Step [360/1305], Loss: 0.0788, Accuracy: 95.31%\nEpoch [11/30], Step [390/1305], Loss: 0.0696, Accuracy: 96.88%\nEpoch [11/30], Step [420/1305], Loss: 0.0875, Accuracy: 96.88%\nEpoch [11/30], Step [450/1305], Loss: 0.1186, Accuracy: 95.31%\nEpoch [11/30], Step [480/1305], Loss: 0.1126, Accuracy: 95.31%\nEpoch [11/30], Step [510/1305], Loss: 0.0985, Accuracy: 93.75%\nEpoch [11/30], Step [540/1305], Loss: 0.0380, Accuracy: 96.88%\nEpoch [11/30], Step [570/1305], Loss: 0.0174, Accuracy: 100.00%\nEpoch [11/30], Step [600/1305], Loss: 0.0333, Accuracy: 100.00%\nEpoch [11/30], Step [630/1305], Loss: 0.0497, Accuracy: 96.88%\nEpoch [11/30], Step [660/1305], Loss: 0.1198, Accuracy: 92.19%\nEpoch [11/30], Step [690/1305], Loss: 0.1081, Accuracy: 95.31%\nEpoch [11/30], Step [720/1305], Loss: 0.2090, Accuracy: 90.62%\nEpoch [11/30], Step [750/1305], Loss: 0.0547, Accuracy: 96.88%\nEpoch [11/30], Step [780/1305], Loss: 0.0552, Accuracy: 96.88%\nEpoch [11/30], Step [810/1305], Loss: 0.0838, Accuracy: 95.31%\nEpoch [11/30], Step [840/1305], Loss: 0.1061, Accuracy: 95.31%\nEpoch [11/30], Step [870/1305], Loss: 0.0131, Accuracy: 100.00%\nEpoch [11/30], Step [900/1305], Loss: 0.1614, Accuracy: 92.19%\nEpoch [11/30], Step [930/1305], Loss: 0.0440, Accuracy: 98.44%\nEpoch [11/30], Step [960/1305], Loss: 0.0183, Accuracy: 100.00%\nEpoch [11/30], Step [990/1305], Loss: 0.0612, Accuracy: 98.44%\nEpoch [11/30], Step [1020/1305], Loss: 0.1265, Accuracy: 90.62%\nEpoch [11/30], Step [1050/1305], Loss: 0.0238, Accuracy: 100.00%\nEpoch [11/30], Step [1080/1305], Loss: 0.1540, Accuracy: 95.31%\nEpoch [11/30], Step [1110/1305], Loss: 0.1237, Accuracy: 96.88%\nEpoch [11/30], Step [1140/1305], Loss: 0.0501, Accuracy: 98.44%\nEpoch [11/30], Step [1170/1305], Loss: 0.0591, Accuracy: 98.44%\nEpoch [11/30], Step [1200/1305], Loss: 0.0498, Accuracy: 98.44%\nEpoch [11/30], Step [1230/1305], Loss: 0.0987, Accuracy: 95.31%\nEpoch [11/30], Step [1260/1305], Loss: 0.1212, Accuracy: 96.88%\nEpoch [11/30], Step [1290/1305], Loss: 0.0437, Accuracy: 98.44%\nStart validation #11\nValidation #11  Accuracy: 96.88%  Average Loss: 0.0757\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfa1cc56ed5c4d8a846264fcda4fdc8e"}},"metadata":{}},{"name":"stdout","text":"Epoch [12/30], Step [30/1305], Loss: 0.0399, Accuracy: 98.44%\nEpoch [12/30], Step [60/1305], Loss: 0.1573, Accuracy: 95.31%\nEpoch [12/30], Step [90/1305], Loss: 0.1245, Accuracy: 95.31%\nEpoch [12/30], Step [120/1305], Loss: 0.1062, Accuracy: 95.31%\nEpoch [12/30], Step [150/1305], Loss: 0.0583, Accuracy: 98.44%\nEpoch [12/30], Step [180/1305], Loss: 0.0211, Accuracy: 100.00%\nEpoch [12/30], Step [210/1305], Loss: 0.0123, Accuracy: 100.00%\nEpoch [12/30], Step [240/1305], Loss: 0.0499, Accuracy: 98.44%\nEpoch [12/30], Step [270/1305], Loss: 0.0141, Accuracy: 100.00%\nEpoch [12/30], Step [300/1305], Loss: 0.0283, Accuracy: 98.44%\nEpoch [12/30], Step [330/1305], Loss: 0.0805, Accuracy: 96.88%\nEpoch [12/30], Step [360/1305], Loss: 0.0264, Accuracy: 100.00%\nEpoch [12/30], Step [390/1305], Loss: 0.0762, Accuracy: 96.88%\nEpoch [12/30], Step [420/1305], Loss: 0.1662, Accuracy: 93.75%\nEpoch [12/30], Step [450/1305], Loss: 0.0825, Accuracy: 96.88%\nEpoch [12/30], Step [480/1305], Loss: 0.0095, Accuracy: 100.00%\nEpoch [12/30], Step [510/1305], Loss: 0.0570, Accuracy: 96.88%\nEpoch [12/30], Step [540/1305], Loss: 0.0462, Accuracy: 96.88%\nEpoch [12/30], Step [570/1305], Loss: 0.0372, Accuracy: 98.44%\nEpoch [12/30], Step [600/1305], Loss: 0.0710, Accuracy: 96.88%\nEpoch [12/30], Step [630/1305], Loss: 0.1251, Accuracy: 92.19%\nEpoch [12/30], Step [660/1305], Loss: 0.0674, Accuracy: 95.31%\nEpoch [12/30], Step [690/1305], Loss: 0.0944, Accuracy: 95.31%\nEpoch [12/30], Step [720/1305], Loss: 0.1074, Accuracy: 96.88%\nEpoch [12/30], Step [750/1305], Loss: 0.0582, Accuracy: 98.44%\nEpoch [12/30], Step [780/1305], Loss: 0.1308, Accuracy: 95.31%\nEpoch [12/30], Step [810/1305], Loss: 0.0425, Accuracy: 96.88%\nEpoch [12/30], Step [840/1305], Loss: 0.0612, Accuracy: 96.88%\nEpoch [12/30], Step [870/1305], Loss: 0.0306, Accuracy: 98.44%\nEpoch [12/30], Step [900/1305], Loss: 0.0452, Accuracy: 96.88%\nEpoch [12/30], Step [930/1305], Loss: 0.0982, Accuracy: 96.88%\nEpoch [12/30], Step [960/1305], Loss: 0.0393, Accuracy: 98.44%\nEpoch [12/30], Step [990/1305], Loss: 0.0915, Accuracy: 96.88%\nEpoch [12/30], Step [1020/1305], Loss: 0.0454, Accuracy: 98.44%\nEpoch [12/30], Step [1050/1305], Loss: 0.0253, Accuracy: 100.00%\nEpoch [12/30], Step [1080/1305], Loss: 0.1047, Accuracy: 95.31%\nEpoch [12/30], Step [1110/1305], Loss: 0.1186, Accuracy: 98.44%\nEpoch [12/30], Step [1140/1305], Loss: 0.1009, Accuracy: 92.19%\nEpoch [12/30], Step [1170/1305], Loss: 0.0315, Accuracy: 100.00%\nEpoch [12/30], Step [1200/1305], Loss: 0.0193, Accuracy: 100.00%\nEpoch [12/30], Step [1230/1305], Loss: 0.0462, Accuracy: 98.44%\nEpoch [12/30], Step [1260/1305], Loss: 0.0768, Accuracy: 96.88%\nEpoch [12/30], Step [1290/1305], Loss: 0.0372, Accuracy: 98.44%\nStart validation #12\nValidation #12  Accuracy: 100.00%  Average Loss: 0.0163\nBest performance at epoch: 12\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88e01601711419b970fb06bd2d15436"}},"metadata":{}},{"name":"stdout","text":"Epoch [13/30], Step [30/1305], Loss: 0.0766, Accuracy: 93.75%\nEpoch [13/30], Step [60/1305], Loss: 0.0482, Accuracy: 98.44%\nEpoch [13/30], Step [90/1305], Loss: 0.1728, Accuracy: 92.19%\nEpoch [13/30], Step [120/1305], Loss: 0.0501, Accuracy: 96.88%\nEpoch [13/30], Step [150/1305], Loss: 0.0509, Accuracy: 96.88%\nEpoch [13/30], Step [180/1305], Loss: 0.2982, Accuracy: 93.75%\nEpoch [13/30], Step [210/1305], Loss: 0.0403, Accuracy: 96.88%\nEpoch [13/30], Step [240/1305], Loss: 0.1413, Accuracy: 95.31%\nEpoch [13/30], Step [270/1305], Loss: 0.0648, Accuracy: 98.44%\nEpoch [13/30], Step [300/1305], Loss: 0.0855, Accuracy: 96.88%\nEpoch [13/30], Step [330/1305], Loss: 0.0784, Accuracy: 93.75%\nEpoch [13/30], Step [360/1305], Loss: 0.1330, Accuracy: 93.75%\nEpoch [13/30], Step [390/1305], Loss: 0.0593, Accuracy: 96.88%\nEpoch [13/30], Step [420/1305], Loss: 0.1125, Accuracy: 96.88%\nEpoch [13/30], Step [450/1305], Loss: 0.0388, Accuracy: 98.44%\nEpoch [13/30], Step [480/1305], Loss: 0.1105, Accuracy: 96.88%\nEpoch [13/30], Step [510/1305], Loss: 0.0301, Accuracy: 100.00%\nEpoch [13/30], Step [540/1305], Loss: 0.0138, Accuracy: 100.00%\nEpoch [13/30], Step [570/1305], Loss: 0.0500, Accuracy: 98.44%\nEpoch [13/30], Step [600/1305], Loss: 0.0139, Accuracy: 100.00%\nEpoch [13/30], Step [630/1305], Loss: 0.0156, Accuracy: 100.00%\nEpoch [13/30], Step [660/1305], Loss: 0.0403, Accuracy: 98.44%\nEpoch [13/30], Step [690/1305], Loss: 0.0369, Accuracy: 100.00%\nEpoch [13/30], Step [720/1305], Loss: 0.0942, Accuracy: 96.88%\nEpoch [13/30], Step [750/1305], Loss: 0.1126, Accuracy: 96.88%\nEpoch [13/30], Step [780/1305], Loss: 0.0351, Accuracy: 98.44%\nEpoch [13/30], Step [810/1305], Loss: 0.1033, Accuracy: 96.88%\nEpoch [13/30], Step [840/1305], Loss: 0.0652, Accuracy: 96.88%\nEpoch [13/30], Step [870/1305], Loss: 0.1446, Accuracy: 95.31%\nEpoch [13/30], Step [900/1305], Loss: 0.0639, Accuracy: 96.88%\nEpoch [13/30], Step [930/1305], Loss: 0.0570, Accuracy: 98.44%\nEpoch [13/30], Step [960/1305], Loss: 0.1153, Accuracy: 96.88%\nEpoch [13/30], Step [990/1305], Loss: 0.0310, Accuracy: 100.00%\nEpoch [13/30], Step [1020/1305], Loss: 0.1223, Accuracy: 96.88%\nEpoch [13/30], Step [1050/1305], Loss: 0.0751, Accuracy: 96.88%\nEpoch [13/30], Step [1080/1305], Loss: 0.0635, Accuracy: 96.88%\nEpoch [13/30], Step [1110/1305], Loss: 0.0249, Accuracy: 100.00%\nEpoch [13/30], Step [1140/1305], Loss: 0.0474, Accuracy: 96.88%\nEpoch [13/30], Step [1170/1305], Loss: 0.0600, Accuracy: 98.44%\nEpoch [13/30], Step [1200/1305], Loss: 0.0397, Accuracy: 98.44%\nEpoch [13/30], Step [1230/1305], Loss: 0.0304, Accuracy: 98.44%\nEpoch [13/30], Step [1260/1305], Loss: 0.0344, Accuracy: 98.44%\nEpoch [13/30], Step [1290/1305], Loss: 0.0266, Accuracy: 100.00%\nStart validation #13\nValidation #13  Accuracy: 100.00%  Average Loss: 0.0195\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce7d1b141b88453e80760e8e6e3318ba"}},"metadata":{}},{"name":"stdout","text":"Epoch [14/30], Step [30/1305], Loss: 0.0770, Accuracy: 96.88%\nEpoch [14/30], Step [60/1305], Loss: 0.1020, Accuracy: 98.44%\nEpoch [14/30], Step [90/1305], Loss: 0.0741, Accuracy: 98.44%\nEpoch [14/30], Step [120/1305], Loss: 0.0620, Accuracy: 96.88%\nEpoch [14/30], Step [150/1305], Loss: 0.0248, Accuracy: 98.44%\nEpoch [14/30], Step [180/1305], Loss: 0.0830, Accuracy: 96.88%\nEpoch [14/30], Step [210/1305], Loss: 0.1154, Accuracy: 95.31%\nEpoch [14/30], Step [240/1305], Loss: 0.0778, Accuracy: 95.31%\nEpoch [14/30], Step [270/1305], Loss: 0.0567, Accuracy: 96.88%\nEpoch [14/30], Step [300/1305], Loss: 0.0476, Accuracy: 98.44%\nEpoch [14/30], Step [330/1305], Loss: 0.0642, Accuracy: 98.44%\nEpoch [14/30], Step [360/1305], Loss: 0.0061, Accuracy: 100.00%\nEpoch [14/30], Step [390/1305], Loss: 0.0220, Accuracy: 100.00%\nEpoch [14/30], Step [420/1305], Loss: 0.1080, Accuracy: 95.31%\nEpoch [14/30], Step [450/1305], Loss: 0.0059, Accuracy: 100.00%\nEpoch [14/30], Step [480/1305], Loss: 0.0583, Accuracy: 96.88%\nEpoch [14/30], Step [510/1305], Loss: 0.0190, Accuracy: 100.00%\nEpoch [14/30], Step [540/1305], Loss: 0.1223, Accuracy: 96.88%\nEpoch [14/30], Step [570/1305], Loss: 0.0391, Accuracy: 98.44%\nEpoch [14/30], Step [600/1305], Loss: 0.0381, Accuracy: 98.44%\nEpoch [14/30], Step [630/1305], Loss: 0.0869, Accuracy: 96.88%\nEpoch [14/30], Step [660/1305], Loss: 0.0408, Accuracy: 98.44%\nEpoch [14/30], Step [690/1305], Loss: 0.0378, Accuracy: 98.44%\nEpoch [14/30], Step [720/1305], Loss: 0.0178, Accuracy: 98.44%\nEpoch [14/30], Step [750/1305], Loss: 0.0230, Accuracy: 100.00%\nEpoch [14/30], Step [780/1305], Loss: 0.0871, Accuracy: 95.31%\nEpoch [14/30], Step [810/1305], Loss: 0.0850, Accuracy: 96.88%\nEpoch [14/30], Step [840/1305], Loss: 0.1110, Accuracy: 95.31%\nEpoch [14/30], Step [870/1305], Loss: 0.1698, Accuracy: 96.88%\nEpoch [14/30], Step [900/1305], Loss: 0.1891, Accuracy: 93.75%\nEpoch [14/30], Step [930/1305], Loss: 0.0526, Accuracy: 96.88%\nEpoch [14/30], Step [960/1305], Loss: 0.0531, Accuracy: 95.31%\nEpoch [14/30], Step [990/1305], Loss: 0.0703, Accuracy: 96.88%\nEpoch [14/30], Step [1020/1305], Loss: 0.1381, Accuracy: 95.31%\nEpoch [14/30], Step [1050/1305], Loss: 0.0877, Accuracy: 98.44%\nEpoch [14/30], Step [1080/1305], Loss: 0.2267, Accuracy: 93.75%\nEpoch [14/30], Step [1110/1305], Loss: 0.0676, Accuracy: 98.44%\nEpoch [14/30], Step [1140/1305], Loss: 0.0639, Accuracy: 98.44%\nEpoch [14/30], Step [1170/1305], Loss: 0.1285, Accuracy: 95.31%\nEpoch [14/30], Step [1200/1305], Loss: 0.0455, Accuracy: 100.00%\nEpoch [14/30], Step [1230/1305], Loss: 0.0146, Accuracy: 100.00%\nEpoch [14/30], Step [1260/1305], Loss: 0.1125, Accuracy: 96.88%\nEpoch [14/30], Step [1290/1305], Loss: 0.0866, Accuracy: 96.88%\nStart validation #14\nValidation #14  Accuracy: 100.00%  Average Loss: 0.0217\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9425ac00474e49fca7638d6b6da96b93"}},"metadata":{}},{"name":"stdout","text":"Epoch [15/30], Step [30/1305], Loss: 0.0345, Accuracy: 100.00%\nEpoch [15/30], Step [60/1305], Loss: 0.0189, Accuracy: 98.44%\nEpoch [15/30], Step [90/1305], Loss: 0.0409, Accuracy: 98.44%\nEpoch [15/30], Step [120/1305], Loss: 0.0104, Accuracy: 100.00%\nEpoch [15/30], Step [150/1305], Loss: 0.0098, Accuracy: 100.00%\nEpoch [15/30], Step [180/1305], Loss: 0.0544, Accuracy: 98.44%\nEpoch [15/30], Step [210/1305], Loss: 0.0398, Accuracy: 98.44%\nEpoch [15/30], Step [240/1305], Loss: 0.0721, Accuracy: 96.88%\nEpoch [15/30], Step [270/1305], Loss: 0.1845, Accuracy: 93.75%\nEpoch [15/30], Step [300/1305], Loss: 0.1295, Accuracy: 92.19%\nEpoch [15/30], Step [330/1305], Loss: 0.0671, Accuracy: 98.44%\nEpoch [15/30], Step [360/1305], Loss: 0.0163, Accuracy: 100.00%\nEpoch [15/30], Step [390/1305], Loss: 0.0609, Accuracy: 98.44%\nEpoch [15/30], Step [420/1305], Loss: 0.0645, Accuracy: 98.44%\nEpoch [15/30], Step [450/1305], Loss: 0.1416, Accuracy: 96.88%\nEpoch [15/30], Step [480/1305], Loss: 0.0211, Accuracy: 100.00%\nEpoch [15/30], Step [510/1305], Loss: 0.0454, Accuracy: 95.31%\nEpoch [15/30], Step [540/1305], Loss: 0.0879, Accuracy: 96.88%\nEpoch [15/30], Step [570/1305], Loss: 0.0186, Accuracy: 100.00%\nEpoch [15/30], Step [600/1305], Loss: 0.0440, Accuracy: 98.44%\nEpoch [15/30], Step [630/1305], Loss: 0.0275, Accuracy: 98.44%\nEpoch [15/30], Step [660/1305], Loss: 0.0723, Accuracy: 96.88%\nEpoch [15/30], Step [690/1305], Loss: 0.0448, Accuracy: 98.44%\nEpoch [15/30], Step [720/1305], Loss: 0.0698, Accuracy: 95.31%\nEpoch [15/30], Step [750/1305], Loss: 0.0749, Accuracy: 98.44%\nEpoch [15/30], Step [780/1305], Loss: 0.0184, Accuracy: 100.00%\nEpoch [15/30], Step [810/1305], Loss: 0.0686, Accuracy: 98.44%\nEpoch [15/30], Step [840/1305], Loss: 0.0905, Accuracy: 96.88%\nEpoch [15/30], Step [870/1305], Loss: 0.1447, Accuracy: 96.88%\nEpoch [15/30], Step [900/1305], Loss: 0.0982, Accuracy: 96.88%\nEpoch [15/30], Step [930/1305], Loss: 0.0557, Accuracy: 98.44%\nEpoch [15/30], Step [960/1305], Loss: 0.0160, Accuracy: 100.00%\nEpoch [15/30], Step [990/1305], Loss: 0.0303, Accuracy: 100.00%\nEpoch [15/30], Step [1020/1305], Loss: 0.0372, Accuracy: 98.44%\nEpoch [15/30], Step [1050/1305], Loss: 0.0107, Accuracy: 100.00%\nEpoch [15/30], Step [1080/1305], Loss: 0.0402, Accuracy: 98.44%\nEpoch [15/30], Step [1110/1305], Loss: 0.0463, Accuracy: 96.88%\nEpoch [15/30], Step [1140/1305], Loss: 0.0245, Accuracy: 100.00%\nEpoch [15/30], Step [1170/1305], Loss: 0.0156, Accuracy: 100.00%\nEpoch [15/30], Step [1200/1305], Loss: 0.0440, Accuracy: 98.44%\nEpoch [15/30], Step [1230/1305], Loss: 0.1476, Accuracy: 95.31%\nEpoch [15/30], Step [1260/1305], Loss: 0.1497, Accuracy: 95.31%\nEpoch [15/30], Step [1290/1305], Loss: 0.0672, Accuracy: 96.88%\nStart validation #15\nValidation #15  Accuracy: 100.00%  Average Loss: 0.0186\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff1f530345bf4c77acfc56e39c23e1f9"}},"metadata":{}},{"name":"stdout","text":"Epoch [16/30], Step [30/1305], Loss: 0.0737, Accuracy: 95.31%\nEpoch [16/30], Step [60/1305], Loss: 0.0756, Accuracy: 98.44%\nEpoch [16/30], Step [90/1305], Loss: 0.1563, Accuracy: 92.19%\nEpoch [16/30], Step [120/1305], Loss: 0.0160, Accuracy: 100.00%\nEpoch [16/30], Step [150/1305], Loss: 0.0454, Accuracy: 95.31%\nEpoch [16/30], Step [180/1305], Loss: 0.0582, Accuracy: 96.88%\nEpoch [16/30], Step [210/1305], Loss: 0.0044, Accuracy: 100.00%\nEpoch [16/30], Step [240/1305], Loss: 0.0411, Accuracy: 96.88%\nEpoch [16/30], Step [270/1305], Loss: 0.0842, Accuracy: 95.31%\nEpoch [16/30], Step [300/1305], Loss: 0.0319, Accuracy: 98.44%\nEpoch [16/30], Step [330/1305], Loss: 0.0274, Accuracy: 100.00%\nEpoch [16/30], Step [360/1305], Loss: 0.0411, Accuracy: 98.44%\nEpoch [16/30], Step [390/1305], Loss: 0.0206, Accuracy: 100.00%\nEpoch [16/30], Step [420/1305], Loss: 0.0284, Accuracy: 100.00%\nEpoch [16/30], Step [450/1305], Loss: 0.0402, Accuracy: 98.44%\nEpoch [16/30], Step [480/1305], Loss: 0.0262, Accuracy: 98.44%\nEpoch [16/30], Step [510/1305], Loss: 0.2083, Accuracy: 93.75%\nEpoch [16/30], Step [540/1305], Loss: 0.0245, Accuracy: 100.00%\nEpoch [16/30], Step [570/1305], Loss: 0.0460, Accuracy: 98.44%\nEpoch [16/30], Step [600/1305], Loss: 0.0151, Accuracy: 100.00%\nEpoch [16/30], Step [630/1305], Loss: 0.0734, Accuracy: 96.88%\nEpoch [16/30], Step [660/1305], Loss: 0.0245, Accuracy: 100.00%\nEpoch [16/30], Step [690/1305], Loss: 0.0159, Accuracy: 100.00%\nEpoch [16/30], Step [720/1305], Loss: 0.0042, Accuracy: 100.00%\nEpoch [16/30], Step [750/1305], Loss: 0.1298, Accuracy: 96.88%\nEpoch [16/30], Step [780/1305], Loss: 0.0390, Accuracy: 96.88%\nEpoch [16/30], Step [810/1305], Loss: 0.0712, Accuracy: 98.44%\nEpoch [16/30], Step [840/1305], Loss: 0.0422, Accuracy: 98.44%\nEpoch [16/30], Step [870/1305], Loss: 0.0932, Accuracy: 95.31%\nEpoch [16/30], Step [900/1305], Loss: 0.0415, Accuracy: 96.88%\nEpoch [16/30], Step [930/1305], Loss: 0.1926, Accuracy: 95.31%\nEpoch [16/30], Step [960/1305], Loss: 0.0220, Accuracy: 100.00%\nEpoch [16/30], Step [990/1305], Loss: 0.1253, Accuracy: 93.75%\nEpoch [16/30], Step [1020/1305], Loss: 0.0227, Accuracy: 100.00%\nEpoch [16/30], Step [1050/1305], Loss: 0.0046, Accuracy: 100.00%\nEpoch [16/30], Step [1080/1305], Loss: 0.0691, Accuracy: 96.88%\nEpoch [16/30], Step [1110/1305], Loss: 0.0390, Accuracy: 100.00%\nEpoch [16/30], Step [1140/1305], Loss: 0.0422, Accuracy: 98.44%\nEpoch [16/30], Step [1170/1305], Loss: 0.0157, Accuracy: 100.00%\nEpoch [16/30], Step [1200/1305], Loss: 0.0109, Accuracy: 100.00%\nEpoch [16/30], Step [1230/1305], Loss: 0.0155, Accuracy: 100.00%\nEpoch [16/30], Step [1260/1305], Loss: 0.0334, Accuracy: 98.44%\nEpoch [16/30], Step [1290/1305], Loss: 0.0569, Accuracy: 98.44%\nStart validation #16\nValidation #16  Accuracy: 100.00%  Average Loss: 0.0185\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c962a490c7204defaa3fdcba873bf93a"}},"metadata":{}},{"name":"stdout","text":"Epoch [17/30], Step [30/1305], Loss: 0.0332, Accuracy: 98.44%\nEpoch [17/30], Step [60/1305], Loss: 0.0413, Accuracy: 98.44%\nEpoch [17/30], Step [90/1305], Loss: 0.0422, Accuracy: 98.44%\nEpoch [17/30], Step [120/1305], Loss: 0.0725, Accuracy: 96.88%\nEpoch [17/30], Step [150/1305], Loss: 0.0847, Accuracy: 95.31%\nEpoch [17/30], Step [180/1305], Loss: 0.1553, Accuracy: 96.88%\nEpoch [17/30], Step [210/1305], Loss: 0.0463, Accuracy: 98.44%\nEpoch [17/30], Step [240/1305], Loss: 0.0623, Accuracy: 98.44%\nEpoch [17/30], Step [270/1305], Loss: 0.0369, Accuracy: 98.44%\nEpoch [17/30], Step [300/1305], Loss: 0.0240, Accuracy: 98.44%\nEpoch [17/30], Step [330/1305], Loss: 0.0446, Accuracy: 98.44%\nEpoch [17/30], Step [360/1305], Loss: 0.0310, Accuracy: 98.44%\nEpoch [17/30], Step [390/1305], Loss: 0.0227, Accuracy: 100.00%\nEpoch [17/30], Step [420/1305], Loss: 0.0589, Accuracy: 95.31%\nEpoch [17/30], Step [450/1305], Loss: 0.1294, Accuracy: 96.88%\nEpoch [17/30], Step [480/1305], Loss: 0.1083, Accuracy: 95.31%\nEpoch [17/30], Step [510/1305], Loss: 0.0143, Accuracy: 100.00%\nEpoch [17/30], Step [540/1305], Loss: 0.0098, Accuracy: 100.00%\nEpoch [17/30], Step [570/1305], Loss: 0.0229, Accuracy: 98.44%\nEpoch [17/30], Step [600/1305], Loss: 0.1000, Accuracy: 96.88%\nEpoch [17/30], Step [630/1305], Loss: 0.0447, Accuracy: 98.44%\nEpoch [17/30], Step [660/1305], Loss: 0.0420, Accuracy: 98.44%\nEpoch [17/30], Step [690/1305], Loss: 0.0257, Accuracy: 100.00%\nEpoch [17/30], Step [720/1305], Loss: 0.1191, Accuracy: 95.31%\nEpoch [17/30], Step [750/1305], Loss: 0.1625, Accuracy: 95.31%\nEpoch [17/30], Step [780/1305], Loss: 0.0969, Accuracy: 95.31%\nEpoch [17/30], Step [810/1305], Loss: 0.0950, Accuracy: 96.88%\nEpoch [17/30], Step [840/1305], Loss: 0.0133, Accuracy: 100.00%\nEpoch [17/30], Step [870/1305], Loss: 0.0190, Accuracy: 100.00%\nEpoch [17/30], Step [900/1305], Loss: 0.0913, Accuracy: 96.88%\nEpoch [17/30], Step [930/1305], Loss: 0.0060, Accuracy: 100.00%\nEpoch [17/30], Step [960/1305], Loss: 0.0090, Accuracy: 100.00%\nEpoch [17/30], Step [990/1305], Loss: 0.0207, Accuracy: 100.00%\nEpoch [17/30], Step [1020/1305], Loss: 0.0406, Accuracy: 98.44%\nEpoch [17/30], Step [1050/1305], Loss: 0.0278, Accuracy: 98.44%\nEpoch [17/30], Step [1080/1305], Loss: 0.0321, Accuracy: 100.00%\nEpoch [17/30], Step [1110/1305], Loss: 0.0585, Accuracy: 98.44%\nEpoch [17/30], Step [1140/1305], Loss: 0.0245, Accuracy: 100.00%\nEpoch [17/30], Step [1170/1305], Loss: 0.1321, Accuracy: 96.88%\nEpoch [17/30], Step [1200/1305], Loss: 0.0394, Accuracy: 98.44%\nEpoch [17/30], Step [1230/1305], Loss: 0.1386, Accuracy: 92.19%\nEpoch [17/30], Step [1260/1305], Loss: 0.0228, Accuracy: 100.00%\nEpoch [17/30], Step [1290/1305], Loss: 0.0378, Accuracy: 98.44%\nStart validation #17\nValidation #17  Accuracy: 93.75%  Average Loss: 0.1500\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50b37187fc2041a1859661bbedc2d167"}},"metadata":{}},{"name":"stdout","text":"Epoch [18/30], Step [30/1305], Loss: 0.0618, Accuracy: 96.88%\nEpoch [18/30], Step [60/1305], Loss: 0.0706, Accuracy: 95.31%\nEpoch [18/30], Step [90/1305], Loss: 0.0334, Accuracy: 96.88%\nEpoch [18/30], Step [120/1305], Loss: 0.0122, Accuracy: 100.00%\nEpoch [18/30], Step [150/1305], Loss: 0.0139, Accuracy: 100.00%\nEpoch [18/30], Step [180/1305], Loss: 0.0198, Accuracy: 100.00%\nEpoch [18/30], Step [210/1305], Loss: 0.0205, Accuracy: 100.00%\nEpoch [18/30], Step [240/1305], Loss: 0.0401, Accuracy: 98.44%\nEpoch [18/30], Step [270/1305], Loss: 0.0429, Accuracy: 98.44%\nEpoch [18/30], Step [300/1305], Loss: 0.0751, Accuracy: 98.44%\nEpoch [18/30], Step [330/1305], Loss: 0.0112, Accuracy: 100.00%\nEpoch [18/30], Step [360/1305], Loss: 0.0344, Accuracy: 96.88%\nEpoch [18/30], Step [390/1305], Loss: 0.1020, Accuracy: 96.88%\nEpoch [18/30], Step [420/1305], Loss: 0.1459, Accuracy: 95.31%\nEpoch [18/30], Step [450/1305], Loss: 0.0129, Accuracy: 100.00%\nEpoch [18/30], Step [480/1305], Loss: 0.0375, Accuracy: 98.44%\nEpoch [18/30], Step [510/1305], Loss: 0.1333, Accuracy: 95.31%\nEpoch [18/30], Step [540/1305], Loss: 0.1118, Accuracy: 96.88%\nEpoch [18/30], Step [570/1305], Loss: 0.1386, Accuracy: 96.88%\nEpoch [18/30], Step [600/1305], Loss: 0.0979, Accuracy: 96.88%\nEpoch [18/30], Step [630/1305], Loss: 0.0363, Accuracy: 98.44%\nEpoch [18/30], Step [660/1305], Loss: 0.0098, Accuracy: 100.00%\nEpoch [18/30], Step [690/1305], Loss: 0.0612, Accuracy: 96.88%\nEpoch [18/30], Step [720/1305], Loss: 0.0024, Accuracy: 100.00%\nEpoch [18/30], Step [750/1305], Loss: 0.0664, Accuracy: 98.44%\nEpoch [18/30], Step [780/1305], Loss: 0.0722, Accuracy: 98.44%\nEpoch [18/30], Step [810/1305], Loss: 0.1118, Accuracy: 96.88%\nEpoch [18/30], Step [840/1305], Loss: 0.0142, Accuracy: 100.00%\nEpoch [18/30], Step [870/1305], Loss: 0.0616, Accuracy: 98.44%\nEpoch [18/30], Step [900/1305], Loss: 0.0616, Accuracy: 98.44%\nEpoch [18/30], Step [930/1305], Loss: 0.0924, Accuracy: 96.88%\nEpoch [18/30], Step [960/1305], Loss: 0.0987, Accuracy: 95.31%\nEpoch [18/30], Step [990/1305], Loss: 0.0158, Accuracy: 100.00%\nEpoch [18/30], Step [1020/1305], Loss: 0.1183, Accuracy: 95.31%\nEpoch [18/30], Step [1050/1305], Loss: 0.0447, Accuracy: 98.44%\nEpoch [18/30], Step [1080/1305], Loss: 0.1462, Accuracy: 96.88%\nEpoch [18/30], Step [1110/1305], Loss: 0.0232, Accuracy: 98.44%\nEpoch [18/30], Step [1140/1305], Loss: 0.1722, Accuracy: 98.44%\nEpoch [18/30], Step [1170/1305], Loss: 0.0464, Accuracy: 98.44%\nEpoch [18/30], Step [1200/1305], Loss: 0.1066, Accuracy: 96.88%\nEpoch [18/30], Step [1230/1305], Loss: 0.0070, Accuracy: 100.00%\nEpoch [18/30], Step [1260/1305], Loss: 0.0891, Accuracy: 93.75%\nEpoch [18/30], Step [1290/1305], Loss: 0.0552, Accuracy: 96.88%\nStart validation #18\nValidation #18  Accuracy: 96.88%  Average Loss: 0.0511\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0500d8f438d42bb9fe2d437398409f2"}},"metadata":{}},{"name":"stdout","text":"Epoch [19/30], Step [30/1305], Loss: 0.0294, Accuracy: 98.44%\nEpoch [19/30], Step [60/1305], Loss: 0.0085, Accuracy: 100.00%\nEpoch [19/30], Step [90/1305], Loss: 0.0341, Accuracy: 98.44%\nEpoch [19/30], Step [120/1305], Loss: 0.1020, Accuracy: 98.44%\nEpoch [19/30], Step [150/1305], Loss: 0.0153, Accuracy: 100.00%\nEpoch [19/30], Step [180/1305], Loss: 0.0892, Accuracy: 96.88%\nEpoch [19/30], Step [210/1305], Loss: 0.0625, Accuracy: 98.44%\nEpoch [19/30], Step [240/1305], Loss: 0.0216, Accuracy: 100.00%\nEpoch [19/30], Step [270/1305], Loss: 0.0191, Accuracy: 98.44%\nEpoch [19/30], Step [300/1305], Loss: 0.0452, Accuracy: 98.44%\nEpoch [19/30], Step [330/1305], Loss: 0.0143, Accuracy: 100.00%\nEpoch [19/30], Step [360/1305], Loss: 0.0037, Accuracy: 100.00%\nEpoch [19/30], Step [390/1305], Loss: 0.0386, Accuracy: 96.88%\nEpoch [19/30], Step [420/1305], Loss: 0.0401, Accuracy: 98.44%\nEpoch [19/30], Step [450/1305], Loss: 0.0452, Accuracy: 98.44%\nEpoch [19/30], Step [480/1305], Loss: 0.0243, Accuracy: 98.44%\nEpoch [19/30], Step [510/1305], Loss: 0.0204, Accuracy: 100.00%\nEpoch [19/30], Step [540/1305], Loss: 0.0416, Accuracy: 98.44%\nEpoch [19/30], Step [570/1305], Loss: 0.0356, Accuracy: 98.44%\nEpoch [19/30], Step [600/1305], Loss: 0.0524, Accuracy: 96.88%\nEpoch [19/30], Step [630/1305], Loss: 0.0251, Accuracy: 100.00%\nEpoch [19/30], Step [660/1305], Loss: 0.0672, Accuracy: 96.88%\nEpoch [19/30], Step [690/1305], Loss: 0.0582, Accuracy: 98.44%\nEpoch [19/30], Step [720/1305], Loss: 0.0186, Accuracy: 98.44%\nEpoch [19/30], Step [750/1305], Loss: 0.0645, Accuracy: 98.44%\nEpoch [19/30], Step [780/1305], Loss: 0.0586, Accuracy: 98.44%\nEpoch [19/30], Step [810/1305], Loss: 0.0148, Accuracy: 100.00%\nEpoch [19/30], Step [840/1305], Loss: 0.0611, Accuracy: 96.88%\nEpoch [19/30], Step [870/1305], Loss: 0.0377, Accuracy: 98.44%\nEpoch [19/30], Step [900/1305], Loss: 0.0316, Accuracy: 98.44%\nEpoch [19/30], Step [930/1305], Loss: 0.0347, Accuracy: 98.44%\nEpoch [19/30], Step [960/1305], Loss: 0.0426, Accuracy: 98.44%\nEpoch [19/30], Step [990/1305], Loss: 0.1032, Accuracy: 96.88%\nEpoch [19/30], Step [1020/1305], Loss: 0.0834, Accuracy: 96.88%\nEpoch [19/30], Step [1050/1305], Loss: 0.0298, Accuracy: 98.44%\nEpoch [19/30], Step [1080/1305], Loss: 0.0123, Accuracy: 100.00%\nEpoch [19/30], Step [1110/1305], Loss: 0.0889, Accuracy: 96.88%\nEpoch [19/30], Step [1140/1305], Loss: 0.1173, Accuracy: 96.88%\nEpoch [19/30], Step [1170/1305], Loss: 0.0608, Accuracy: 96.88%\nEpoch [19/30], Step [1200/1305], Loss: 0.0218, Accuracy: 98.44%\nEpoch [19/30], Step [1230/1305], Loss: 0.0102, Accuracy: 100.00%\nEpoch [19/30], Step [1260/1305], Loss: 0.0237, Accuracy: 100.00%\nEpoch [19/30], Step [1290/1305], Loss: 0.0992, Accuracy: 98.44%\nStart validation #19\nValidation #19  Accuracy: 100.00%  Average Loss: 0.0316\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc95af09b8224b44925b40cd23b54c6a"}},"metadata":{}},{"name":"stdout","text":"Epoch [20/30], Step [30/1305], Loss: 0.0251, Accuracy: 100.00%\nEpoch [20/30], Step [60/1305], Loss: 0.0996, Accuracy: 95.31%\nEpoch [20/30], Step [90/1305], Loss: 0.0412, Accuracy: 98.44%\nEpoch [20/30], Step [120/1305], Loss: 0.0068, Accuracy: 100.00%\nEpoch [20/30], Step [150/1305], Loss: 0.0120, Accuracy: 100.00%\nEpoch [20/30], Step [180/1305], Loss: 0.0146, Accuracy: 100.00%\nEpoch [20/30], Step [210/1305], Loss: 0.0037, Accuracy: 100.00%\nEpoch [20/30], Step [240/1305], Loss: 0.0131, Accuracy: 100.00%\nEpoch [20/30], Step [270/1305], Loss: 0.0653, Accuracy: 96.88%\nEpoch [20/30], Step [300/1305], Loss: 0.0282, Accuracy: 98.44%\nEpoch [20/30], Step [330/1305], Loss: 0.0159, Accuracy: 100.00%\nEpoch [20/30], Step [360/1305], Loss: 0.0770, Accuracy: 96.88%\nEpoch [20/30], Step [390/1305], Loss: 0.0442, Accuracy: 96.88%\nEpoch [20/30], Step [420/1305], Loss: 0.0513, Accuracy: 98.44%\nEpoch [20/30], Step [450/1305], Loss: 0.0796, Accuracy: 96.88%\nEpoch [20/30], Step [480/1305], Loss: 0.0360, Accuracy: 98.44%\nEpoch [20/30], Step [510/1305], Loss: 0.0391, Accuracy: 98.44%\nEpoch [20/30], Step [540/1305], Loss: 0.0982, Accuracy: 96.88%\nEpoch [20/30], Step [570/1305], Loss: 0.0044, Accuracy: 100.00%\nEpoch [20/30], Step [600/1305], Loss: 0.0343, Accuracy: 98.44%\nEpoch [20/30], Step [630/1305], Loss: 0.2406, Accuracy: 93.75%\nEpoch [20/30], Step [660/1305], Loss: 0.0193, Accuracy: 100.00%\nEpoch [20/30], Step [690/1305], Loss: 0.0079, Accuracy: 100.00%\nEpoch [20/30], Step [720/1305], Loss: 0.0117, Accuracy: 100.00%\nEpoch [20/30], Step [750/1305], Loss: 0.0196, Accuracy: 100.00%\nEpoch [20/30], Step [780/1305], Loss: 0.0360, Accuracy: 100.00%\nEpoch [20/30], Step [810/1305], Loss: 0.0144, Accuracy: 100.00%\nEpoch [20/30], Step [840/1305], Loss: 0.0031, Accuracy: 100.00%\nEpoch [20/30], Step [870/1305], Loss: 0.0277, Accuracy: 100.00%\nEpoch [20/30], Step [900/1305], Loss: 0.0178, Accuracy: 100.00%\nEpoch [20/30], Step [930/1305], Loss: 0.0519, Accuracy: 98.44%\nEpoch [20/30], Step [960/1305], Loss: 0.0527, Accuracy: 98.44%\nEpoch [20/30], Step [990/1305], Loss: 0.0275, Accuracy: 100.00%\nEpoch [20/30], Step [1020/1305], Loss: 0.0188, Accuracy: 100.00%\nEpoch [20/30], Step [1050/1305], Loss: 0.0894, Accuracy: 96.88%\nEpoch [20/30], Step [1080/1305], Loss: 0.0567, Accuracy: 96.88%\nEpoch [20/30], Step [1110/1305], Loss: 0.0863, Accuracy: 98.44%\nEpoch [20/30], Step [1140/1305], Loss: 0.0649, Accuracy: 98.44%\nEpoch [20/30], Step [1170/1305], Loss: 0.0604, Accuracy: 98.44%\nEpoch [20/30], Step [1200/1305], Loss: 0.1774, Accuracy: 95.31%\nEpoch [20/30], Step [1230/1305], Loss: 0.0089, Accuracy: 100.00%\nEpoch [20/30], Step [1260/1305], Loss: 0.0177, Accuracy: 100.00%\nEpoch [20/30], Step [1290/1305], Loss: 0.0207, Accuracy: 98.44%\nStart validation #20\nValidation #20  Accuracy: 100.00%  Average Loss: 0.0096\nBest performance at epoch: 20\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55aad1b5b00b4909b45ba8c5c282a2c4"}},"metadata":{}},{"name":"stdout","text":"Epoch [21/30], Step [30/1305], Loss: 0.0473, Accuracy: 96.88%\nEpoch [21/30], Step [60/1305], Loss: 0.0947, Accuracy: 96.88%\nEpoch [21/30], Step [90/1305], Loss: 0.0435, Accuracy: 96.88%\nEpoch [21/30], Step [120/1305], Loss: 0.0059, Accuracy: 100.00%\nEpoch [21/30], Step [150/1305], Loss: 0.0680, Accuracy: 98.44%\nEpoch [21/30], Step [180/1305], Loss: 0.0079, Accuracy: 100.00%\nEpoch [21/30], Step [210/1305], Loss: 0.0601, Accuracy: 96.88%\nEpoch [21/30], Step [240/1305], Loss: 0.0145, Accuracy: 100.00%\nEpoch [21/30], Step [270/1305], Loss: 0.1215, Accuracy: 96.88%\nEpoch [21/30], Step [300/1305], Loss: 0.0193, Accuracy: 100.00%\nEpoch [21/30], Step [330/1305], Loss: 0.0103, Accuracy: 100.00%\nEpoch [21/30], Step [360/1305], Loss: 0.0454, Accuracy: 98.44%\nEpoch [21/30], Step [390/1305], Loss: 0.0490, Accuracy: 98.44%\nEpoch [21/30], Step [420/1305], Loss: 0.0761, Accuracy: 96.88%\nEpoch [21/30], Step [450/1305], Loss: 0.0347, Accuracy: 98.44%\nEpoch [21/30], Step [480/1305], Loss: 0.0322, Accuracy: 98.44%\nEpoch [21/30], Step [510/1305], Loss: 0.0201, Accuracy: 100.00%\nEpoch [21/30], Step [540/1305], Loss: 0.0044, Accuracy: 100.00%\nEpoch [21/30], Step [570/1305], Loss: 0.0407, Accuracy: 98.44%\nEpoch [21/30], Step [600/1305], Loss: 0.0467, Accuracy: 98.44%\nEpoch [21/30], Step [630/1305], Loss: 0.0072, Accuracy: 100.00%\nEpoch [21/30], Step [660/1305], Loss: 0.0534, Accuracy: 96.88%\nEpoch [21/30], Step [690/1305], Loss: 0.0189, Accuracy: 98.44%\nEpoch [21/30], Step [720/1305], Loss: 0.0540, Accuracy: 96.88%\nEpoch [21/30], Step [750/1305], Loss: 0.1049, Accuracy: 96.88%\nEpoch [21/30], Step [780/1305], Loss: 0.0448, Accuracy: 98.44%\nEpoch [21/30], Step [810/1305], Loss: 0.0199, Accuracy: 98.44%\nEpoch [21/30], Step [840/1305], Loss: 0.0344, Accuracy: 98.44%\nEpoch [21/30], Step [870/1305], Loss: 0.0125, Accuracy: 100.00%\nEpoch [21/30], Step [900/1305], Loss: 0.0112, Accuracy: 100.00%\nEpoch [21/30], Step [930/1305], Loss: 0.0076, Accuracy: 100.00%\nEpoch [21/30], Step [960/1305], Loss: 0.0735, Accuracy: 95.31%\nEpoch [21/30], Step [990/1305], Loss: 0.0544, Accuracy: 98.44%\nEpoch [21/30], Step [1020/1305], Loss: 0.0177, Accuracy: 100.00%\nEpoch [21/30], Step [1050/1305], Loss: 0.0092, Accuracy: 100.00%\nEpoch [21/30], Step [1080/1305], Loss: 0.0138, Accuracy: 100.00%\nEpoch [21/30], Step [1110/1305], Loss: 0.0538, Accuracy: 96.88%\nEpoch [21/30], Step [1140/1305], Loss: 0.0215, Accuracy: 100.00%\nEpoch [21/30], Step [1170/1305], Loss: 0.0091, Accuracy: 100.00%\nEpoch [21/30], Step [1200/1305], Loss: 0.0069, Accuracy: 100.00%\nEpoch [21/30], Step [1230/1305], Loss: 0.0062, Accuracy: 100.00%\nEpoch [21/30], Step [1260/1305], Loss: 0.0198, Accuracy: 100.00%\nEpoch [21/30], Step [1290/1305], Loss: 0.0471, Accuracy: 98.44%\nStart validation #21\nValidation #21  Accuracy: 96.88%  Average Loss: 0.0669\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20da38cd795f4375aa2665176cc9a50e"}},"metadata":{}},{"name":"stdout","text":"Epoch [22/30], Step [30/1305], Loss: 0.0040, Accuracy: 100.00%\nEpoch [22/30], Step [60/1305], Loss: 0.0541, Accuracy: 98.44%\nEpoch [22/30], Step [90/1305], Loss: 0.1513, Accuracy: 95.31%\nEpoch [22/30], Step [120/1305], Loss: 0.0534, Accuracy: 96.88%\nEpoch [22/30], Step [150/1305], Loss: 0.0295, Accuracy: 100.00%\nEpoch [22/30], Step [180/1305], Loss: 0.0105, Accuracy: 100.00%\nEpoch [22/30], Step [210/1305], Loss: 0.0188, Accuracy: 100.00%\nEpoch [22/30], Step [240/1305], Loss: 0.0080, Accuracy: 100.00%\nEpoch [22/30], Step [270/1305], Loss: 0.0648, Accuracy: 98.44%\nEpoch [22/30], Step [300/1305], Loss: 0.1341, Accuracy: 95.31%\nEpoch [22/30], Step [330/1305], Loss: 0.1352, Accuracy: 95.31%\nEpoch [22/30], Step [360/1305], Loss: 0.0959, Accuracy: 98.44%\nEpoch [22/30], Step [390/1305], Loss: 0.0210, Accuracy: 100.00%\nEpoch [22/30], Step [420/1305], Loss: 0.0336, Accuracy: 98.44%\nEpoch [22/30], Step [450/1305], Loss: 0.1060, Accuracy: 98.44%\nEpoch [22/30], Step [480/1305], Loss: 0.0745, Accuracy: 96.88%\nEpoch [22/30], Step [510/1305], Loss: 0.0154, Accuracy: 100.00%\nEpoch [22/30], Step [540/1305], Loss: 0.0305, Accuracy: 100.00%\nEpoch [22/30], Step [570/1305], Loss: 0.0559, Accuracy: 98.44%\nEpoch [22/30], Step [600/1305], Loss: 0.0334, Accuracy: 98.44%\nEpoch [22/30], Step [630/1305], Loss: 0.0668, Accuracy: 96.88%\nEpoch [22/30], Step [660/1305], Loss: 0.0064, Accuracy: 100.00%\nEpoch [22/30], Step [690/1305], Loss: 0.0233, Accuracy: 98.44%\nEpoch [22/30], Step [720/1305], Loss: 0.0743, Accuracy: 96.88%\nEpoch [22/30], Step [750/1305], Loss: 0.0626, Accuracy: 96.88%\nEpoch [22/30], Step [780/1305], Loss: 0.0321, Accuracy: 98.44%\nEpoch [22/30], Step [810/1305], Loss: 0.1383, Accuracy: 96.88%\nEpoch [22/30], Step [840/1305], Loss: 0.0304, Accuracy: 98.44%\nEpoch [22/30], Step [870/1305], Loss: 0.1018, Accuracy: 98.44%\nEpoch [22/30], Step [900/1305], Loss: 0.0098, Accuracy: 100.00%\nEpoch [22/30], Step [930/1305], Loss: 0.0354, Accuracy: 98.44%\nEpoch [22/30], Step [960/1305], Loss: 0.0952, Accuracy: 96.88%\nEpoch [22/30], Step [990/1305], Loss: 0.0509, Accuracy: 98.44%\nEpoch [22/30], Step [1020/1305], Loss: 0.0978, Accuracy: 98.44%\nEpoch [22/30], Step [1050/1305], Loss: 0.0191, Accuracy: 98.44%\nEpoch [22/30], Step [1080/1305], Loss: 0.0379, Accuracy: 98.44%\nEpoch [22/30], Step [1110/1305], Loss: 0.0062, Accuracy: 100.00%\nEpoch [22/30], Step [1140/1305], Loss: 0.1349, Accuracy: 95.31%\nEpoch [22/30], Step [1170/1305], Loss: 0.0417, Accuracy: 98.44%\nEpoch [22/30], Step [1200/1305], Loss: 0.0272, Accuracy: 98.44%\nEpoch [22/30], Step [1230/1305], Loss: 0.0723, Accuracy: 98.44%\nEpoch [22/30], Step [1260/1305], Loss: 0.0248, Accuracy: 98.44%\nEpoch [22/30], Step [1290/1305], Loss: 0.0386, Accuracy: 98.44%\nStart validation #22\nValidation #22  Accuracy: 96.88%  Average Loss: 0.1335\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e9ea8342f6416c911794fb17abd85b"}},"metadata":{}},{"name":"stdout","text":"Epoch [23/30], Step [30/1305], Loss: 0.0342, Accuracy: 98.44%\nEpoch [23/30], Step [60/1305], Loss: 0.0502, Accuracy: 98.44%\nEpoch [23/30], Step [90/1305], Loss: 0.0131, Accuracy: 100.00%\nEpoch [23/30], Step [120/1305], Loss: 0.0111, Accuracy: 100.00%\nEpoch [23/30], Step [150/1305], Loss: 0.0499, Accuracy: 98.44%\nEpoch [23/30], Step [180/1305], Loss: 0.0159, Accuracy: 100.00%\nEpoch [23/30], Step [210/1305], Loss: 0.0125, Accuracy: 100.00%\nEpoch [23/30], Step [240/1305], Loss: 0.0777, Accuracy: 96.88%\nEpoch [23/30], Step [270/1305], Loss: 0.0229, Accuracy: 98.44%\nEpoch [23/30], Step [300/1305], Loss: 0.0337, Accuracy: 98.44%\nEpoch [23/30], Step [330/1305], Loss: 0.0178, Accuracy: 100.00%\nEpoch [23/30], Step [360/1305], Loss: 0.0031, Accuracy: 100.00%\nEpoch [23/30], Step [390/1305], Loss: 0.0256, Accuracy: 100.00%\nEpoch [23/30], Step [420/1305], Loss: 0.0168, Accuracy: 98.44%\nEpoch [23/30], Step [450/1305], Loss: 0.0083, Accuracy: 100.00%\nEpoch [23/30], Step [480/1305], Loss: 0.0021, Accuracy: 100.00%\nEpoch [23/30], Step [510/1305], Loss: 0.0616, Accuracy: 98.44%\nEpoch [23/30], Step [540/1305], Loss: 0.0231, Accuracy: 98.44%\nEpoch [23/30], Step [570/1305], Loss: 0.1236, Accuracy: 95.31%\nEpoch [23/30], Step [600/1305], Loss: 0.0062, Accuracy: 100.00%\nEpoch [23/30], Step [630/1305], Loss: 0.1408, Accuracy: 95.31%\nEpoch [23/30], Step [660/1305], Loss: 0.2965, Accuracy: 95.31%\nEpoch [23/30], Step [690/1305], Loss: 0.0211, Accuracy: 100.00%\nEpoch [23/30], Step [720/1305], Loss: 0.0739, Accuracy: 98.44%\nEpoch [23/30], Step [750/1305], Loss: 0.0081, Accuracy: 100.00%\nEpoch [23/30], Step [780/1305], Loss: 0.1135, Accuracy: 95.31%\nEpoch [23/30], Step [810/1305], Loss: 0.0509, Accuracy: 98.44%\nEpoch [23/30], Step [840/1305], Loss: 0.0749, Accuracy: 95.31%\nEpoch [23/30], Step [870/1305], Loss: 0.0617, Accuracy: 96.88%\nEpoch [23/30], Step [900/1305], Loss: 0.0232, Accuracy: 98.44%\nEpoch [23/30], Step [930/1305], Loss: 0.0154, Accuracy: 100.00%\nEpoch [23/30], Step [960/1305], Loss: 0.0454, Accuracy: 96.88%\nEpoch [23/30], Step [990/1305], Loss: 0.0289, Accuracy: 98.44%\nEpoch [23/30], Step [1020/1305], Loss: 0.0853, Accuracy: 96.88%\nEpoch [23/30], Step [1050/1305], Loss: 0.1557, Accuracy: 98.44%\nEpoch [23/30], Step [1080/1305], Loss: 0.0159, Accuracy: 100.00%\nEpoch [23/30], Step [1110/1305], Loss: 0.0376, Accuracy: 96.88%\nEpoch [23/30], Step [1140/1305], Loss: 0.0311, Accuracy: 98.44%\nEpoch [23/30], Step [1170/1305], Loss: 0.0300, Accuracy: 98.44%\nEpoch [23/30], Step [1200/1305], Loss: 0.0107, Accuracy: 100.00%\nEpoch [23/30], Step [1230/1305], Loss: 0.0425, Accuracy: 98.44%\nEpoch [23/30], Step [1260/1305], Loss: 0.0646, Accuracy: 96.88%\nEpoch [23/30], Step [1290/1305], Loss: 0.0233, Accuracy: 100.00%\nStart validation #23\nValidation #23  Accuracy: 96.88%  Average Loss: 0.0542\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7746a23e5e054017bd500ef45c2ac97f"}},"metadata":{}},{"name":"stdout","text":"Epoch [24/30], Step [30/1305], Loss: 0.0462, Accuracy: 98.44%\nEpoch [24/30], Step [60/1305], Loss: 0.0360, Accuracy: 98.44%\nEpoch [24/30], Step [90/1305], Loss: 0.0644, Accuracy: 96.88%\nEpoch [24/30], Step [120/1305], Loss: 0.0534, Accuracy: 98.44%\nEpoch [24/30], Step [150/1305], Loss: 0.0365, Accuracy: 98.44%\nEpoch [24/30], Step [180/1305], Loss: 0.1316, Accuracy: 93.75%\nEpoch [24/30], Step [210/1305], Loss: 0.0048, Accuracy: 100.00%\nEpoch [24/30], Step [240/1305], Loss: 0.0100, Accuracy: 100.00%\nEpoch [24/30], Step [270/1305], Loss: 0.0078, Accuracy: 100.00%\nEpoch [24/30], Step [300/1305], Loss: 0.0116, Accuracy: 100.00%\nEpoch [24/30], Step [330/1305], Loss: 0.0203, Accuracy: 100.00%\nEpoch [24/30], Step [360/1305], Loss: 0.0148, Accuracy: 100.00%\nEpoch [24/30], Step [390/1305], Loss: 0.0320, Accuracy: 98.44%\nEpoch [24/30], Step [420/1305], Loss: 0.0237, Accuracy: 98.44%\nEpoch [24/30], Step [450/1305], Loss: 0.0207, Accuracy: 100.00%\nEpoch [24/30], Step [480/1305], Loss: 0.1199, Accuracy: 95.31%\nEpoch [24/30], Step [510/1305], Loss: 0.0298, Accuracy: 98.44%\nEpoch [24/30], Step [540/1305], Loss: 0.0667, Accuracy: 96.88%\nEpoch [24/30], Step [570/1305], Loss: 0.0155, Accuracy: 98.44%\nEpoch [24/30], Step [600/1305], Loss: 0.0237, Accuracy: 100.00%\nEpoch [24/30], Step [630/1305], Loss: 0.0090, Accuracy: 100.00%\nEpoch [24/30], Step [660/1305], Loss: 0.0291, Accuracy: 98.44%\nEpoch [24/30], Step [690/1305], Loss: 0.0083, Accuracy: 100.00%\nEpoch [24/30], Step [720/1305], Loss: 0.0317, Accuracy: 98.44%\nEpoch [24/30], Step [750/1305], Loss: 0.0171, Accuracy: 100.00%\nEpoch [24/30], Step [780/1305], Loss: 0.1079, Accuracy: 95.31%\nEpoch [24/30], Step [810/1305], Loss: 0.0185, Accuracy: 100.00%\nEpoch [24/30], Step [840/1305], Loss: 0.0294, Accuracy: 98.44%\nEpoch [24/30], Step [870/1305], Loss: 0.0379, Accuracy: 98.44%\nEpoch [24/30], Step [900/1305], Loss: 0.0207, Accuracy: 100.00%\nEpoch [24/30], Step [930/1305], Loss: 0.0686, Accuracy: 98.44%\nEpoch [24/30], Step [960/1305], Loss: 0.0499, Accuracy: 98.44%\nEpoch [24/30], Step [990/1305], Loss: 0.0148, Accuracy: 100.00%\nEpoch [24/30], Step [1020/1305], Loss: 0.0455, Accuracy: 98.44%\nEpoch [24/30], Step [1050/1305], Loss: 0.0064, Accuracy: 100.00%\nEpoch [24/30], Step [1080/1305], Loss: 0.0195, Accuracy: 100.00%\nEpoch [24/30], Step [1110/1305], Loss: 0.1305, Accuracy: 96.88%\nEpoch [24/30], Step [1140/1305], Loss: 0.0151, Accuracy: 98.44%\nEpoch [24/30], Step [1170/1305], Loss: 0.1449, Accuracy: 96.88%\nEpoch [24/30], Step [1200/1305], Loss: 0.0474, Accuracy: 96.88%\nEpoch [24/30], Step [1230/1305], Loss: 0.0579, Accuracy: 96.88%\nEpoch [24/30], Step [1260/1305], Loss: 0.0314, Accuracy: 98.44%\nEpoch [24/30], Step [1290/1305], Loss: 0.0125, Accuracy: 100.00%\nStart validation #24\nValidation #24  Accuracy: 96.88%  Average Loss: 0.0440\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a34fd2a00a2476cbbd9efa45c4fec48"}},"metadata":{}},{"name":"stdout","text":"Epoch [25/30], Step [30/1305], Loss: 0.0117, Accuracy: 100.00%\nEpoch [25/30], Step [60/1305], Loss: 0.0628, Accuracy: 98.44%\nEpoch [25/30], Step [90/1305], Loss: 0.0666, Accuracy: 98.44%\nEpoch [25/30], Step [120/1305], Loss: 0.0150, Accuracy: 100.00%\nEpoch [25/30], Step [150/1305], Loss: 0.0163, Accuracy: 100.00%\nEpoch [25/30], Step [180/1305], Loss: 0.0083, Accuracy: 100.00%\nEpoch [25/30], Step [210/1305], Loss: 0.0508, Accuracy: 96.88%\nEpoch [25/30], Step [240/1305], Loss: 0.0568, Accuracy: 98.44%\nEpoch [25/30], Step [270/1305], Loss: 0.0088, Accuracy: 100.00%\nEpoch [25/30], Step [300/1305], Loss: 0.0152, Accuracy: 100.00%\nEpoch [25/30], Step [330/1305], Loss: 0.0228, Accuracy: 100.00%\nEpoch [25/30], Step [360/1305], Loss: 0.0571, Accuracy: 96.88%\nEpoch [25/30], Step [390/1305], Loss: 0.0341, Accuracy: 100.00%\nEpoch [25/30], Step [420/1305], Loss: 0.0898, Accuracy: 95.31%\nEpoch [25/30], Step [450/1305], Loss: 0.1223, Accuracy: 95.31%\nEpoch [25/30], Step [480/1305], Loss: 0.0705, Accuracy: 96.88%\nEpoch [25/30], Step [510/1305], Loss: 0.0689, Accuracy: 98.44%\nEpoch [25/30], Step [540/1305], Loss: 0.0188, Accuracy: 100.00%\nEpoch [25/30], Step [570/1305], Loss: 0.0889, Accuracy: 95.31%\nEpoch [25/30], Step [600/1305], Loss: 0.0278, Accuracy: 98.44%\nEpoch [25/30], Step [630/1305], Loss: 0.0044, Accuracy: 100.00%\nEpoch [25/30], Step [660/1305], Loss: 0.0139, Accuracy: 100.00%\nEpoch [25/30], Step [690/1305], Loss: 0.0365, Accuracy: 98.44%\nEpoch [25/30], Step [720/1305], Loss: 0.1210, Accuracy: 95.31%\nEpoch [25/30], Step [750/1305], Loss: 0.0274, Accuracy: 100.00%\nEpoch [25/30], Step [780/1305], Loss: 0.0231, Accuracy: 100.00%\nEpoch [25/30], Step [810/1305], Loss: 0.1119, Accuracy: 96.88%\nEpoch [25/30], Step [840/1305], Loss: 0.0368, Accuracy: 98.44%\nEpoch [25/30], Step [870/1305], Loss: 0.0781, Accuracy: 96.88%\nEpoch [25/30], Step [900/1305], Loss: 0.0118, Accuracy: 100.00%\nEpoch [25/30], Step [930/1305], Loss: 0.0517, Accuracy: 96.88%\nEpoch [25/30], Step [960/1305], Loss: 0.0253, Accuracy: 98.44%\nEpoch [25/30], Step [990/1305], Loss: 0.0128, Accuracy: 100.00%\nEpoch [25/30], Step [1020/1305], Loss: 0.0320, Accuracy: 96.88%\nEpoch [25/30], Step [1050/1305], Loss: 0.0326, Accuracy: 96.88%\nEpoch [25/30], Step [1080/1305], Loss: 0.0335, Accuracy: 98.44%\nEpoch [25/30], Step [1110/1305], Loss: 0.0177, Accuracy: 100.00%\nEpoch [25/30], Step [1140/1305], Loss: 0.0249, Accuracy: 100.00%\nEpoch [25/30], Step [1170/1305], Loss: 0.0967, Accuracy: 96.88%\nEpoch [25/30], Step [1200/1305], Loss: 0.0193, Accuracy: 100.00%\nEpoch [25/30], Step [1230/1305], Loss: 0.0117, Accuracy: 100.00%\nEpoch [25/30], Step [1260/1305], Loss: 0.0212, Accuracy: 100.00%\nEpoch [25/30], Step [1290/1305], Loss: 0.0210, Accuracy: 100.00%\nStart validation #25\nValidation #25  Accuracy: 100.00%  Average Loss: 0.0296\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c342ee6a98c84af3ba78d9ed082790a4"}},"metadata":{}},{"name":"stdout","text":"Epoch [26/30], Step [30/1305], Loss: 0.0598, Accuracy: 98.44%\nEpoch [26/30], Step [60/1305], Loss: 0.0165, Accuracy: 100.00%\nEpoch [26/30], Step [90/1305], Loss: 0.0935, Accuracy: 95.31%\nEpoch [26/30], Step [120/1305], Loss: 0.0259, Accuracy: 98.44%\nEpoch [26/30], Step [150/1305], Loss: 0.0018, Accuracy: 100.00%\nEpoch [26/30], Step [180/1305], Loss: 0.0243, Accuracy: 98.44%\nEpoch [26/30], Step [210/1305], Loss: 0.0228, Accuracy: 98.44%\nEpoch [26/30], Step [240/1305], Loss: 0.0139, Accuracy: 100.00%\nEpoch [26/30], Step [270/1305], Loss: 0.0360, Accuracy: 98.44%\nEpoch [26/30], Step [300/1305], Loss: 0.0264, Accuracy: 98.44%\nEpoch [26/30], Step [330/1305], Loss: 0.0852, Accuracy: 92.19%\nEpoch [26/30], Step [360/1305], Loss: 0.0636, Accuracy: 98.44%\nEpoch [26/30], Step [390/1305], Loss: 0.0257, Accuracy: 98.44%\nEpoch [26/30], Step [420/1305], Loss: 0.0467, Accuracy: 96.88%\nEpoch [26/30], Step [450/1305], Loss: 0.0264, Accuracy: 98.44%\nEpoch [26/30], Step [480/1305], Loss: 0.0127, Accuracy: 100.00%\nEpoch [26/30], Step [510/1305], Loss: 0.0742, Accuracy: 98.44%\nEpoch [26/30], Step [540/1305], Loss: 0.0351, Accuracy: 96.88%\nEpoch [26/30], Step [570/1305], Loss: 0.1120, Accuracy: 95.31%\nEpoch [26/30], Step [600/1305], Loss: 0.0377, Accuracy: 96.88%\nEpoch [26/30], Step [630/1305], Loss: 0.0768, Accuracy: 98.44%\nEpoch [26/30], Step [660/1305], Loss: 0.0097, Accuracy: 100.00%\nEpoch [26/30], Step [690/1305], Loss: 0.0358, Accuracy: 98.44%\nEpoch [26/30], Step [720/1305], Loss: 0.0177, Accuracy: 100.00%\nEpoch [26/30], Step [750/1305], Loss: 0.1213, Accuracy: 96.88%\nEpoch [26/30], Step [780/1305], Loss: 0.0488, Accuracy: 98.44%\nEpoch [26/30], Step [810/1305], Loss: 0.0159, Accuracy: 98.44%\nEpoch [26/30], Step [840/1305], Loss: 0.0241, Accuracy: 98.44%\nEpoch [26/30], Step [870/1305], Loss: 0.0890, Accuracy: 98.44%\nEpoch [26/30], Step [900/1305], Loss: 0.0124, Accuracy: 100.00%\nEpoch [26/30], Step [930/1305], Loss: 0.0461, Accuracy: 96.88%\nEpoch [26/30], Step [960/1305], Loss: 0.0446, Accuracy: 98.44%\nEpoch [26/30], Step [990/1305], Loss: 0.0057, Accuracy: 100.00%\nEpoch [26/30], Step [1020/1305], Loss: 0.0278, Accuracy: 98.44%\nEpoch [26/30], Step [1050/1305], Loss: 0.0536, Accuracy: 96.88%\nEpoch [26/30], Step [1080/1305], Loss: 0.0165, Accuracy: 100.00%\nEpoch [26/30], Step [1110/1305], Loss: 0.0022, Accuracy: 100.00%\nEpoch [26/30], Step [1140/1305], Loss: 0.0788, Accuracy: 98.44%\nEpoch [26/30], Step [1170/1305], Loss: 0.0572, Accuracy: 98.44%\nEpoch [26/30], Step [1200/1305], Loss: 0.0151, Accuracy: 100.00%\nEpoch [26/30], Step [1230/1305], Loss: 0.0198, Accuracy: 100.00%\nEpoch [26/30], Step [1260/1305], Loss: 0.0330, Accuracy: 98.44%\nEpoch [26/30], Step [1290/1305], Loss: 0.0730, Accuracy: 98.44%\nStart validation #26\nValidation #26  Accuracy: 100.00%  Average Loss: 0.0133\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"994e49a5912843c7a2ee1af18a9a8f70"}},"metadata":{}},{"name":"stdout","text":"Epoch [27/30], Step [30/1305], Loss: 0.0315, Accuracy: 98.44%\nEpoch [27/30], Step [60/1305], Loss: 0.0515, Accuracy: 98.44%\nEpoch [27/30], Step [90/1305], Loss: 0.0229, Accuracy: 98.44%\nEpoch [27/30], Step [120/1305], Loss: 0.1311, Accuracy: 98.44%\nEpoch [27/30], Step [150/1305], Loss: 0.0066, Accuracy: 100.00%\nEpoch [27/30], Step [180/1305], Loss: 0.0065, Accuracy: 100.00%\nEpoch [27/30], Step [210/1305], Loss: 0.0083, Accuracy: 100.00%\nEpoch [27/30], Step [240/1305], Loss: 0.0376, Accuracy: 98.44%\nEpoch [27/30], Step [270/1305], Loss: 0.0680, Accuracy: 96.88%\nEpoch [27/30], Step [300/1305], Loss: 0.0142, Accuracy: 100.00%\nEpoch [27/30], Step [330/1305], Loss: 0.0117, Accuracy: 100.00%\nEpoch [27/30], Step [360/1305], Loss: 0.0498, Accuracy: 96.88%\nEpoch [27/30], Step [390/1305], Loss: 0.0263, Accuracy: 98.44%\nEpoch [27/30], Step [420/1305], Loss: 0.0191, Accuracy: 98.44%\nEpoch [27/30], Step [450/1305], Loss: 0.0014, Accuracy: 100.00%\nEpoch [27/30], Step [480/1305], Loss: 0.1033, Accuracy: 96.88%\nEpoch [27/30], Step [510/1305], Loss: 0.0066, Accuracy: 100.00%\nEpoch [27/30], Step [540/1305], Loss: 0.0482, Accuracy: 98.44%\nEpoch [27/30], Step [570/1305], Loss: 0.0219, Accuracy: 100.00%\nEpoch [27/30], Step [600/1305], Loss: 0.0430, Accuracy: 96.88%\nEpoch [27/30], Step [630/1305], Loss: 0.0635, Accuracy: 96.88%\nEpoch [27/30], Step [660/1305], Loss: 0.0477, Accuracy: 98.44%\nEpoch [27/30], Step [690/1305], Loss: 0.0226, Accuracy: 98.44%\nEpoch [27/30], Step [720/1305], Loss: 0.0263, Accuracy: 98.44%\nEpoch [27/30], Step [750/1305], Loss: 0.0320, Accuracy: 100.00%\nEpoch [27/30], Step [780/1305], Loss: 0.0423, Accuracy: 98.44%\nEpoch [27/30], Step [810/1305], Loss: 0.0717, Accuracy: 98.44%\nEpoch [27/30], Step [840/1305], Loss: 0.0077, Accuracy: 100.00%\nEpoch [27/30], Step [870/1305], Loss: 0.0525, Accuracy: 98.44%\nEpoch [27/30], Step [900/1305], Loss: 0.0458, Accuracy: 96.88%\nEpoch [27/30], Step [930/1305], Loss: 0.0057, Accuracy: 100.00%\nEpoch [27/30], Step [960/1305], Loss: 0.1214, Accuracy: 95.31%\nEpoch [27/30], Step [990/1305], Loss: 0.0328, Accuracy: 98.44%\nEpoch [27/30], Step [1020/1305], Loss: 0.0453, Accuracy: 98.44%\nEpoch [27/30], Step [1050/1305], Loss: 0.0447, Accuracy: 98.44%\nEpoch [27/30], Step [1080/1305], Loss: 0.0443, Accuracy: 98.44%\nEpoch [27/30], Step [1110/1305], Loss: 0.0522, Accuracy: 96.88%\nEpoch [27/30], Step [1140/1305], Loss: 0.1745, Accuracy: 93.75%\nEpoch [27/30], Step [1170/1305], Loss: 0.0145, Accuracy: 100.00%\nEpoch [27/30], Step [1200/1305], Loss: 0.0350, Accuracy: 98.44%\nEpoch [27/30], Step [1230/1305], Loss: 0.0118, Accuracy: 100.00%\nEpoch [27/30], Step [1260/1305], Loss: 0.0320, Accuracy: 98.44%\nEpoch [27/30], Step [1290/1305], Loss: 0.0684, Accuracy: 98.44%\nStart validation #27\nValidation #27  Accuracy: 96.88%  Average Loss: 0.0788\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90fef915481f43408d087a59a315cb31"}},"metadata":{}},{"name":"stdout","text":"Epoch [28/30], Step [30/1305], Loss: 0.0444, Accuracy: 98.44%\nEpoch [28/30], Step [60/1305], Loss: 0.0190, Accuracy: 98.44%\nEpoch [28/30], Step [90/1305], Loss: 0.0293, Accuracy: 98.44%\nEpoch [28/30], Step [120/1305], Loss: 0.0277, Accuracy: 100.00%\nEpoch [28/30], Step [150/1305], Loss: 0.0245, Accuracy: 98.44%\nEpoch [28/30], Step [180/1305], Loss: 0.1550, Accuracy: 95.31%\nEpoch [28/30], Step [210/1305], Loss: 0.0063, Accuracy: 100.00%\nEpoch [28/30], Step [240/1305], Loss: 0.0152, Accuracy: 100.00%\nEpoch [28/30], Step [270/1305], Loss: 0.0034, Accuracy: 100.00%\nEpoch [28/30], Step [300/1305], Loss: 0.1883, Accuracy: 93.75%\nEpoch [28/30], Step [330/1305], Loss: 0.1089, Accuracy: 95.31%\nEpoch [28/30], Step [360/1305], Loss: 0.0298, Accuracy: 98.44%\nEpoch [28/30], Step [390/1305], Loss: 0.0537, Accuracy: 96.88%\nEpoch [28/30], Step [420/1305], Loss: 0.0016, Accuracy: 100.00%\nEpoch [28/30], Step [450/1305], Loss: 0.0209, Accuracy: 100.00%\nEpoch [28/30], Step [480/1305], Loss: 0.0114, Accuracy: 100.00%\nEpoch [28/30], Step [510/1305], Loss: 0.1074, Accuracy: 93.75%\nEpoch [28/30], Step [540/1305], Loss: 0.0094, Accuracy: 100.00%\nEpoch [28/30], Step [570/1305], Loss: 0.0180, Accuracy: 100.00%\nEpoch [28/30], Step [600/1305], Loss: 0.0197, Accuracy: 100.00%\nEpoch [28/30], Step [630/1305], Loss: 0.1266, Accuracy: 96.88%\nEpoch [28/30], Step [660/1305], Loss: 0.0053, Accuracy: 100.00%\nEpoch [28/30], Step [690/1305], Loss: 0.0251, Accuracy: 98.44%\nEpoch [28/30], Step [720/1305], Loss: 0.1975, Accuracy: 95.31%\nEpoch [28/30], Step [750/1305], Loss: 0.0326, Accuracy: 100.00%\nEpoch [28/30], Step [780/1305], Loss: 0.0604, Accuracy: 95.31%\nEpoch [28/30], Step [810/1305], Loss: 0.0428, Accuracy: 96.88%\nEpoch [28/30], Step [840/1305], Loss: 0.0034, Accuracy: 100.00%\nEpoch [28/30], Step [870/1305], Loss: 0.0363, Accuracy: 98.44%\nEpoch [28/30], Step [900/1305], Loss: 0.0424, Accuracy: 98.44%\nEpoch [28/30], Step [930/1305], Loss: 0.0662, Accuracy: 96.88%\nEpoch [28/30], Step [960/1305], Loss: 0.0987, Accuracy: 96.88%\nEpoch [28/30], Step [990/1305], Loss: 0.0122, Accuracy: 100.00%\nEpoch [28/30], Step [1020/1305], Loss: 0.0027, Accuracy: 100.00%\nEpoch [28/30], Step [1050/1305], Loss: 0.0057, Accuracy: 100.00%\nEpoch [28/30], Step [1080/1305], Loss: 0.0150, Accuracy: 100.00%\nEpoch [28/30], Step [1110/1305], Loss: 0.0711, Accuracy: 98.44%\nEpoch [28/30], Step [1140/1305], Loss: 0.0473, Accuracy: 96.88%\nEpoch [28/30], Step [1170/1305], Loss: 0.0076, Accuracy: 100.00%\nEpoch [28/30], Step [1200/1305], Loss: 0.0054, Accuracy: 100.00%\nEpoch [28/30], Step [1230/1305], Loss: 0.0284, Accuracy: 100.00%\nEpoch [28/30], Step [1260/1305], Loss: 0.0098, Accuracy: 100.00%\nEpoch [28/30], Step [1290/1305], Loss: 0.0183, Accuracy: 98.44%\nStart validation #28\nValidation #28  Accuracy: 100.00%  Average Loss: 0.0224\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8462c24bd4f645cb9547da1b4aa8251c"}},"metadata":{}},{"name":"stdout","text":"Epoch [29/30], Step [30/1305], Loss: 0.0080, Accuracy: 100.00%\nEpoch [29/30], Step [60/1305], Loss: 0.1101, Accuracy: 95.31%\nEpoch [29/30], Step [90/1305], Loss: 0.0133, Accuracy: 100.00%\nEpoch [29/30], Step [120/1305], Loss: 0.0449, Accuracy: 98.44%\nEpoch [29/30], Step [150/1305], Loss: 0.0390, Accuracy: 98.44%\nEpoch [29/30], Step [180/1305], Loss: 0.0157, Accuracy: 98.44%\nEpoch [29/30], Step [210/1305], Loss: 0.0358, Accuracy: 98.44%\nEpoch [29/30], Step [240/1305], Loss: 0.0471, Accuracy: 96.88%\nEpoch [29/30], Step [270/1305], Loss: 0.0209, Accuracy: 100.00%\nEpoch [29/30], Step [300/1305], Loss: 0.0056, Accuracy: 100.00%\nEpoch [29/30], Step [330/1305], Loss: 0.0463, Accuracy: 98.44%\nEpoch [29/30], Step [360/1305], Loss: 0.0151, Accuracy: 98.44%\nEpoch [29/30], Step [390/1305], Loss: 0.0091, Accuracy: 100.00%\nEpoch [29/30], Step [420/1305], Loss: 0.0671, Accuracy: 96.88%\nEpoch [29/30], Step [450/1305], Loss: 0.0498, Accuracy: 96.88%\nEpoch [29/30], Step [480/1305], Loss: 0.0080, Accuracy: 100.00%\nEpoch [29/30], Step [510/1305], Loss: 0.0219, Accuracy: 100.00%\nEpoch [29/30], Step [540/1305], Loss: 0.0383, Accuracy: 98.44%\nEpoch [29/30], Step [570/1305], Loss: 0.0491, Accuracy: 98.44%\nEpoch [29/30], Step [600/1305], Loss: 0.0635, Accuracy: 96.88%\nEpoch [29/30], Step [630/1305], Loss: 0.0228, Accuracy: 98.44%\nEpoch [29/30], Step [660/1305], Loss: 0.0341, Accuracy: 98.44%\nEpoch [29/30], Step [690/1305], Loss: 0.0404, Accuracy: 96.88%\nEpoch [29/30], Step [720/1305], Loss: 0.0275, Accuracy: 98.44%\nEpoch [29/30], Step [750/1305], Loss: 0.0290, Accuracy: 98.44%\nEpoch [29/30], Step [780/1305], Loss: 0.0108, Accuracy: 100.00%\nEpoch [29/30], Step [810/1305], Loss: 0.0035, Accuracy: 100.00%\nEpoch [29/30], Step [840/1305], Loss: 0.0053, Accuracy: 100.00%\nEpoch [29/30], Step [870/1305], Loss: 0.0814, Accuracy: 96.88%\nEpoch [29/30], Step [900/1305], Loss: 0.0932, Accuracy: 96.88%\nEpoch [29/30], Step [930/1305], Loss: 0.0171, Accuracy: 98.44%\nEpoch [29/30], Step [960/1305], Loss: 0.0389, Accuracy: 98.44%\nEpoch [29/30], Step [990/1305], Loss: 0.0519, Accuracy: 96.88%\nEpoch [29/30], Step [1020/1305], Loss: 0.0495, Accuracy: 98.44%\nEpoch [29/30], Step [1050/1305], Loss: 0.0260, Accuracy: 100.00%\nEpoch [29/30], Step [1080/1305], Loss: 0.0764, Accuracy: 96.88%\nEpoch [29/30], Step [1110/1305], Loss: 0.0120, Accuracy: 100.00%\nEpoch [29/30], Step [1140/1305], Loss: 0.0286, Accuracy: 98.44%\nEpoch [29/30], Step [1170/1305], Loss: 0.0394, Accuracy: 98.44%\nEpoch [29/30], Step [1200/1305], Loss: 0.0034, Accuracy: 100.00%\nEpoch [29/30], Step [1230/1305], Loss: 0.0617, Accuracy: 98.44%\nEpoch [29/30], Step [1260/1305], Loss: 0.0264, Accuracy: 100.00%\nEpoch [29/30], Step [1290/1305], Loss: 0.0219, Accuracy: 100.00%\nStart validation #29\nValidation #29  Accuracy: 100.00%  Average Loss: 0.0057\nBest performance at epoch: 29\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef33cf750e64249a5cd4dc47175295d"}},"metadata":{}},{"name":"stdout","text":"Epoch [30/30], Step [30/1305], Loss: 0.0137, Accuracy: 100.00%\nEpoch [30/30], Step [60/1305], Loss: 0.0281, Accuracy: 100.00%\nEpoch [30/30], Step [90/1305], Loss: 0.0606, Accuracy: 96.88%\nEpoch [30/30], Step [120/1305], Loss: 0.0143, Accuracy: 100.00%\nEpoch [30/30], Step [150/1305], Loss: 0.0170, Accuracy: 100.00%\nEpoch [30/30], Step [180/1305], Loss: 0.0148, Accuracy: 100.00%\nEpoch [30/30], Step [210/1305], Loss: 0.0441, Accuracy: 98.44%\nEpoch [30/30], Step [240/1305], Loss: 0.0062, Accuracy: 100.00%\nEpoch [30/30], Step [270/1305], Loss: 0.0958, Accuracy: 96.88%\nEpoch [30/30], Step [300/1305], Loss: 0.0052, Accuracy: 100.00%\nEpoch [30/30], Step [330/1305], Loss: 0.0032, Accuracy: 100.00%\nEpoch [30/30], Step [360/1305], Loss: 0.0171, Accuracy: 98.44%\nEpoch [30/30], Step [390/1305], Loss: 0.1596, Accuracy: 95.31%\nEpoch [30/30], Step [420/1305], Loss: 0.0202, Accuracy: 100.00%\nEpoch [30/30], Step [450/1305], Loss: 0.0197, Accuracy: 100.00%\nEpoch [30/30], Step [480/1305], Loss: 0.0999, Accuracy: 96.88%\nEpoch [30/30], Step [510/1305], Loss: 0.0243, Accuracy: 100.00%\nEpoch [30/30], Step [540/1305], Loss: 0.0419, Accuracy: 98.44%\nEpoch [30/30], Step [570/1305], Loss: 0.0159, Accuracy: 100.00%\nEpoch [30/30], Step [600/1305], Loss: 0.0330, Accuracy: 98.44%\nEpoch [30/30], Step [630/1305], Loss: 0.0179, Accuracy: 100.00%\nEpoch [30/30], Step [660/1305], Loss: 0.0085, Accuracy: 100.00%\nEpoch [30/30], Step [690/1305], Loss: 0.0151, Accuracy: 100.00%\nEpoch [30/30], Step [720/1305], Loss: 0.0151, Accuracy: 100.00%\nEpoch [30/30], Step [750/1305], Loss: 0.0323, Accuracy: 98.44%\nEpoch [30/30], Step [780/1305], Loss: 0.0301, Accuracy: 98.44%\nEpoch [30/30], Step [810/1305], Loss: 0.0202, Accuracy: 100.00%\nEpoch [30/30], Step [840/1305], Loss: 0.0134, Accuracy: 100.00%\nEpoch [30/30], Step [870/1305], Loss: 0.0367, Accuracy: 98.44%\nEpoch [30/30], Step [900/1305], Loss: 0.0283, Accuracy: 98.44%\nEpoch [30/30], Step [930/1305], Loss: 0.0590, Accuracy: 96.88%\nEpoch [30/30], Step [960/1305], Loss: 0.0215, Accuracy: 100.00%\nEpoch [30/30], Step [990/1305], Loss: 0.0034, Accuracy: 100.00%\nEpoch [30/30], Step [1020/1305], Loss: 0.0018, Accuracy: 100.00%\nEpoch [30/30], Step [1050/1305], Loss: 0.0213, Accuracy: 100.00%\nEpoch [30/30], Step [1080/1305], Loss: 0.0197, Accuracy: 98.44%\nEpoch [30/30], Step [1110/1305], Loss: 0.0780, Accuracy: 96.88%\nEpoch [30/30], Step [1140/1305], Loss: 0.0558, Accuracy: 98.44%\nEpoch [30/30], Step [1170/1305], Loss: 0.0468, Accuracy: 96.88%\nEpoch [30/30], Step [1200/1305], Loss: 0.0079, Accuracy: 100.00%\nEpoch [30/30], Step [1230/1305], Loss: 0.0213, Accuracy: 98.44%\nEpoch [30/30], Step [1260/1305], Loss: 0.0026, Accuracy: 100.00%\nEpoch [30/30], Step [1290/1305], Loss: 0.0238, Accuracy: 100.00%\nStart validation #30\nValidation #30  Accuracy: 100.00%  Average Loss: 0.0047\nBest performance at epoch: 30\nSave model in ./saved\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.ylabel('Loss')\nplt.plot(train_loss_list, label = 'Train')\nplt.plot(val_loss_list, label = 'Validation')\nplt.subplot(1,2,2)\nplt.ylabel('Accuracy')\nplt.plot(train_accuracy_list, label = 'Train')\nplt.plot(val_accuracy_list, label = 'Validation')\n# plt.savefig('graph.png',facecolor = 'w')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir='./logs/logs_transfer'","metadata":{"execution":{"iopub.status.busy":"2024-05-03T05:44:35.268238Z","iopub.execute_input":"2024-05-03T05:44:35.268604Z","iopub.status.idle":"2024-05-03T05:44:41.802281Z","shell.execute_reply.started":"2024-05-03T05:44:35.268575Z","shell.execute_reply":"2024-05-03T05:44:41.801417Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-26c168ee3c13268e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-26c168ee3c13268e\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Zip files**","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\nshutil.make_archive('OUTPUT', 'zip', '/kaggle/working/')\nFileLink(r'OUTPUT.zip') # 여기에 zip파일 이름 넣기","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:20:50.570061Z","iopub.execute_input":"2024-05-03T08:20:50.570662Z","iopub.status.idle":"2024-05-03T08:22:24.206581Z","shell.execute_reply.started":"2024-05-03T08:20:50.570616Z","shell.execute_reply":"2024-05-03T08:22:24.205703Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/OUTPUT.zip","text/html":"<a href='OUTPUT.zip' target='_blank'>OUTPUT.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'OUTPUT.zip') # 여기에 zip파일 이름 넣기","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:34:08.821914Z","iopub.status.idle":"2024-05-03T08:34:08.822248Z","shell.execute_reply.started":"2024-05-03T08:34:08.822090Z","shell.execute_reply":"2024-05-03T08:34:08.822103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\nshutil.make_archive('OUTPUT1', 'zip', '/kaggle/working/')\nFileLink(r'OUTPUT1.zip') # 여기에 zip파일 이름 넣기","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:32:56.302135Z","iopub.execute_input":"2024-05-03T08:32:56.302498Z","iopub.status.idle":"2024-05-03T08:34:08.820892Z","shell.execute_reply.started":"2024-05-03T08:32:56.302468Z","shell.execute_reply":"2024-05-03T08:34:08.819608Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileLink\n\u001b[0;32m----> 3\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOUTPUT1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m FileLink(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOUTPUT1.zip\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# 여기에 zip파일 이름 넣기\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1124\u001b[0m, in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             os\u001b[38;5;241m.\u001b[39mchdir(root_dir)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1009\u001b[0m, in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger, owner, group, root_dir)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[1;32m   1008\u001b[0m     arcname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(arcdirpath, name)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[43mzf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marcname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madding \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1776\u001b[0m, in \u001b[0;36mZipFile.write\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1775\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[0;32m-> 1776\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:195\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    193\u001b[0m fdst_write \u001b[38;5;241m=\u001b[39m fdst\u001b[38;5;241m.\u001b[39mwrite\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buf:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'OUTPUT1.zip') # 여기에 zip파일 이름 넣기","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:34:15.091358Z","iopub.execute_input":"2024-05-03T08:34:15.091729Z","iopub.status.idle":"2024-05-03T08:34:15.098093Z","shell.execute_reply.started":"2024-05-03T08:34:15.091698Z","shell.execute_reply":"2024-05-03T08:34:15.097318Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/OUTPUT1.zip","text/html":"<a href='OUTPUT1.zip' target='_blank'>OUTPUT1.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('OUTPUT2', 'zip', '/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:37:02.593122Z","iopub.status.idle":"2024-05-03T08:37:02.593553Z","shell.execute_reply.started":"2024-05-03T08:37:02.593329Z","shell.execute_reply":"2024-05-03T08:37:02.593348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'OUTPUT2.zip') # 여기에 zip파일 이름 넣기","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:44:34.974151Z","iopub.execute_input":"2024-05-03T08:44:34.974754Z","iopub.status.idle":"2024-05-03T08:44:34.980604Z","shell.execute_reply.started":"2024-05-03T08:44:34.974721Z","shell.execute_reply":"2024-05-03T08:44:34.979839Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/OUTPUT2.zip","text/html":"<a href='OUTPUT2.zip' target='_blank'>OUTPUT2.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'/kaggle/working/saved/ckpoint_model_30_100.0%.pt') # 여기에 zip파일 이름 넣기","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:47:53.418073Z","iopub.execute_input":"2024-05-03T08:47:53.418448Z","iopub.status.idle":"2024-05-03T08:47:53.424575Z","shell.execute_reply.started":"2024-05-03T08:47:53.418418Z","shell.execute_reply":"2024-05-03T08:47:53.423741Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/saved/ckpoint_model_30_100.0%.pt","text/html":"<a href='/kaggle/working/saved/ckpoint_model_30_100.0%.pt' target='_blank'>/kaggle/working/saved/ckpoint_model_30_100.0%.pt</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'/kaggle/working/saved/ckpoint_model_20_100.0%.pt') # 여기에 zip파일 이름 넣기","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:48:05.243717Z","iopub.execute_input":"2024-05-03T08:48:05.244451Z","iopub.status.idle":"2024-05-03T08:48:05.250543Z","shell.execute_reply.started":"2024-05-03T08:48:05.244418Z","shell.execute_reply":"2024-05-03T08:48:05.249592Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/saved/ckpoint_model_20_100.0%.pt","text/html":"<a href='/kaggle/working/saved/ckpoint_model_20_100.0%.pt' target='_blank'>/kaggle/working/saved/ckpoint_model_20_100.0%.pt</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}