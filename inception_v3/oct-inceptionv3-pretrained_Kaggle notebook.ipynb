{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23942,"sourceType":"datasetVersion","datasetId":17839}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Package Load","metadata":{}},{"cell_type":"code","source":"import torch\nprint('pytorch version: {}'.format(torch.__version__))\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm.notebook import tqdm\n%matplotlib inline\n\nprint('pytorch version: {}'.format(torch.__version__))\nprint('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장\n\n# 이걸 해줘야 matplotlib 시행 시 에러가 안 남\nimport os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:10:01.535419Z","iopub.execute_input":"2024-05-08T11:10:01.535813Z","iopub.status.idle":"2024-05-08T11:10:01.546296Z","shell.execute_reply.started":"2024-05-08T11:10:01.535787Z","shell.execute_reply":"2024-05-08T11:10:01.545327Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"pytorch version: 2.1.2\npytorch version: 2.1.2\nGPU 사용 가능 여부: True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Hyperparameters","metadata":{}},{"cell_type":"code","source":"batch_size = 64\nnum_epochs = 50\nlearning_rate = 0.001","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:10:01.547470Z","iopub.execute_input":"2024-05-08T11:10:01.547746Z","iopub.status.idle":"2024-05-08T11:10:01.563407Z","shell.execute_reply.started":"2024-05-08T11:10:01.547706Z","shell.execute_reply":"2024-05-08T11:10:01.562642Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Dataloader","metadata":{}},{"cell_type":"code","source":"# For Kaggle notebook\ndata_dir = '/kaggle/input/kermany2018/OCT2017 /'","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:10:02.854584Z","iopub.execute_input":"2024-05-08T11:10:02.855277Z","iopub.status.idle":"2024-05-08T11:10:02.859171Z","shell.execute_reply.started":"2024-05-08T11:10:02.855244Z","shell.execute_reply":"2024-05-08T11:10:02.858289Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class OCTDataset(Dataset):\n    def __init__(self, data_dir, mode, transform=None):\n        self.all_data = sorted(glob.glob(os.path.join(data_dir, mode,'*', '*')))\n        self.transform = transform\n    \n    def __getitem__(self, index):\n        data_path = self.all_data[index]\n        img = Image.open(data_path)\n        if self.transform is not None:\n            img = self.transform(img)\n        img = img.squeeze()\n        img = torch.stack((img, img, img,), dim=0)  # VGG16이 3 channel이라 concat시키기\n        name = os.path.basename(data_path)\n        if name.startswith('NORMAL'):\n            label = 0\n        elif name.startswith('CNV'):\n            label = 1\n        elif name.startswith('DME'):\n            label = 2\n        elif name.startswith('DRUSEN'):\n            label = 3\n        return img, label\n    \n    def __len__(self):\n        length = len(self.all_data)\n        return length\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomRotation(5),\n        transforms.RandomResizedCrop(299, scale=(0.96, 1.0), ratio=(0.95, 1.05)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize(0.1881,0.1850)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize([350]),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(0.1881,0.1850)\n    ])\n}\n# Inception v3는 (3,299,299)를 사용함\n\ntrain_data = OCTDataset(data_dir=data_dir, mode='train', transform=data_transforms['train'])\nval_data = OCTDataset(data_dir=data_dir, mode='val', transform=data_transforms['val'])\ntest_data = OCTDataset(data_dir=data_dir, mode='test', transform=data_transforms['val'])\n\n# For Kaggle: 2 core CPU available\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=2)  # num_worker로 Multi Process Data Loading 구현\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2) # Kaggle CPU = 2 core\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)\n\ntrain_mean = 0.1881\ntrain_std = 0.1850","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:10:06.876971Z","iopub.execute_input":"2024-05-08T11:10:06.877642Z","iopub.status.idle":"2024-05-08T11:10:09.043313Z","shell.execute_reply.started":"2024-05-08T11:10:06.877610Z","shell.execute_reply":"2024-05-08T11:10:09.042504Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Model: Inception V3 Transfer Learning","metadata":{}},{"cell_type":"code","source":"from collections import namedtuple\nInceptionOutputs = namedtuple(\"InceptionOutputs\", [\"logits\", \"aux_logits\"])\n\nclass TransferInceptionV3(nn.Module):\n    def __init__ (self, num_classes):\n        super(TransferInceptionV3, self).__init__()\n        self.inception = torchvision.models.inception_v3(pretrained=True)\n        aux_in_feature = self.inception.AuxLogits.fc.in_features\n        self.inception.AuxLogits.fc = nn.Linear(aux_in_feature, num_classes)\n        final_in_feature = self.inception.fc.in_features\n        self.inception.fc = nn.Linear(final_in_feature, num_classes)\n        \n    def forward(self,x):\n        return self.inception(x)\n\ninception_transfer = TransferInceptionV3(num_classes=4).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:10:16.188110Z","iopub.execute_input":"2024-05-08T11:10:16.188477Z","iopub.status.idle":"2024-05-08T11:10:16.645008Z","shell.execute_reply.started":"2024-05-08T11:10:16.188449Z","shell.execute_reply":"2024-05-08T11:10:16.644195Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"inception_transfer","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-08T11:10:19.984606Z","iopub.execute_input":"2024-05-08T11:10:19.984958Z","iopub.status.idle":"2024-05-08T11:10:19.997233Z","shell.execute_reply.started":"2024-05-08T11:10:19.984932Z","shell.execute_reply":"2024-05-08T11:10:19.996276Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TransferInceptionV3(\n  (inception): Inception3(\n    (Conv2d_1a_3x3): BasicConv2d(\n      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (Conv2d_2a_3x3): BasicConv2d(\n      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (Conv2d_2b_3x3): BasicConv2d(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (Conv2d_3b_1x1): BasicConv2d(\n      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (Conv2d_4a_3x3): BasicConv2d(\n      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (Mixed_5b): InceptionA(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_1): BasicConv2d(\n        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_2): BasicConv2d(\n        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3): BasicConv2d(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_5c): InceptionA(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_1): BasicConv2d(\n        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_2): BasicConv2d(\n        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3): BasicConv2d(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_5d): InceptionA(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_1): BasicConv2d(\n        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_2): BasicConv2d(\n        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3): BasicConv2d(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6a): InceptionB(\n      (branch3x3): BasicConv2d(\n        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3): BasicConv2d(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6b): InceptionC(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_1): BasicConv2d(\n        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_2): BasicConv2d(\n        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_3): BasicConv2d(\n        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_1): BasicConv2d(\n        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_2): BasicConv2d(\n        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_3): BasicConv2d(\n        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_4): BasicConv2d(\n        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_5): BasicConv2d(\n        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6c): InceptionC(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_1): BasicConv2d(\n        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_2): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_3): BasicConv2d(\n        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_1): BasicConv2d(\n        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_2): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_3): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_4): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_5): BasicConv2d(\n        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6d): InceptionC(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_1): BasicConv2d(\n        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_2): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_3): BasicConv2d(\n        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_1): BasicConv2d(\n        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_2): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_3): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_4): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_5): BasicConv2d(\n        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6e): InceptionC(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_3): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_3): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_4): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_5): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (AuxLogits): InceptionAux(\n      (conv0): BasicConv2d(\n        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (conv1): BasicConv2d(\n        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (fc): Linear(in_features=768, out_features=4, bias=True)\n    )\n    (Mixed_7a): InceptionD(\n      (branch3x3_1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2): BasicConv2d(\n        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7x3_1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7x3_2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7x3_3): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7x3_4): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_7b): InceptionE(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_1): BasicConv2d(\n        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2a): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2b): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3a): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3b): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_7c): InceptionE(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_1): BasicConv2d(\n        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2a): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2b): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3a): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3b): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (dropout): Dropout(p=0.5, inplace=False)\n    (fc): Linear(in_features=2048, out_features=4, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Auxiliary logit + 이전 6e inception module (181 ~ 218) / Fc layer + 이전 7b, 7c inception module (237~292)\ncount = 0\nfor param in inception_transfer.inception.parameters():\n    count += 1\n    if (181 <= count and count <= 218):\n        param.requires_grad = True\n    elif (237 <= count and count <= 292):\n        param.requires_grad = True\n    else:\n        param.requires_grad = False\n\nfor name, param in inception_transfer.inception.named_parameters():\n    print(name, param.requires_grad)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-08T11:10:22.722108Z","iopub.execute_input":"2024-05-08T11:10:22.722939Z","iopub.status.idle":"2024-05-08T11:10:22.735440Z","shell.execute_reply.started":"2024-05-08T11:10:22.722902Z","shell.execute_reply":"2024-05-08T11:10:22.734539Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Conv2d_1a_3x3.conv.weight False\nConv2d_1a_3x3.bn.weight False\nConv2d_1a_3x3.bn.bias False\nConv2d_2a_3x3.conv.weight False\nConv2d_2a_3x3.bn.weight False\nConv2d_2a_3x3.bn.bias False\nConv2d_2b_3x3.conv.weight False\nConv2d_2b_3x3.bn.weight False\nConv2d_2b_3x3.bn.bias False\nConv2d_3b_1x1.conv.weight False\nConv2d_3b_1x1.bn.weight False\nConv2d_3b_1x1.bn.bias False\nConv2d_4a_3x3.conv.weight False\nConv2d_4a_3x3.bn.weight False\nConv2d_4a_3x3.bn.bias False\nMixed_5b.branch1x1.conv.weight False\nMixed_5b.branch1x1.bn.weight False\nMixed_5b.branch1x1.bn.bias False\nMixed_5b.branch5x5_1.conv.weight False\nMixed_5b.branch5x5_1.bn.weight False\nMixed_5b.branch5x5_1.bn.bias False\nMixed_5b.branch5x5_2.conv.weight False\nMixed_5b.branch5x5_2.bn.weight False\nMixed_5b.branch5x5_2.bn.bias False\nMixed_5b.branch3x3dbl_1.conv.weight False\nMixed_5b.branch3x3dbl_1.bn.weight False\nMixed_5b.branch3x3dbl_1.bn.bias False\nMixed_5b.branch3x3dbl_2.conv.weight False\nMixed_5b.branch3x3dbl_2.bn.weight False\nMixed_5b.branch3x3dbl_2.bn.bias False\nMixed_5b.branch3x3dbl_3.conv.weight False\nMixed_5b.branch3x3dbl_3.bn.weight False\nMixed_5b.branch3x3dbl_3.bn.bias False\nMixed_5b.branch_pool.conv.weight False\nMixed_5b.branch_pool.bn.weight False\nMixed_5b.branch_pool.bn.bias False\nMixed_5c.branch1x1.conv.weight False\nMixed_5c.branch1x1.bn.weight False\nMixed_5c.branch1x1.bn.bias False\nMixed_5c.branch5x5_1.conv.weight False\nMixed_5c.branch5x5_1.bn.weight False\nMixed_5c.branch5x5_1.bn.bias False\nMixed_5c.branch5x5_2.conv.weight False\nMixed_5c.branch5x5_2.bn.weight False\nMixed_5c.branch5x5_2.bn.bias False\nMixed_5c.branch3x3dbl_1.conv.weight False\nMixed_5c.branch3x3dbl_1.bn.weight False\nMixed_5c.branch3x3dbl_1.bn.bias False\nMixed_5c.branch3x3dbl_2.conv.weight False\nMixed_5c.branch3x3dbl_2.bn.weight False\nMixed_5c.branch3x3dbl_2.bn.bias False\nMixed_5c.branch3x3dbl_3.conv.weight False\nMixed_5c.branch3x3dbl_3.bn.weight False\nMixed_5c.branch3x3dbl_3.bn.bias False\nMixed_5c.branch_pool.conv.weight False\nMixed_5c.branch_pool.bn.weight False\nMixed_5c.branch_pool.bn.bias False\nMixed_5d.branch1x1.conv.weight False\nMixed_5d.branch1x1.bn.weight False\nMixed_5d.branch1x1.bn.bias False\nMixed_5d.branch5x5_1.conv.weight False\nMixed_5d.branch5x5_1.bn.weight False\nMixed_5d.branch5x5_1.bn.bias False\nMixed_5d.branch5x5_2.conv.weight False\nMixed_5d.branch5x5_2.bn.weight False\nMixed_5d.branch5x5_2.bn.bias False\nMixed_5d.branch3x3dbl_1.conv.weight False\nMixed_5d.branch3x3dbl_1.bn.weight False\nMixed_5d.branch3x3dbl_1.bn.bias False\nMixed_5d.branch3x3dbl_2.conv.weight False\nMixed_5d.branch3x3dbl_2.bn.weight False\nMixed_5d.branch3x3dbl_2.bn.bias False\nMixed_5d.branch3x3dbl_3.conv.weight False\nMixed_5d.branch3x3dbl_3.bn.weight False\nMixed_5d.branch3x3dbl_3.bn.bias False\nMixed_5d.branch_pool.conv.weight False\nMixed_5d.branch_pool.bn.weight False\nMixed_5d.branch_pool.bn.bias False\nMixed_6a.branch3x3.conv.weight False\nMixed_6a.branch3x3.bn.weight False\nMixed_6a.branch3x3.bn.bias False\nMixed_6a.branch3x3dbl_1.conv.weight False\nMixed_6a.branch3x3dbl_1.bn.weight False\nMixed_6a.branch3x3dbl_1.bn.bias False\nMixed_6a.branch3x3dbl_2.conv.weight False\nMixed_6a.branch3x3dbl_2.bn.weight False\nMixed_6a.branch3x3dbl_2.bn.bias False\nMixed_6a.branch3x3dbl_3.conv.weight False\nMixed_6a.branch3x3dbl_3.bn.weight False\nMixed_6a.branch3x3dbl_3.bn.bias False\nMixed_6b.branch1x1.conv.weight False\nMixed_6b.branch1x1.bn.weight False\nMixed_6b.branch1x1.bn.bias False\nMixed_6b.branch7x7_1.conv.weight False\nMixed_6b.branch7x7_1.bn.weight False\nMixed_6b.branch7x7_1.bn.bias False\nMixed_6b.branch7x7_2.conv.weight False\nMixed_6b.branch7x7_2.bn.weight False\nMixed_6b.branch7x7_2.bn.bias False\nMixed_6b.branch7x7_3.conv.weight False\nMixed_6b.branch7x7_3.bn.weight False\nMixed_6b.branch7x7_3.bn.bias False\nMixed_6b.branch7x7dbl_1.conv.weight False\nMixed_6b.branch7x7dbl_1.bn.weight False\nMixed_6b.branch7x7dbl_1.bn.bias False\nMixed_6b.branch7x7dbl_2.conv.weight False\nMixed_6b.branch7x7dbl_2.bn.weight False\nMixed_6b.branch7x7dbl_2.bn.bias False\nMixed_6b.branch7x7dbl_3.conv.weight False\nMixed_6b.branch7x7dbl_3.bn.weight False\nMixed_6b.branch7x7dbl_3.bn.bias False\nMixed_6b.branch7x7dbl_4.conv.weight False\nMixed_6b.branch7x7dbl_4.bn.weight False\nMixed_6b.branch7x7dbl_4.bn.bias False\nMixed_6b.branch7x7dbl_5.conv.weight False\nMixed_6b.branch7x7dbl_5.bn.weight False\nMixed_6b.branch7x7dbl_5.bn.bias False\nMixed_6b.branch_pool.conv.weight False\nMixed_6b.branch_pool.bn.weight False\nMixed_6b.branch_pool.bn.bias False\nMixed_6c.branch1x1.conv.weight False\nMixed_6c.branch1x1.bn.weight False\nMixed_6c.branch1x1.bn.bias False\nMixed_6c.branch7x7_1.conv.weight False\nMixed_6c.branch7x7_1.bn.weight False\nMixed_6c.branch7x7_1.bn.bias False\nMixed_6c.branch7x7_2.conv.weight False\nMixed_6c.branch7x7_2.bn.weight False\nMixed_6c.branch7x7_2.bn.bias False\nMixed_6c.branch7x7_3.conv.weight False\nMixed_6c.branch7x7_3.bn.weight False\nMixed_6c.branch7x7_3.bn.bias False\nMixed_6c.branch7x7dbl_1.conv.weight False\nMixed_6c.branch7x7dbl_1.bn.weight False\nMixed_6c.branch7x7dbl_1.bn.bias False\nMixed_6c.branch7x7dbl_2.conv.weight False\nMixed_6c.branch7x7dbl_2.bn.weight False\nMixed_6c.branch7x7dbl_2.bn.bias False\nMixed_6c.branch7x7dbl_3.conv.weight False\nMixed_6c.branch7x7dbl_3.bn.weight False\nMixed_6c.branch7x7dbl_3.bn.bias False\nMixed_6c.branch7x7dbl_4.conv.weight False\nMixed_6c.branch7x7dbl_4.bn.weight False\nMixed_6c.branch7x7dbl_4.bn.bias False\nMixed_6c.branch7x7dbl_5.conv.weight False\nMixed_6c.branch7x7dbl_5.bn.weight False\nMixed_6c.branch7x7dbl_5.bn.bias False\nMixed_6c.branch_pool.conv.weight False\nMixed_6c.branch_pool.bn.weight False\nMixed_6c.branch_pool.bn.bias False\nMixed_6d.branch1x1.conv.weight False\nMixed_6d.branch1x1.bn.weight False\nMixed_6d.branch1x1.bn.bias False\nMixed_6d.branch7x7_1.conv.weight False\nMixed_6d.branch7x7_1.bn.weight False\nMixed_6d.branch7x7_1.bn.bias False\nMixed_6d.branch7x7_2.conv.weight False\nMixed_6d.branch7x7_2.bn.weight False\nMixed_6d.branch7x7_2.bn.bias False\nMixed_6d.branch7x7_3.conv.weight False\nMixed_6d.branch7x7_3.bn.weight False\nMixed_6d.branch7x7_3.bn.bias False\nMixed_6d.branch7x7dbl_1.conv.weight False\nMixed_6d.branch7x7dbl_1.bn.weight False\nMixed_6d.branch7x7dbl_1.bn.bias False\nMixed_6d.branch7x7dbl_2.conv.weight False\nMixed_6d.branch7x7dbl_2.bn.weight False\nMixed_6d.branch7x7dbl_2.bn.bias False\nMixed_6d.branch7x7dbl_3.conv.weight False\nMixed_6d.branch7x7dbl_3.bn.weight False\nMixed_6d.branch7x7dbl_3.bn.bias False\nMixed_6d.branch7x7dbl_4.conv.weight False\nMixed_6d.branch7x7dbl_4.bn.weight False\nMixed_6d.branch7x7dbl_4.bn.bias False\nMixed_6d.branch7x7dbl_5.conv.weight False\nMixed_6d.branch7x7dbl_5.bn.weight False\nMixed_6d.branch7x7dbl_5.bn.bias False\nMixed_6d.branch_pool.conv.weight False\nMixed_6d.branch_pool.bn.weight False\nMixed_6d.branch_pool.bn.bias False\nMixed_6e.branch1x1.conv.weight True\nMixed_6e.branch1x1.bn.weight True\nMixed_6e.branch1x1.bn.bias True\nMixed_6e.branch7x7_1.conv.weight True\nMixed_6e.branch7x7_1.bn.weight True\nMixed_6e.branch7x7_1.bn.bias True\nMixed_6e.branch7x7_2.conv.weight True\nMixed_6e.branch7x7_2.bn.weight True\nMixed_6e.branch7x7_2.bn.bias True\nMixed_6e.branch7x7_3.conv.weight True\nMixed_6e.branch7x7_3.bn.weight True\nMixed_6e.branch7x7_3.bn.bias True\nMixed_6e.branch7x7dbl_1.conv.weight True\nMixed_6e.branch7x7dbl_1.bn.weight True\nMixed_6e.branch7x7dbl_1.bn.bias True\nMixed_6e.branch7x7dbl_2.conv.weight True\nMixed_6e.branch7x7dbl_2.bn.weight True\nMixed_6e.branch7x7dbl_2.bn.bias True\nMixed_6e.branch7x7dbl_3.conv.weight True\nMixed_6e.branch7x7dbl_3.bn.weight True\nMixed_6e.branch7x7dbl_3.bn.bias True\nMixed_6e.branch7x7dbl_4.conv.weight True\nMixed_6e.branch7x7dbl_4.bn.weight True\nMixed_6e.branch7x7dbl_4.bn.bias True\nMixed_6e.branch7x7dbl_5.conv.weight True\nMixed_6e.branch7x7dbl_5.bn.weight True\nMixed_6e.branch7x7dbl_5.bn.bias True\nMixed_6e.branch_pool.conv.weight True\nMixed_6e.branch_pool.bn.weight True\nMixed_6e.branch_pool.bn.bias True\nAuxLogits.conv0.conv.weight True\nAuxLogits.conv0.bn.weight True\nAuxLogits.conv0.bn.bias True\nAuxLogits.conv1.conv.weight True\nAuxLogits.conv1.bn.weight True\nAuxLogits.conv1.bn.bias True\nAuxLogits.fc.weight True\nAuxLogits.fc.bias True\nMixed_7a.branch3x3_1.conv.weight False\nMixed_7a.branch3x3_1.bn.weight False\nMixed_7a.branch3x3_1.bn.bias False\nMixed_7a.branch3x3_2.conv.weight False\nMixed_7a.branch3x3_2.bn.weight False\nMixed_7a.branch3x3_2.bn.bias False\nMixed_7a.branch7x7x3_1.conv.weight False\nMixed_7a.branch7x7x3_1.bn.weight False\nMixed_7a.branch7x7x3_1.bn.bias False\nMixed_7a.branch7x7x3_2.conv.weight False\nMixed_7a.branch7x7x3_2.bn.weight False\nMixed_7a.branch7x7x3_2.bn.bias False\nMixed_7a.branch7x7x3_3.conv.weight False\nMixed_7a.branch7x7x3_3.bn.weight False\nMixed_7a.branch7x7x3_3.bn.bias False\nMixed_7a.branch7x7x3_4.conv.weight False\nMixed_7a.branch7x7x3_4.bn.weight False\nMixed_7a.branch7x7x3_4.bn.bias False\nMixed_7b.branch1x1.conv.weight True\nMixed_7b.branch1x1.bn.weight True\nMixed_7b.branch1x1.bn.bias True\nMixed_7b.branch3x3_1.conv.weight True\nMixed_7b.branch3x3_1.bn.weight True\nMixed_7b.branch3x3_1.bn.bias True\nMixed_7b.branch3x3_2a.conv.weight True\nMixed_7b.branch3x3_2a.bn.weight True\nMixed_7b.branch3x3_2a.bn.bias True\nMixed_7b.branch3x3_2b.conv.weight True\nMixed_7b.branch3x3_2b.bn.weight True\nMixed_7b.branch3x3_2b.bn.bias True\nMixed_7b.branch3x3dbl_1.conv.weight True\nMixed_7b.branch3x3dbl_1.bn.weight True\nMixed_7b.branch3x3dbl_1.bn.bias True\nMixed_7b.branch3x3dbl_2.conv.weight True\nMixed_7b.branch3x3dbl_2.bn.weight True\nMixed_7b.branch3x3dbl_2.bn.bias True\nMixed_7b.branch3x3dbl_3a.conv.weight True\nMixed_7b.branch3x3dbl_3a.bn.weight True\nMixed_7b.branch3x3dbl_3a.bn.bias True\nMixed_7b.branch3x3dbl_3b.conv.weight True\nMixed_7b.branch3x3dbl_3b.bn.weight True\nMixed_7b.branch3x3dbl_3b.bn.bias True\nMixed_7b.branch_pool.conv.weight True\nMixed_7b.branch_pool.bn.weight True\nMixed_7b.branch_pool.bn.bias True\nMixed_7c.branch1x1.conv.weight True\nMixed_7c.branch1x1.bn.weight True\nMixed_7c.branch1x1.bn.bias True\nMixed_7c.branch3x3_1.conv.weight True\nMixed_7c.branch3x3_1.bn.weight True\nMixed_7c.branch3x3_1.bn.bias True\nMixed_7c.branch3x3_2a.conv.weight True\nMixed_7c.branch3x3_2a.bn.weight True\nMixed_7c.branch3x3_2a.bn.bias True\nMixed_7c.branch3x3_2b.conv.weight True\nMixed_7c.branch3x3_2b.bn.weight True\nMixed_7c.branch3x3_2b.bn.bias True\nMixed_7c.branch3x3dbl_1.conv.weight True\nMixed_7c.branch3x3dbl_1.bn.weight True\nMixed_7c.branch3x3dbl_1.bn.bias True\nMixed_7c.branch3x3dbl_2.conv.weight True\nMixed_7c.branch3x3dbl_2.bn.weight True\nMixed_7c.branch3x3dbl_2.bn.bias True\nMixed_7c.branch3x3dbl_3a.conv.weight True\nMixed_7c.branch3x3dbl_3a.bn.weight True\nMixed_7c.branch3x3dbl_3a.bn.bias True\nMixed_7c.branch3x3dbl_3b.conv.weight True\nMixed_7c.branch3x3dbl_3b.bn.weight True\nMixed_7c.branch3x3dbl_3b.bn.bias True\nMixed_7c.branch_pool.conv.weight True\nMixed_7c.branch_pool.bn.weight True\nMixed_7c.branch_pool.bn.bias True\nfc.weight True\nfc.bias True\n","output_type":"stream"}]},{"cell_type":"code","source":"# 7b inception module의 Conv layer를 다시 initialization\nname_list=[]\nfor name, param in inception_transfer.inception.Mixed_7b.named_parameters():\n    name_list = name.split('.')\n    if name_list[1]=='conv':\n        if name_list[2]=='weight':\n            print(name)\n            nn.init.xavier_uniform_(param)\n            print(name+'의 conv filter initialization setting 완료')\n            print()\n\n# 7c inception module의 Conv layer를 다시 initialization\nname_list=[]\nfor name, param in inception_transfer.inception.Mixed_7c.named_parameters():\n    name_list = name.split('.')\n    if name_list[1]=='conv':\n        if name_list[2]=='weight':\n            print(name)\n            nn.init.xavier_uniform_(param)\n            print(name+'의 conv filter initialization setting 완료')\n            print()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-08T11:10:24.594775Z","iopub.execute_input":"2024-05-08T11:10:24.595128Z","iopub.status.idle":"2024-05-08T11:10:24.613481Z","shell.execute_reply.started":"2024-05-08T11:10:24.595104Z","shell.execute_reply":"2024-05-08T11:10:24.612435Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"branch1x1.conv.weight\nbranch1x1.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3_1.conv.weight\nbranch3x3_1.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3_2a.conv.weight\nbranch3x3_2a.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3_2b.conv.weight\nbranch3x3_2b.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3dbl_1.conv.weight\nbranch3x3dbl_1.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3dbl_2.conv.weight\nbranch3x3dbl_2.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3dbl_3a.conv.weight\nbranch3x3dbl_3a.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3dbl_3b.conv.weight\nbranch3x3dbl_3b.conv.weight의 conv filter initialization setting 완료\n\nbranch_pool.conv.weight\nbranch_pool.conv.weight의 conv filter initialization setting 완료\n\nbranch1x1.conv.weight\nbranch1x1.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3_1.conv.weight\nbranch3x3_1.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3_2a.conv.weight\nbranch3x3_2a.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3_2b.conv.weight\nbranch3x3_2b.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3dbl_1.conv.weight\nbranch3x3dbl_1.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3dbl_2.conv.weight\nbranch3x3dbl_2.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3dbl_3a.conv.weight\nbranch3x3dbl_3a.conv.weight의 conv filter initialization setting 완료\n\nbranch3x3dbl_3b.conv.weight\nbranch3x3dbl_3b.conv.weight의 conv filter initialization setting 완료\n\nbranch_pool.conv.weight\nbranch_pool.conv.weight의 conv filter initialization setting 완료\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# 7b, 7c inception module의 batch normalization gamma, beta initialization\n# Residual block이 없으니 모두 1로 initialization, beta는 0으로 initialization\nname_list=[]\nfor name, param in inception_transfer.inception.Mixed_7b.named_parameters():\n    name_list = name.split('.')\n    if name_list[1]=='bn':\n        if name_list[2]=='weight':\n            print(name)\n            nn.init.ones_(param)\n            print(name+'의 gamma one setting 완료')\n            print()\n        elif name_list[2]=='bias':\n            print(name)\n            nn.init.zeros_(param)\n            print(name+'의 beta zero setting 완료')\n            print()\n\nname_list=[]\nfor name, param in inception_transfer.inception.Mixed_7c.named_parameters():\n    name_list = name.split('.')\n    if name_list[1]=='bn':\n        if name_list[2]=='weight':\n            print(name)\n            nn.init.ones_(param)\n            print(name+'의 gamma one setting 완료')\n            print()\n        elif name_list[2]=='bias':\n            print(name)\n            nn.init.zeros_(param)\n            print(name+'의 beta zero setting 완료')\n            print()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-08T11:10:26.840954Z","iopub.execute_input":"2024-05-08T11:10:26.841753Z","iopub.status.idle":"2024-05-08T11:10:26.869589Z","shell.execute_reply.started":"2024-05-08T11:10:26.841707Z","shell.execute_reply":"2024-05-08T11:10:26.868589Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"branch1x1.bn.weight\nbranch1x1.bn.weight의 gamma one setting 완료\n\nbranch1x1.bn.bias\nbranch1x1.bn.bias의 beta zero setting 완료\n\nbranch3x3_1.bn.weight\nbranch3x3_1.bn.weight의 gamma one setting 완료\n\nbranch3x3_1.bn.bias\nbranch3x3_1.bn.bias의 beta zero setting 완료\n\nbranch3x3_2a.bn.weight\nbranch3x3_2a.bn.weight의 gamma one setting 완료\n\nbranch3x3_2a.bn.bias\nbranch3x3_2a.bn.bias의 beta zero setting 완료\n\nbranch3x3_2b.bn.weight\nbranch3x3_2b.bn.weight의 gamma one setting 완료\n\nbranch3x3_2b.bn.bias\nbranch3x3_2b.bn.bias의 beta zero setting 완료\n\nbranch3x3dbl_1.bn.weight\nbranch3x3dbl_1.bn.weight의 gamma one setting 완료\n\nbranch3x3dbl_1.bn.bias\nbranch3x3dbl_1.bn.bias의 beta zero setting 완료\n\nbranch3x3dbl_2.bn.weight\nbranch3x3dbl_2.bn.weight의 gamma one setting 완료\n\nbranch3x3dbl_2.bn.bias\nbranch3x3dbl_2.bn.bias의 beta zero setting 완료\n\nbranch3x3dbl_3a.bn.weight\nbranch3x3dbl_3a.bn.weight의 gamma one setting 완료\n\nbranch3x3dbl_3a.bn.bias\nbranch3x3dbl_3a.bn.bias의 beta zero setting 완료\n\nbranch3x3dbl_3b.bn.weight\nbranch3x3dbl_3b.bn.weight의 gamma one setting 완료\n\nbranch3x3dbl_3b.bn.bias\nbranch3x3dbl_3b.bn.bias의 beta zero setting 완료\n\nbranch_pool.bn.weight\nbranch_pool.bn.weight의 gamma one setting 완료\n\nbranch_pool.bn.bias\nbranch_pool.bn.bias의 beta zero setting 완료\n\nbranch1x1.bn.weight\nbranch1x1.bn.weight의 gamma one setting 완료\n\nbranch1x1.bn.bias\nbranch1x1.bn.bias의 beta zero setting 완료\n\nbranch3x3_1.bn.weight\nbranch3x3_1.bn.weight의 gamma one setting 완료\n\nbranch3x3_1.bn.bias\nbranch3x3_1.bn.bias의 beta zero setting 완료\n\nbranch3x3_2a.bn.weight\nbranch3x3_2a.bn.weight의 gamma one setting 완료\n\nbranch3x3_2a.bn.bias\nbranch3x3_2a.bn.bias의 beta zero setting 완료\n\nbranch3x3_2b.bn.weight\nbranch3x3_2b.bn.weight의 gamma one setting 완료\n\nbranch3x3_2b.bn.bias\nbranch3x3_2b.bn.bias의 beta zero setting 완료\n\nbranch3x3dbl_1.bn.weight\nbranch3x3dbl_1.bn.weight의 gamma one setting 완료\n\nbranch3x3dbl_1.bn.bias\nbranch3x3dbl_1.bn.bias의 beta zero setting 완료\n\nbranch3x3dbl_2.bn.weight\nbranch3x3dbl_2.bn.weight의 gamma one setting 완료\n\nbranch3x3dbl_2.bn.bias\nbranch3x3dbl_2.bn.bias의 beta zero setting 완료\n\nbranch3x3dbl_3a.bn.weight\nbranch3x3dbl_3a.bn.weight의 gamma one setting 완료\n\nbranch3x3dbl_3a.bn.bias\nbranch3x3dbl_3a.bn.bias의 beta zero setting 완료\n\nbranch3x3dbl_3b.bn.weight\nbranch3x3dbl_3b.bn.weight의 gamma one setting 완료\n\nbranch3x3dbl_3b.bn.bias\nbranch3x3dbl_3b.bn.bias의 beta zero setting 완료\n\nbranch_pool.bn.weight\nbranch_pool.bn.weight의 gamma one setting 완료\n\nbranch_pool.bn.bias\nbranch_pool.bn.bias의 beta zero setting 완료\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Checkpoint","metadata":{}},{"cell_type":"code","source":"def save_model(model, epoch, optimizer, epoch_loss, val_accuracy, saved_dir):\n    os.makedirs(saved_dir, exist_ok=True)\n    check_point = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': epoch_loss\n    }\n    val_accuracy = round(val_accuracy,1)\n    file_name = str(f\"ckpoint_{epoch+1}_{val_accuracy}%.pt\")\n    output_path = os.path.join(saved_dir, file_name)\n    torch.save(check_point,output_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:10:28.765461Z","iopub.execute_input":"2024-05-08T11:10:28.766342Z","iopub.status.idle":"2024-05-08T11:10:28.772039Z","shell.execute_reply.started":"2024-05-08T11:10:28.766310Z","shell.execute_reply":"2024-05-08T11:10:28.771091Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Tensorboard","metadata":{}},{"cell_type":"code","source":"logs_base_dir = \"./logs/logs_transfer\"\nos.makedirs(logs_base_dir, exist_ok=True)\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter(logs_base_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:10:40.884919Z","iopub.execute_input":"2024-05-08T11:10:40.885935Z","iopub.status.idle":"2024-05-08T11:10:51.268894Z","shell.execute_reply.started":"2024-05-08T11:10:40.885893Z","shell.execute_reply":"2024-05-08T11:10:51.268086Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2024-05-08 11:10:42.911582: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-08 11:10:42.911709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-08 11:10:43.044939: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Train, Validation, Test","metadata":{}},{"cell_type":"code","source":"def train(num_epochs, model, data_loader, criterion, optimizer, scheduler, val_every, device, saved_dir, writer):\n    print('Start training..')\n    torch.cuda.empty_cache()\n    best_loss = 9999999\n    train_loss_list = []\n    val_loss_list = []\n    train_accuracy_list = []\n    val_accuracy_list = []\n    for epoch in tqdm(range(num_epochs), desc='epoch'):\n        count = 0\n        best_epoch = 0\n        # running_loss = 0.0\n        for i, (imgs, labels) in tqdm(enumerate(data_loader), desc=\"in epoch\"):\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs, aux = model(imgs)       # 여기서 inception net의 특징이 나옴\n            output_loss = criterion(outputs, labels)\n            aux_loss = criterion(aux, labels)\n            loss = output_loss + 0.3*aux_loss\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Saving train loss\n            train_loss_list.append(loss.item())\n\n            _, argmax = torch.max(outputs, 1)\n            accuracy = (labels == argmax).float().mean()\n            # Saving train accuracy\n            train_accuracy_list.append(accuracy)\n\n            if (i+1) % 30 == 0:\n                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n                    epoch+1, num_epochs, i+1, len(data_loader), loss.item(), accuracy.item() * 100))\n            if (i+1) % 50 == 0:\n                writer.add_scalar('Loss/Train', loss, i)\n                writer.add_scalar('Accuracy/Train', accuracy, i)\n            #if i % 30 == 29:\n                #loss_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader) ]))\n                #running_loss = 0.0\n        if (epoch + 1) % val_every == 0:\n            avrg_loss, val_accuracy = validation(epoch + 1, model, val_loader, criterion, device)\n            # Saving validation loss and accuracy\n            val_loss_list.append(avrg_loss)\n            writer.add_scalar('Loss/Validation', avrg_loss, epoch+1)\n            val_accuracy_list.append(val_accuracy)\n            writer.add_scalar('Accuracy/Validation', val_accuracy, epoch+1)\n            if avrg_loss < best_loss:\n                print('Best performance at epoch: {}'.format(epoch + 1))\n                print('Save model in', saved_dir)\n                best_loss = avrg_loss\n                save_model(model, epoch, optimizer, avrg_loss, val_accuracy, saved_dir)\n                count = 0\n                best_epoch = epoch + 1\n            else:\n                count += 1\n                print(f'Best epoch does not appear. Previous best epoch:{best_epoch}, A number of epochs remain until early stop: {10-count}')\n                if count >= 10:\n                    print('Best performance does not occur within 10 epochs. Early stopping!!')\n                    scheduler.step()\n                    writer.flush()\n                    return train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list\n            ''' Only for local setting\n            loss_tracker(loss_plt, torch.Tensor([avrg_loss]), torch.Tensor([epoch]))'''\n    scheduler.step()\n    writer.flush()\n    return train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list\n\ndef validation(epoch, model, data_loader, criterion, device):\n    print('Start validation #{}'.format(epoch) )\n    model.eval()\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        total_loss = 0\n        cnt = 0\n        for i, (imgs, labels) in enumerate(data_loader):\n            imgs, labels = imgs.to(device), labels.to(device)\n            \n            outputs = model(imgs)       # eval을 했기 때문에 aux가 필요 없음\n            loss = criterion(outputs, labels)\n            \n            total += imgs.size(0)\n            _, argmax = torch.max(outputs, 1)\n            correct += (labels == argmax).sum().item()\n            total_loss += loss\n            cnt += 1\n        avrg_loss = total_loss / cnt\n        val_accuracy = correct / total * 100\n        print('Validation #{}  Accuracy: {:.2f}%  Average Loss: {:.4f}'.format(epoch, val_accuracy, avrg_loss))\n    model.train()\n    return avrg_loss, val_accuracy\n\ndef test(model, data_loader, device):\n    print('Start test..')\n    model.eval()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        answer_list = []\n        pred_list = []\n        pred_proba_list = []\n        \n        for i, (imgs, labels) in tqdm(enumerate(data_loader)):\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            outputs = model(imgs)       # 여기도 eval을 하기 때문에 aux가 필요 없음\n\n            pred_probability = F.softmax(outputs, dim=1)\n            pred_proba_list.append(pred_probability.tolist())\n            \n            _, argmax = torch.max(outputs, 1)\n            pred_list.append(argmax.tolist())\n\n            total += imgs.size(0)\n            correct += (labels == argmax).sum().item()\n            \n            answer_list.append(labels.tolist())\n        \n        print('Test accuracy for {} images: {:.2f}%'.format(total, correct / total * 100))\n    model.train()        \n    return pred_list, answer_list, pred_proba_list","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:10:58.639569Z","iopub.execute_input":"2024-05-08T11:10:58.640347Z","iopub.status.idle":"2024-05-08T11:10:58.664863Z","shell.execute_reply.started":"2024-05-08T11:10:58.640316Z","shell.execute_reply":"2024-05-08T11:10:58.663701Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Loss, optimizer, directory for saving","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(7777)\n\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(inception_transfer.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.00001)\n\nval_every = 1\nsaved_dir = './saved'","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:11:00.941171Z","iopub.execute_input":"2024-05-08T11:11:00.941536Z","iopub.status.idle":"2024-05-08T11:11:00.962262Z","shell.execute_reply.started":"2024-05-08T11:11:00.941508Z","shell.execute_reply":"2024-05-08T11:11:00.961007Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Train","metadata":{}},{"cell_type":"code","source":"train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list = train(num_epochs, inception_transfer, train_loader, criterion, optimizer, scheduler, val_every, device, saved_dir, writer)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-08T11:11:04.570107Z","iopub.execute_input":"2024-05-08T11:11:04.571032Z","iopub.status.idle":"2024-05-08T14:12:05.512218Z","shell.execute_reply.started":"2024-05-08T11:11:04.570993Z","shell.execute_reply":"2024-05-08T14:12:05.510926Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Start training..\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a57d2cbe0a64fd58f3e64f1b6a133d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbf21c26f60f4802b033e6c2a3c8db86"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/50], Step [30/1305], Loss: 0.3552, Accuracy: 90.62%\nEpoch [1/50], Step [60/1305], Loss: 0.2752, Accuracy: 95.31%\nEpoch [1/50], Step [90/1305], Loss: 0.5236, Accuracy: 85.94%\nEpoch [1/50], Step [120/1305], Loss: 0.3976, Accuracy: 89.06%\nEpoch [1/50], Step [150/1305], Loss: 0.5068, Accuracy: 90.62%\nEpoch [1/50], Step [180/1305], Loss: 0.3227, Accuracy: 89.06%\nEpoch [1/50], Step [210/1305], Loss: 0.3037, Accuracy: 89.06%\nEpoch [1/50], Step [240/1305], Loss: 0.2001, Accuracy: 95.31%\nEpoch [1/50], Step [270/1305], Loss: 0.2407, Accuracy: 96.88%\nEpoch [1/50], Step [300/1305], Loss: 0.2449, Accuracy: 96.88%\nEpoch [1/50], Step [330/1305], Loss: 0.3068, Accuracy: 93.75%\nEpoch [1/50], Step [360/1305], Loss: 0.2016, Accuracy: 93.75%\nEpoch [1/50], Step [390/1305], Loss: 0.1526, Accuracy: 96.88%\nEpoch [1/50], Step [420/1305], Loss: 0.0705, Accuracy: 98.44%\nEpoch [1/50], Step [450/1305], Loss: 0.2164, Accuracy: 95.31%\nEpoch [1/50], Step [480/1305], Loss: 0.2903, Accuracy: 96.88%\nEpoch [1/50], Step [510/1305], Loss: 0.2926, Accuracy: 93.75%\nEpoch [1/50], Step [540/1305], Loss: 0.1052, Accuracy: 95.31%\nEpoch [1/50], Step [570/1305], Loss: 0.3184, Accuracy: 92.19%\nEpoch [1/50], Step [600/1305], Loss: 0.3184, Accuracy: 89.06%\nEpoch [1/50], Step [630/1305], Loss: 0.3295, Accuracy: 90.62%\nEpoch [1/50], Step [660/1305], Loss: 0.2656, Accuracy: 90.62%\nEpoch [1/50], Step [690/1305], Loss: 0.3780, Accuracy: 93.75%\nEpoch [1/50], Step [720/1305], Loss: 0.1799, Accuracy: 95.31%\nEpoch [1/50], Step [750/1305], Loss: 0.2761, Accuracy: 95.31%\nEpoch [1/50], Step [780/1305], Loss: 0.3218, Accuracy: 90.62%\nEpoch [1/50], Step [810/1305], Loss: 0.1026, Accuracy: 98.44%\nEpoch [1/50], Step [840/1305], Loss: 0.1571, Accuracy: 95.31%\nEpoch [1/50], Step [870/1305], Loss: 0.2786, Accuracy: 93.75%\nEpoch [1/50], Step [900/1305], Loss: 0.1796, Accuracy: 96.88%\nEpoch [1/50], Step [930/1305], Loss: 0.2894, Accuracy: 95.31%\nEpoch [1/50], Step [960/1305], Loss: 0.2641, Accuracy: 92.19%\nEpoch [1/50], Step [990/1305], Loss: 0.1556, Accuracy: 95.31%\nEpoch [1/50], Step [1020/1305], Loss: 0.2896, Accuracy: 90.62%\nEpoch [1/50], Step [1050/1305], Loss: 0.1173, Accuracy: 96.88%\nEpoch [1/50], Step [1080/1305], Loss: 0.2063, Accuracy: 96.88%\nEpoch [1/50], Step [1110/1305], Loss: 0.0599, Accuracy: 98.44%\nEpoch [1/50], Step [1140/1305], Loss: 0.2718, Accuracy: 90.62%\nEpoch [1/50], Step [1170/1305], Loss: 0.1284, Accuracy: 96.88%\nEpoch [1/50], Step [1200/1305], Loss: 0.1776, Accuracy: 95.31%\nEpoch [1/50], Step [1230/1305], Loss: 0.1250, Accuracy: 96.88%\nEpoch [1/50], Step [1260/1305], Loss: 0.1743, Accuracy: 92.19%\nEpoch [1/50], Step [1290/1305], Loss: 0.2881, Accuracy: 95.31%\nStart validation #1\nValidation #1  Accuracy: 96.88%  Average Loss: 0.0579\nBest performance at epoch: 1\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d8a2d886e14bcaa94aaeabbf7bd6e6"}},"metadata":{}},{"name":"stdout","text":"Epoch [2/50], Step [30/1305], Loss: 0.2822, Accuracy: 93.75%\nEpoch [2/50], Step [60/1305], Loss: 0.3116, Accuracy: 90.62%\nEpoch [2/50], Step [90/1305], Loss: 0.1667, Accuracy: 92.19%\nEpoch [2/50], Step [120/1305], Loss: 0.1021, Accuracy: 98.44%\nEpoch [2/50], Step [150/1305], Loss: 0.1758, Accuracy: 95.31%\nEpoch [2/50], Step [180/1305], Loss: 0.1338, Accuracy: 95.31%\nEpoch [2/50], Step [210/1305], Loss: 0.1738, Accuracy: 95.31%\nEpoch [2/50], Step [240/1305], Loss: 0.0606, Accuracy: 100.00%\nEpoch [2/50], Step [270/1305], Loss: 0.0556, Accuracy: 100.00%\nEpoch [2/50], Step [300/1305], Loss: 0.0600, Accuracy: 98.44%\nEpoch [2/50], Step [330/1305], Loss: 0.2251, Accuracy: 95.31%\nEpoch [2/50], Step [360/1305], Loss: 0.1158, Accuracy: 96.88%\nEpoch [2/50], Step [390/1305], Loss: 0.1403, Accuracy: 95.31%\nEpoch [2/50], Step [420/1305], Loss: 0.1093, Accuracy: 96.88%\nEpoch [2/50], Step [450/1305], Loss: 0.1257, Accuracy: 96.88%\nEpoch [2/50], Step [480/1305], Loss: 0.1393, Accuracy: 96.88%\nEpoch [2/50], Step [510/1305], Loss: 0.2067, Accuracy: 93.75%\nEpoch [2/50], Step [540/1305], Loss: 0.1473, Accuracy: 95.31%\nEpoch [2/50], Step [570/1305], Loss: 0.1549, Accuracy: 95.31%\nEpoch [2/50], Step [600/1305], Loss: 0.1651, Accuracy: 98.44%\nEpoch [2/50], Step [630/1305], Loss: 0.3803, Accuracy: 95.31%\nEpoch [2/50], Step [660/1305], Loss: 0.1821, Accuracy: 95.31%\nEpoch [2/50], Step [690/1305], Loss: 0.0947, Accuracy: 98.44%\nEpoch [2/50], Step [720/1305], Loss: 0.1975, Accuracy: 93.75%\nEpoch [2/50], Step [750/1305], Loss: 0.0770, Accuracy: 98.44%\nEpoch [2/50], Step [780/1305], Loss: 0.1119, Accuracy: 95.31%\nEpoch [2/50], Step [810/1305], Loss: 0.0869, Accuracy: 98.44%\nEpoch [2/50], Step [840/1305], Loss: 0.1688, Accuracy: 96.88%\nEpoch [2/50], Step [870/1305], Loss: 0.2435, Accuracy: 95.31%\nEpoch [2/50], Step [900/1305], Loss: 0.1189, Accuracy: 96.88%\nEpoch [2/50], Step [930/1305], Loss: 0.1663, Accuracy: 96.88%\nEpoch [2/50], Step [960/1305], Loss: 0.2886, Accuracy: 92.19%\nEpoch [2/50], Step [990/1305], Loss: 0.1864, Accuracy: 95.31%\nEpoch [2/50], Step [1020/1305], Loss: 0.3668, Accuracy: 93.75%\nEpoch [2/50], Step [1050/1305], Loss: 0.1599, Accuracy: 96.88%\nEpoch [2/50], Step [1080/1305], Loss: 0.2049, Accuracy: 96.88%\nEpoch [2/50], Step [1110/1305], Loss: 0.3422, Accuracy: 93.75%\nEpoch [2/50], Step [1140/1305], Loss: 0.3492, Accuracy: 93.75%\nEpoch [2/50], Step [1170/1305], Loss: 0.1232, Accuracy: 98.44%\nEpoch [2/50], Step [1200/1305], Loss: 0.1086, Accuracy: 98.44%\nEpoch [2/50], Step [1230/1305], Loss: 0.1313, Accuracy: 96.88%\nEpoch [2/50], Step [1260/1305], Loss: 0.2397, Accuracy: 93.75%\nEpoch [2/50], Step [1290/1305], Loss: 0.4059, Accuracy: 87.50%\nStart validation #2\nValidation #2  Accuracy: 100.00%  Average Loss: 0.0410\nBest performance at epoch: 2\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b3456f2906441d949336a25220ad76"}},"metadata":{}},{"name":"stdout","text":"Epoch [3/50], Step [30/1305], Loss: 0.1148, Accuracy: 96.88%\nEpoch [3/50], Step [60/1305], Loss: 0.0606, Accuracy: 98.44%\nEpoch [3/50], Step [90/1305], Loss: 0.1863, Accuracy: 96.88%\nEpoch [3/50], Step [120/1305], Loss: 0.1841, Accuracy: 95.31%\nEpoch [3/50], Step [150/1305], Loss: 0.1551, Accuracy: 93.75%\nEpoch [3/50], Step [180/1305], Loss: 0.1150, Accuracy: 95.31%\nEpoch [3/50], Step [210/1305], Loss: 0.0571, Accuracy: 98.44%\nEpoch [3/50], Step [240/1305], Loss: 0.0847, Accuracy: 96.88%\nEpoch [3/50], Step [270/1305], Loss: 0.1351, Accuracy: 98.44%\nEpoch [3/50], Step [300/1305], Loss: 0.1719, Accuracy: 93.75%\nEpoch [3/50], Step [330/1305], Loss: 0.0385, Accuracy: 100.00%\nEpoch [3/50], Step [360/1305], Loss: 0.1183, Accuracy: 95.31%\nEpoch [3/50], Step [390/1305], Loss: 0.2617, Accuracy: 92.19%\nEpoch [3/50], Step [420/1305], Loss: 0.0352, Accuracy: 100.00%\nEpoch [3/50], Step [450/1305], Loss: 0.2353, Accuracy: 93.75%\nEpoch [3/50], Step [480/1305], Loss: 0.0663, Accuracy: 98.44%\nEpoch [3/50], Step [510/1305], Loss: 0.2377, Accuracy: 92.19%\nEpoch [3/50], Step [540/1305], Loss: 0.0798, Accuracy: 95.31%\nEpoch [3/50], Step [570/1305], Loss: 0.0732, Accuracy: 100.00%\nEpoch [3/50], Step [600/1305], Loss: 0.0657, Accuracy: 95.31%\nEpoch [3/50], Step [630/1305], Loss: 0.2646, Accuracy: 93.75%\nEpoch [3/50], Step [660/1305], Loss: 0.1381, Accuracy: 98.44%\nEpoch [3/50], Step [690/1305], Loss: 0.1665, Accuracy: 95.31%\nEpoch [3/50], Step [720/1305], Loss: 0.2555, Accuracy: 92.19%\nEpoch [3/50], Step [750/1305], Loss: 0.0954, Accuracy: 96.88%\nEpoch [3/50], Step [780/1305], Loss: 0.2393, Accuracy: 92.19%\nEpoch [3/50], Step [810/1305], Loss: 0.0552, Accuracy: 100.00%\nEpoch [3/50], Step [840/1305], Loss: 0.1770, Accuracy: 92.19%\nEpoch [3/50], Step [870/1305], Loss: 0.1062, Accuracy: 96.88%\nEpoch [3/50], Step [900/1305], Loss: 0.1059, Accuracy: 96.88%\nEpoch [3/50], Step [930/1305], Loss: 0.1306, Accuracy: 93.75%\nEpoch [3/50], Step [960/1305], Loss: 0.0727, Accuracy: 100.00%\nEpoch [3/50], Step [990/1305], Loss: 0.2104, Accuracy: 96.88%\nEpoch [3/50], Step [1020/1305], Loss: 0.1361, Accuracy: 96.88%\nEpoch [3/50], Step [1050/1305], Loss: 0.1439, Accuracy: 96.88%\nEpoch [3/50], Step [1080/1305], Loss: 0.2158, Accuracy: 95.31%\nEpoch [3/50], Step [1110/1305], Loss: 0.1813, Accuracy: 95.31%\nEpoch [3/50], Step [1140/1305], Loss: 0.1530, Accuracy: 95.31%\nEpoch [3/50], Step [1170/1305], Loss: 0.0832, Accuracy: 96.88%\nEpoch [3/50], Step [1200/1305], Loss: 0.2198, Accuracy: 95.31%\nEpoch [3/50], Step [1230/1305], Loss: 0.0896, Accuracy: 96.88%\nEpoch [3/50], Step [1260/1305], Loss: 0.0626, Accuracy: 96.88%\nEpoch [3/50], Step [1290/1305], Loss: 0.3595, Accuracy: 92.19%\nStart validation #3\nValidation #3  Accuracy: 100.00%  Average Loss: 0.0249\nBest performance at epoch: 3\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aecf4ee2ff148b89f7ace227c18362d"}},"metadata":{}},{"name":"stdout","text":"Epoch [4/50], Step [30/1305], Loss: 0.2148, Accuracy: 93.75%\nEpoch [4/50], Step [60/1305], Loss: 0.0280, Accuracy: 100.00%\nEpoch [4/50], Step [90/1305], Loss: 0.1149, Accuracy: 95.31%\nEpoch [4/50], Step [120/1305], Loss: 0.0970, Accuracy: 95.31%\nEpoch [4/50], Step [150/1305], Loss: 0.2315, Accuracy: 90.62%\nEpoch [4/50], Step [180/1305], Loss: 0.2596, Accuracy: 90.62%\nEpoch [4/50], Step [210/1305], Loss: 0.0983, Accuracy: 96.88%\nEpoch [4/50], Step [240/1305], Loss: 0.2129, Accuracy: 95.31%\nEpoch [4/50], Step [270/1305], Loss: 0.1791, Accuracy: 95.31%\nEpoch [4/50], Step [300/1305], Loss: 0.2768, Accuracy: 95.31%\nEpoch [4/50], Step [330/1305], Loss: 0.1372, Accuracy: 95.31%\nEpoch [4/50], Step [360/1305], Loss: 0.0761, Accuracy: 98.44%\nEpoch [4/50], Step [390/1305], Loss: 0.0862, Accuracy: 96.88%\nEpoch [4/50], Step [420/1305], Loss: 0.0523, Accuracy: 98.44%\nEpoch [4/50], Step [450/1305], Loss: 0.0620, Accuracy: 100.00%\nEpoch [4/50], Step [480/1305], Loss: 0.0691, Accuracy: 98.44%\nEpoch [4/50], Step [510/1305], Loss: 0.0812, Accuracy: 98.44%\nEpoch [4/50], Step [540/1305], Loss: 0.0926, Accuracy: 95.31%\nEpoch [4/50], Step [570/1305], Loss: 0.2879, Accuracy: 93.75%\nEpoch [4/50], Step [600/1305], Loss: 0.0696, Accuracy: 96.88%\nEpoch [4/50], Step [630/1305], Loss: 0.1717, Accuracy: 95.31%\nEpoch [4/50], Step [660/1305], Loss: 0.1803, Accuracy: 93.75%\nEpoch [4/50], Step [690/1305], Loss: 0.1925, Accuracy: 95.31%\nEpoch [4/50], Step [720/1305], Loss: 0.0355, Accuracy: 100.00%\nEpoch [4/50], Step [750/1305], Loss: 0.0714, Accuracy: 96.88%\nEpoch [4/50], Step [780/1305], Loss: 0.0962, Accuracy: 96.88%\nEpoch [4/50], Step [810/1305], Loss: 0.0687, Accuracy: 98.44%\nEpoch [4/50], Step [840/1305], Loss: 0.2613, Accuracy: 93.75%\nEpoch [4/50], Step [870/1305], Loss: 0.1326, Accuracy: 96.88%\nEpoch [4/50], Step [900/1305], Loss: 0.1547, Accuracy: 95.31%\nEpoch [4/50], Step [930/1305], Loss: 0.0658, Accuracy: 98.44%\nEpoch [4/50], Step [960/1305], Loss: 0.1122, Accuracy: 98.44%\nEpoch [4/50], Step [990/1305], Loss: 0.2530, Accuracy: 95.31%\nEpoch [4/50], Step [1020/1305], Loss: 0.1004, Accuracy: 98.44%\nEpoch [4/50], Step [1050/1305], Loss: 0.2360, Accuracy: 95.31%\nEpoch [4/50], Step [1080/1305], Loss: 0.0766, Accuracy: 98.44%\nEpoch [4/50], Step [1110/1305], Loss: 0.1379, Accuracy: 98.44%\nEpoch [4/50], Step [1140/1305], Loss: 0.2820, Accuracy: 95.31%\nEpoch [4/50], Step [1170/1305], Loss: 0.1674, Accuracy: 95.31%\nEpoch [4/50], Step [1200/1305], Loss: 0.0791, Accuracy: 96.88%\nEpoch [4/50], Step [1230/1305], Loss: 0.0779, Accuracy: 98.44%\nEpoch [4/50], Step [1260/1305], Loss: 0.1274, Accuracy: 96.88%\nEpoch [4/50], Step [1290/1305], Loss: 0.1422, Accuracy: 92.19%\nStart validation #4\nValidation #4  Accuracy: 100.00%  Average Loss: 0.0148\nBest performance at epoch: 4\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00c23d924f364d99b9d35c3338862799"}},"metadata":{}},{"name":"stdout","text":"Epoch [5/50], Step [30/1305], Loss: 0.1703, Accuracy: 95.31%\nEpoch [5/50], Step [60/1305], Loss: 0.0307, Accuracy: 100.00%\nEpoch [5/50], Step [90/1305], Loss: 0.0927, Accuracy: 96.88%\nEpoch [5/50], Step [120/1305], Loss: 0.1026, Accuracy: 96.88%\nEpoch [5/50], Step [150/1305], Loss: 0.1455, Accuracy: 96.88%\nEpoch [5/50], Step [180/1305], Loss: 0.1764, Accuracy: 93.75%\nEpoch [5/50], Step [210/1305], Loss: 0.1640, Accuracy: 95.31%\nEpoch [5/50], Step [240/1305], Loss: 0.1216, Accuracy: 95.31%\nEpoch [5/50], Step [270/1305], Loss: 0.1186, Accuracy: 96.88%\nEpoch [5/50], Step [300/1305], Loss: 0.0738, Accuracy: 96.88%\nEpoch [5/50], Step [330/1305], Loss: 0.0491, Accuracy: 98.44%\nEpoch [5/50], Step [360/1305], Loss: 0.1490, Accuracy: 93.75%\nEpoch [5/50], Step [390/1305], Loss: 0.1098, Accuracy: 96.88%\nEpoch [5/50], Step [420/1305], Loss: 0.3225, Accuracy: 93.75%\nEpoch [5/50], Step [450/1305], Loss: 0.0741, Accuracy: 98.44%\nEpoch [5/50], Step [480/1305], Loss: 0.2372, Accuracy: 90.62%\nEpoch [5/50], Step [510/1305], Loss: 0.1739, Accuracy: 95.31%\nEpoch [5/50], Step [540/1305], Loss: 0.1425, Accuracy: 92.19%\nEpoch [5/50], Step [570/1305], Loss: 0.0984, Accuracy: 96.88%\nEpoch [5/50], Step [600/1305], Loss: 0.0614, Accuracy: 100.00%\nEpoch [5/50], Step [630/1305], Loss: 0.2342, Accuracy: 93.75%\nEpoch [5/50], Step [660/1305], Loss: 0.0303, Accuracy: 98.44%\nEpoch [5/50], Step [690/1305], Loss: 0.1499, Accuracy: 95.31%\nEpoch [5/50], Step [720/1305], Loss: 0.0181, Accuracy: 100.00%\nEpoch [5/50], Step [750/1305], Loss: 0.1415, Accuracy: 93.75%\nEpoch [5/50], Step [780/1305], Loss: 0.1521, Accuracy: 95.31%\nEpoch [5/50], Step [810/1305], Loss: 0.1614, Accuracy: 93.75%\nEpoch [5/50], Step [840/1305], Loss: 0.1959, Accuracy: 93.75%\nEpoch [5/50], Step [870/1305], Loss: 0.1701, Accuracy: 95.31%\nEpoch [5/50], Step [900/1305], Loss: 0.0566, Accuracy: 96.88%\nEpoch [5/50], Step [930/1305], Loss: 0.0888, Accuracy: 98.44%\nEpoch [5/50], Step [960/1305], Loss: 0.2025, Accuracy: 96.88%\nEpoch [5/50], Step [990/1305], Loss: 0.3534, Accuracy: 92.19%\nEpoch [5/50], Step [1020/1305], Loss: 0.1122, Accuracy: 95.31%\nEpoch [5/50], Step [1050/1305], Loss: 0.1528, Accuracy: 93.75%\nEpoch [5/50], Step [1080/1305], Loss: 0.0603, Accuracy: 98.44%\nEpoch [5/50], Step [1110/1305], Loss: 0.2010, Accuracy: 95.31%\nEpoch [5/50], Step [1140/1305], Loss: 0.0967, Accuracy: 96.88%\nEpoch [5/50], Step [1170/1305], Loss: 0.2006, Accuracy: 95.31%\nEpoch [5/50], Step [1200/1305], Loss: 0.0866, Accuracy: 98.44%\nEpoch [5/50], Step [1230/1305], Loss: 0.0811, Accuracy: 98.44%\nEpoch [5/50], Step [1260/1305], Loss: 0.0757, Accuracy: 98.44%\nEpoch [5/50], Step [1290/1305], Loss: 0.0412, Accuracy: 100.00%\nStart validation #5\nValidation #5  Accuracy: 100.00%  Average Loss: 0.0315\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff03331facb6408baf5cc2688a9f890f"}},"metadata":{}},{"name":"stdout","text":"Epoch [6/50], Step [30/1305], Loss: 0.0566, Accuracy: 98.44%\nEpoch [6/50], Step [60/1305], Loss: 0.0740, Accuracy: 98.44%\nEpoch [6/50], Step [90/1305], Loss: 0.1143, Accuracy: 96.88%\nEpoch [6/50], Step [120/1305], Loss: 0.0524, Accuracy: 96.88%\nEpoch [6/50], Step [150/1305], Loss: 0.1736, Accuracy: 95.31%\nEpoch [6/50], Step [180/1305], Loss: 0.0317, Accuracy: 100.00%\nEpoch [6/50], Step [210/1305], Loss: 0.1540, Accuracy: 95.31%\nEpoch [6/50], Step [240/1305], Loss: 0.0634, Accuracy: 98.44%\nEpoch [6/50], Step [270/1305], Loss: 0.0884, Accuracy: 98.44%\nEpoch [6/50], Step [300/1305], Loss: 0.0479, Accuracy: 98.44%\nEpoch [6/50], Step [330/1305], Loss: 0.1138, Accuracy: 96.88%\nEpoch [6/50], Step [360/1305], Loss: 0.0724, Accuracy: 100.00%\nEpoch [6/50], Step [390/1305], Loss: 0.0587, Accuracy: 98.44%\nEpoch [6/50], Step [420/1305], Loss: 0.0381, Accuracy: 100.00%\nEpoch [6/50], Step [450/1305], Loss: 0.1255, Accuracy: 96.88%\nEpoch [6/50], Step [480/1305], Loss: 0.0731, Accuracy: 98.44%\nEpoch [6/50], Step [510/1305], Loss: 0.0420, Accuracy: 100.00%\nEpoch [6/50], Step [540/1305], Loss: 0.1720, Accuracy: 96.88%\nEpoch [6/50], Step [570/1305], Loss: 0.1357, Accuracy: 96.88%\nEpoch [6/50], Step [600/1305], Loss: 0.1836, Accuracy: 98.44%\nEpoch [6/50], Step [630/1305], Loss: 0.0603, Accuracy: 98.44%\nEpoch [6/50], Step [660/1305], Loss: 0.0614, Accuracy: 100.00%\nEpoch [6/50], Step [690/1305], Loss: 0.0301, Accuracy: 100.00%\nEpoch [6/50], Step [720/1305], Loss: 0.1570, Accuracy: 93.75%\nEpoch [6/50], Step [750/1305], Loss: 0.1201, Accuracy: 96.88%\nEpoch [6/50], Step [780/1305], Loss: 0.0840, Accuracy: 96.88%\nEpoch [6/50], Step [810/1305], Loss: 0.1115, Accuracy: 96.88%\nEpoch [6/50], Step [840/1305], Loss: 0.0323, Accuracy: 100.00%\nEpoch [6/50], Step [870/1305], Loss: 0.0633, Accuracy: 98.44%\nEpoch [6/50], Step [900/1305], Loss: 0.1361, Accuracy: 96.88%\nEpoch [6/50], Step [930/1305], Loss: 0.0975, Accuracy: 98.44%\nEpoch [6/50], Step [960/1305], Loss: 0.0930, Accuracy: 96.88%\nEpoch [6/50], Step [990/1305], Loss: 0.0753, Accuracy: 98.44%\nEpoch [6/50], Step [1020/1305], Loss: 0.0233, Accuracy: 100.00%\nEpoch [6/50], Step [1050/1305], Loss: 0.0942, Accuracy: 98.44%\nEpoch [6/50], Step [1080/1305], Loss: 0.1346, Accuracy: 95.31%\nEpoch [6/50], Step [1110/1305], Loss: 0.1793, Accuracy: 93.75%\nEpoch [6/50], Step [1140/1305], Loss: 0.0543, Accuracy: 98.44%\nEpoch [6/50], Step [1170/1305], Loss: 0.2510, Accuracy: 93.75%\nEpoch [6/50], Step [1200/1305], Loss: 0.0504, Accuracy: 98.44%\nEpoch [6/50], Step [1230/1305], Loss: 0.0776, Accuracy: 96.88%\nEpoch [6/50], Step [1260/1305], Loss: 0.1512, Accuracy: 93.75%\nEpoch [6/50], Step [1290/1305], Loss: 0.0919, Accuracy: 96.88%\nStart validation #6\nValidation #6  Accuracy: 100.00%  Average Loss: 0.0377\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11958cd5a2bd42f3aed10e5255459785"}},"metadata":{}},{"name":"stdout","text":"Epoch [7/50], Step [30/1305], Loss: 0.0942, Accuracy: 95.31%\nEpoch [7/50], Step [60/1305], Loss: 0.1284, Accuracy: 93.75%\nEpoch [7/50], Step [90/1305], Loss: 0.0865, Accuracy: 98.44%\nEpoch [7/50], Step [120/1305], Loss: 0.2969, Accuracy: 93.75%\nEpoch [7/50], Step [150/1305], Loss: 0.1430, Accuracy: 96.88%\nEpoch [7/50], Step [180/1305], Loss: 0.0748, Accuracy: 98.44%\nEpoch [7/50], Step [210/1305], Loss: 0.2785, Accuracy: 93.75%\nEpoch [7/50], Step [240/1305], Loss: 0.0296, Accuracy: 100.00%\nEpoch [7/50], Step [270/1305], Loss: 0.0262, Accuracy: 100.00%\nEpoch [7/50], Step [300/1305], Loss: 0.1014, Accuracy: 95.31%\nEpoch [7/50], Step [330/1305], Loss: 0.0435, Accuracy: 98.44%\nEpoch [7/50], Step [360/1305], Loss: 0.0348, Accuracy: 98.44%\nEpoch [7/50], Step [390/1305], Loss: 0.1501, Accuracy: 93.75%\nEpoch [7/50], Step [420/1305], Loss: 0.0639, Accuracy: 96.88%\nEpoch [7/50], Step [450/1305], Loss: 0.0997, Accuracy: 96.88%\nEpoch [7/50], Step [480/1305], Loss: 0.2293, Accuracy: 93.75%\nEpoch [7/50], Step [510/1305], Loss: 0.2233, Accuracy: 95.31%\nEpoch [7/50], Step [540/1305], Loss: 0.1993, Accuracy: 92.19%\nEpoch [7/50], Step [570/1305], Loss: 0.3001, Accuracy: 92.19%\nEpoch [7/50], Step [600/1305], Loss: 0.0986, Accuracy: 98.44%\nEpoch [7/50], Step [630/1305], Loss: 0.0816, Accuracy: 96.88%\nEpoch [7/50], Step [660/1305], Loss: 0.1127, Accuracy: 96.88%\nEpoch [7/50], Step [690/1305], Loss: 0.0191, Accuracy: 100.00%\nEpoch [7/50], Step [720/1305], Loss: 0.0680, Accuracy: 98.44%\nEpoch [7/50], Step [750/1305], Loss: 0.0335, Accuracy: 100.00%\nEpoch [7/50], Step [780/1305], Loss: 0.0788, Accuracy: 98.44%\nEpoch [7/50], Step [810/1305], Loss: 0.0965, Accuracy: 98.44%\nEpoch [7/50], Step [840/1305], Loss: 0.0277, Accuracy: 100.00%\nEpoch [7/50], Step [870/1305], Loss: 0.1107, Accuracy: 96.88%\nEpoch [7/50], Step [900/1305], Loss: 0.1835, Accuracy: 95.31%\nEpoch [7/50], Step [930/1305], Loss: 0.0218, Accuracy: 100.00%\nEpoch [7/50], Step [960/1305], Loss: 0.1198, Accuracy: 98.44%\nEpoch [7/50], Step [990/1305], Loss: 0.0338, Accuracy: 98.44%\nEpoch [7/50], Step [1020/1305], Loss: 0.1716, Accuracy: 95.31%\nEpoch [7/50], Step [1050/1305], Loss: 0.1499, Accuracy: 95.31%\nEpoch [7/50], Step [1080/1305], Loss: 0.1774, Accuracy: 95.31%\nEpoch [7/50], Step [1110/1305], Loss: 0.0770, Accuracy: 96.88%\nEpoch [7/50], Step [1140/1305], Loss: 0.0841, Accuracy: 96.88%\nEpoch [7/50], Step [1170/1305], Loss: 0.4376, Accuracy: 90.62%\nEpoch [7/50], Step [1200/1305], Loss: 0.0383, Accuracy: 98.44%\nEpoch [7/50], Step [1230/1305], Loss: 0.0803, Accuracy: 95.31%\nEpoch [7/50], Step [1260/1305], Loss: 0.0151, Accuracy: 100.00%\nEpoch [7/50], Step [1290/1305], Loss: 0.1111, Accuracy: 98.44%\nStart validation #7\nValidation #7  Accuracy: 100.00%  Average Loss: 0.0337\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12ac851635c847528c5669153220a9b2"}},"metadata":{}},{"name":"stdout","text":"Epoch [8/50], Step [30/1305], Loss: 0.0539, Accuracy: 98.44%\nEpoch [8/50], Step [60/1305], Loss: 0.0321, Accuracy: 100.00%\nEpoch [8/50], Step [90/1305], Loss: 0.0394, Accuracy: 98.44%\nEpoch [8/50], Step [120/1305], Loss: 0.0520, Accuracy: 96.88%\nEpoch [8/50], Step [150/1305], Loss: 0.1158, Accuracy: 96.88%\nEpoch [8/50], Step [180/1305], Loss: 0.0801, Accuracy: 98.44%\nEpoch [8/50], Step [210/1305], Loss: 0.0203, Accuracy: 100.00%\nEpoch [8/50], Step [240/1305], Loss: 0.0839, Accuracy: 98.44%\nEpoch [8/50], Step [270/1305], Loss: 0.0677, Accuracy: 98.44%\nEpoch [8/50], Step [300/1305], Loss: 0.1126, Accuracy: 96.88%\nEpoch [8/50], Step [330/1305], Loss: 0.1318, Accuracy: 98.44%\nEpoch [8/50], Step [360/1305], Loss: 0.0440, Accuracy: 100.00%\nEpoch [8/50], Step [390/1305], Loss: 0.0541, Accuracy: 100.00%\nEpoch [8/50], Step [420/1305], Loss: 0.0176, Accuracy: 100.00%\nEpoch [8/50], Step [450/1305], Loss: 0.0684, Accuracy: 98.44%\nEpoch [8/50], Step [480/1305], Loss: 0.0167, Accuracy: 100.00%\nEpoch [8/50], Step [510/1305], Loss: 0.0884, Accuracy: 98.44%\nEpoch [8/50], Step [540/1305], Loss: 0.1399, Accuracy: 95.31%\nEpoch [8/50], Step [570/1305], Loss: 0.0526, Accuracy: 98.44%\nEpoch [8/50], Step [600/1305], Loss: 0.0346, Accuracy: 100.00%\nEpoch [8/50], Step [630/1305], Loss: 0.0427, Accuracy: 98.44%\nEpoch [8/50], Step [660/1305], Loss: 0.1052, Accuracy: 95.31%\nEpoch [8/50], Step [690/1305], Loss: 0.0270, Accuracy: 100.00%\nEpoch [8/50], Step [720/1305], Loss: 0.0909, Accuracy: 98.44%\nEpoch [8/50], Step [750/1305], Loss: 0.0087, Accuracy: 100.00%\nEpoch [8/50], Step [780/1305], Loss: 0.1190, Accuracy: 95.31%\nEpoch [8/50], Step [810/1305], Loss: 0.1467, Accuracy: 95.31%\nEpoch [8/50], Step [840/1305], Loss: 0.1112, Accuracy: 96.88%\nEpoch [8/50], Step [870/1305], Loss: 0.0606, Accuracy: 98.44%\nEpoch [8/50], Step [900/1305], Loss: 0.1680, Accuracy: 96.88%\nEpoch [8/50], Step [930/1305], Loss: 0.0888, Accuracy: 98.44%\nEpoch [8/50], Step [960/1305], Loss: 0.0220, Accuracy: 100.00%\nEpoch [8/50], Step [990/1305], Loss: 0.1414, Accuracy: 96.88%\nEpoch [8/50], Step [1020/1305], Loss: 0.0799, Accuracy: 96.88%\nEpoch [8/50], Step [1050/1305], Loss: 0.0673, Accuracy: 98.44%\nEpoch [8/50], Step [1080/1305], Loss: 0.0762, Accuracy: 98.44%\nEpoch [8/50], Step [1110/1305], Loss: 0.0837, Accuracy: 98.44%\nEpoch [8/50], Step [1140/1305], Loss: 0.0086, Accuracy: 100.00%\nEpoch [8/50], Step [1170/1305], Loss: 0.0326, Accuracy: 98.44%\nEpoch [8/50], Step [1200/1305], Loss: 0.2313, Accuracy: 95.31%\nEpoch [8/50], Step [1230/1305], Loss: 0.1180, Accuracy: 98.44%\nEpoch [8/50], Step [1260/1305], Loss: 0.0711, Accuracy: 98.44%\nEpoch [8/50], Step [1290/1305], Loss: 0.1796, Accuracy: 96.88%\nStart validation #8\nValidation #8  Accuracy: 100.00%  Average Loss: 0.0106\nBest performance at epoch: 8\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"122fda53fa2343d8a378d41802c1afaa"}},"metadata":{}},{"name":"stdout","text":"Epoch [9/50], Step [30/1305], Loss: 0.0707, Accuracy: 96.88%\nEpoch [9/50], Step [60/1305], Loss: 0.0836, Accuracy: 98.44%\nEpoch [9/50], Step [90/1305], Loss: 0.0078, Accuracy: 100.00%\nEpoch [9/50], Step [120/1305], Loss: 0.1374, Accuracy: 98.44%\nEpoch [9/50], Step [150/1305], Loss: 0.0903, Accuracy: 96.88%\nEpoch [9/50], Step [180/1305], Loss: 0.0752, Accuracy: 96.88%\nEpoch [9/50], Step [210/1305], Loss: 0.0336, Accuracy: 98.44%\nEpoch [9/50], Step [240/1305], Loss: 0.0638, Accuracy: 98.44%\nEpoch [9/50], Step [270/1305], Loss: 0.1018, Accuracy: 98.44%\nEpoch [9/50], Step [300/1305], Loss: 0.0549, Accuracy: 100.00%\nEpoch [9/50], Step [330/1305], Loss: 0.0421, Accuracy: 96.88%\nEpoch [9/50], Step [360/1305], Loss: 0.0629, Accuracy: 98.44%\nEpoch [9/50], Step [390/1305], Loss: 0.0331, Accuracy: 98.44%\nEpoch [9/50], Step [420/1305], Loss: 0.0865, Accuracy: 96.88%\nEpoch [9/50], Step [450/1305], Loss: 0.1845, Accuracy: 95.31%\nEpoch [9/50], Step [480/1305], Loss: 0.0827, Accuracy: 96.88%\nEpoch [9/50], Step [510/1305], Loss: 0.1186, Accuracy: 95.31%\nEpoch [9/50], Step [540/1305], Loss: 0.0324, Accuracy: 98.44%\nEpoch [9/50], Step [570/1305], Loss: 0.1441, Accuracy: 93.75%\nEpoch [9/50], Step [600/1305], Loss: 0.1270, Accuracy: 96.88%\nEpoch [9/50], Step [630/1305], Loss: 0.0774, Accuracy: 96.88%\nEpoch [9/50], Step [660/1305], Loss: 0.0400, Accuracy: 98.44%\nEpoch [9/50], Step [690/1305], Loss: 0.0573, Accuracy: 100.00%\nEpoch [9/50], Step [720/1305], Loss: 0.1670, Accuracy: 93.75%\nEpoch [9/50], Step [750/1305], Loss: 0.1134, Accuracy: 98.44%\nEpoch [9/50], Step [780/1305], Loss: 0.1211, Accuracy: 96.88%\nEpoch [9/50], Step [810/1305], Loss: 0.0589, Accuracy: 98.44%\nEpoch [9/50], Step [840/1305], Loss: 0.0636, Accuracy: 98.44%\nEpoch [9/50], Step [870/1305], Loss: 0.0482, Accuracy: 98.44%\nEpoch [9/50], Step [900/1305], Loss: 0.0378, Accuracy: 98.44%\nEpoch [9/50], Step [930/1305], Loss: 0.0696, Accuracy: 98.44%\nEpoch [9/50], Step [960/1305], Loss: 0.2603, Accuracy: 98.44%\nEpoch [9/50], Step [990/1305], Loss: 0.0916, Accuracy: 96.88%\nEpoch [9/50], Step [1020/1305], Loss: 0.0140, Accuracy: 100.00%\nEpoch [9/50], Step [1050/1305], Loss: 0.2082, Accuracy: 93.75%\nEpoch [9/50], Step [1080/1305], Loss: 0.0365, Accuracy: 100.00%\nEpoch [9/50], Step [1110/1305], Loss: 0.2026, Accuracy: 96.88%\nEpoch [9/50], Step [1140/1305], Loss: 0.0389, Accuracy: 100.00%\nEpoch [9/50], Step [1170/1305], Loss: 0.0272, Accuracy: 100.00%\nEpoch [9/50], Step [1200/1305], Loss: 0.2402, Accuracy: 95.31%\nEpoch [9/50], Step [1230/1305], Loss: 0.0667, Accuracy: 96.88%\nEpoch [9/50], Step [1260/1305], Loss: 0.0850, Accuracy: 96.88%\nEpoch [9/50], Step [1290/1305], Loss: 0.0359, Accuracy: 98.44%\nStart validation #9\nValidation #9  Accuracy: 100.00%  Average Loss: 0.0261\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d25699f6ade432cafa961d8e8f30a3e"}},"metadata":{}},{"name":"stdout","text":"Epoch [10/50], Step [30/1305], Loss: 0.1388, Accuracy: 95.31%\nEpoch [10/50], Step [60/1305], Loss: 0.0192, Accuracy: 100.00%\nEpoch [10/50], Step [90/1305], Loss: 0.0245, Accuracy: 98.44%\nEpoch [10/50], Step [120/1305], Loss: 0.0278, Accuracy: 100.00%\nEpoch [10/50], Step [150/1305], Loss: 0.1723, Accuracy: 95.31%\nEpoch [10/50], Step [180/1305], Loss: 0.0631, Accuracy: 100.00%\nEpoch [10/50], Step [210/1305], Loss: 0.0773, Accuracy: 96.88%\nEpoch [10/50], Step [240/1305], Loss: 0.0256, Accuracy: 98.44%\nEpoch [10/50], Step [270/1305], Loss: 0.3026, Accuracy: 89.06%\nEpoch [10/50], Step [300/1305], Loss: 0.1023, Accuracy: 96.88%\nEpoch [10/50], Step [330/1305], Loss: 0.0263, Accuracy: 100.00%\nEpoch [10/50], Step [360/1305], Loss: 0.0263, Accuracy: 100.00%\nEpoch [10/50], Step [390/1305], Loss: 0.0962, Accuracy: 98.44%\nEpoch [10/50], Step [420/1305], Loss: 0.0127, Accuracy: 100.00%\nEpoch [10/50], Step [450/1305], Loss: 0.0272, Accuracy: 98.44%\nEpoch [10/50], Step [480/1305], Loss: 0.0207, Accuracy: 100.00%\nEpoch [10/50], Step [510/1305], Loss: 0.0156, Accuracy: 100.00%\nEpoch [10/50], Step [540/1305], Loss: 0.0213, Accuracy: 100.00%\nEpoch [10/50], Step [570/1305], Loss: 0.0931, Accuracy: 95.31%\nEpoch [10/50], Step [600/1305], Loss: 0.0163, Accuracy: 100.00%\nEpoch [10/50], Step [630/1305], Loss: 0.1086, Accuracy: 96.88%\nEpoch [10/50], Step [660/1305], Loss: 0.0636, Accuracy: 100.00%\nEpoch [10/50], Step [690/1305], Loss: 0.0425, Accuracy: 100.00%\nEpoch [10/50], Step [720/1305], Loss: 0.0250, Accuracy: 100.00%\nEpoch [10/50], Step [750/1305], Loss: 0.0099, Accuracy: 100.00%\nEpoch [10/50], Step [780/1305], Loss: 0.0109, Accuracy: 100.00%\nEpoch [10/50], Step [810/1305], Loss: 0.0544, Accuracy: 98.44%\nEpoch [10/50], Step [840/1305], Loss: 0.0785, Accuracy: 98.44%\nEpoch [10/50], Step [870/1305], Loss: 0.1250, Accuracy: 96.88%\nEpoch [10/50], Step [900/1305], Loss: 0.0908, Accuracy: 96.88%\nEpoch [10/50], Step [930/1305], Loss: 0.0382, Accuracy: 100.00%\nEpoch [10/50], Step [960/1305], Loss: 0.1075, Accuracy: 96.88%\nEpoch [10/50], Step [990/1305], Loss: 0.0418, Accuracy: 98.44%\nEpoch [10/50], Step [1020/1305], Loss: 0.0424, Accuracy: 98.44%\nEpoch [10/50], Step [1050/1305], Loss: 0.0371, Accuracy: 98.44%\nEpoch [10/50], Step [1080/1305], Loss: 0.0428, Accuracy: 100.00%\nEpoch [10/50], Step [1110/1305], Loss: 0.0551, Accuracy: 98.44%\nEpoch [10/50], Step [1140/1305], Loss: 0.0333, Accuracy: 100.00%\nEpoch [10/50], Step [1170/1305], Loss: 0.1084, Accuracy: 98.44%\nEpoch [10/50], Step [1200/1305], Loss: 0.1925, Accuracy: 95.31%\nEpoch [10/50], Step [1230/1305], Loss: 0.0274, Accuracy: 98.44%\nEpoch [10/50], Step [1260/1305], Loss: 0.0391, Accuracy: 98.44%\nEpoch [10/50], Step [1290/1305], Loss: 0.1136, Accuracy: 96.88%\nStart validation #10\nValidation #10  Accuracy: 100.00%  Average Loss: 0.0332\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1998613aeb454eae8b1c951ad3252880"}},"metadata":{}},{"name":"stdout","text":"Epoch [11/50], Step [30/1305], Loss: 0.1033, Accuracy: 95.31%\nEpoch [11/50], Step [60/1305], Loss: 0.0092, Accuracy: 100.00%\nEpoch [11/50], Step [90/1305], Loss: 0.0825, Accuracy: 98.44%\nEpoch [11/50], Step [120/1305], Loss: 0.0193, Accuracy: 100.00%\nEpoch [11/50], Step [150/1305], Loss: 0.1566, Accuracy: 96.88%\nEpoch [11/50], Step [180/1305], Loss: 0.0222, Accuracy: 100.00%\nEpoch [11/50], Step [210/1305], Loss: 0.0143, Accuracy: 100.00%\nEpoch [11/50], Step [240/1305], Loss: 0.0244, Accuracy: 98.44%\nEpoch [11/50], Step [270/1305], Loss: 0.0732, Accuracy: 98.44%\nEpoch [11/50], Step [300/1305], Loss: 0.0810, Accuracy: 95.31%\nEpoch [11/50], Step [330/1305], Loss: 0.0271, Accuracy: 100.00%\nEpoch [11/50], Step [360/1305], Loss: 0.0801, Accuracy: 98.44%\nEpoch [11/50], Step [390/1305], Loss: 0.0848, Accuracy: 98.44%\nEpoch [11/50], Step [420/1305], Loss: 0.0641, Accuracy: 98.44%\nEpoch [11/50], Step [450/1305], Loss: 0.0467, Accuracy: 98.44%\nEpoch [11/50], Step [480/1305], Loss: 0.0975, Accuracy: 98.44%\nEpoch [11/50], Step [510/1305], Loss: 0.0218, Accuracy: 100.00%\nEpoch [11/50], Step [540/1305], Loss: 0.0665, Accuracy: 96.88%\nEpoch [11/50], Step [570/1305], Loss: 0.0378, Accuracy: 98.44%\nEpoch [11/50], Step [600/1305], Loss: 0.0541, Accuracy: 98.44%\nEpoch [11/50], Step [630/1305], Loss: 0.0676, Accuracy: 96.88%\nEpoch [11/50], Step [660/1305], Loss: 0.1136, Accuracy: 96.88%\nEpoch [11/50], Step [690/1305], Loss: 0.0797, Accuracy: 98.44%\nEpoch [11/50], Step [720/1305], Loss: 0.1433, Accuracy: 95.31%\nEpoch [11/50], Step [750/1305], Loss: 0.0417, Accuracy: 98.44%\nEpoch [11/50], Step [780/1305], Loss: 0.0678, Accuracy: 98.44%\nEpoch [11/50], Step [810/1305], Loss: 0.0393, Accuracy: 100.00%\nEpoch [11/50], Step [840/1305], Loss: 0.1601, Accuracy: 96.88%\nEpoch [11/50], Step [870/1305], Loss: 0.0087, Accuracy: 100.00%\nEpoch [11/50], Step [900/1305], Loss: 0.2829, Accuracy: 92.19%\nEpoch [11/50], Step [930/1305], Loss: 0.0492, Accuracy: 98.44%\nEpoch [11/50], Step [960/1305], Loss: 0.0266, Accuracy: 98.44%\nEpoch [11/50], Step [990/1305], Loss: 0.1251, Accuracy: 95.31%\nEpoch [11/50], Step [1020/1305], Loss: 0.1116, Accuracy: 96.88%\nEpoch [11/50], Step [1050/1305], Loss: 0.0246, Accuracy: 100.00%\nEpoch [11/50], Step [1080/1305], Loss: 0.0927, Accuracy: 98.44%\nEpoch [11/50], Step [1110/1305], Loss: 0.2347, Accuracy: 95.31%\nEpoch [11/50], Step [1140/1305], Loss: 0.0646, Accuracy: 96.88%\nEpoch [11/50], Step [1170/1305], Loss: 0.0335, Accuracy: 100.00%\nEpoch [11/50], Step [1200/1305], Loss: 0.0963, Accuracy: 96.88%\nEpoch [11/50], Step [1230/1305], Loss: 0.0255, Accuracy: 100.00%\nEpoch [11/50], Step [1260/1305], Loss: 0.1423, Accuracy: 96.88%\nEpoch [11/50], Step [1290/1305], Loss: 0.0502, Accuracy: 98.44%\nStart validation #11\nValidation #11  Accuracy: 100.00%  Average Loss: 0.0252\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0faf5042255843589e1cfd16d3ea713e"}},"metadata":{}},{"name":"stdout","text":"Epoch [12/50], Step [30/1305], Loss: 0.1201, Accuracy: 96.88%\nEpoch [12/50], Step [60/1305], Loss: 0.0717, Accuracy: 96.88%\nEpoch [12/50], Step [90/1305], Loss: 0.0361, Accuracy: 100.00%\nEpoch [12/50], Step [120/1305], Loss: 0.0199, Accuracy: 100.00%\nEpoch [12/50], Step [150/1305], Loss: 0.1336, Accuracy: 96.88%\nEpoch [12/50], Step [180/1305], Loss: 0.0247, Accuracy: 100.00%\nEpoch [12/50], Step [210/1305], Loss: 0.0205, Accuracy: 100.00%\nEpoch [12/50], Step [240/1305], Loss: 0.1035, Accuracy: 96.88%\nEpoch [12/50], Step [270/1305], Loss: 0.0332, Accuracy: 98.44%\nEpoch [12/50], Step [300/1305], Loss: 0.0670, Accuracy: 96.88%\nEpoch [12/50], Step [330/1305], Loss: 0.0742, Accuracy: 98.44%\nEpoch [12/50], Step [360/1305], Loss: 0.0269, Accuracy: 98.44%\nEpoch [12/50], Step [390/1305], Loss: 0.0450, Accuracy: 98.44%\nEpoch [12/50], Step [420/1305], Loss: 0.1224, Accuracy: 95.31%\nEpoch [12/50], Step [450/1305], Loss: 0.0822, Accuracy: 96.88%\nEpoch [12/50], Step [480/1305], Loss: 0.0396, Accuracy: 100.00%\nEpoch [12/50], Step [510/1305], Loss: 0.1354, Accuracy: 96.88%\nEpoch [12/50], Step [540/1305], Loss: 0.0248, Accuracy: 100.00%\nEpoch [12/50], Step [570/1305], Loss: 0.0284, Accuracy: 98.44%\nEpoch [12/50], Step [600/1305], Loss: 0.0759, Accuracy: 98.44%\nEpoch [12/50], Step [630/1305], Loss: 0.0627, Accuracy: 98.44%\nEpoch [12/50], Step [660/1305], Loss: 0.0295, Accuracy: 100.00%\nEpoch [12/50], Step [690/1305], Loss: 0.1079, Accuracy: 96.88%\nEpoch [12/50], Step [720/1305], Loss: 0.0450, Accuracy: 98.44%\nEpoch [12/50], Step [750/1305], Loss: 0.0602, Accuracy: 98.44%\nEpoch [12/50], Step [780/1305], Loss: 0.2199, Accuracy: 95.31%\nEpoch [12/50], Step [810/1305], Loss: 0.0737, Accuracy: 96.88%\nEpoch [12/50], Step [840/1305], Loss: 0.1356, Accuracy: 96.88%\nEpoch [12/50], Step [870/1305], Loss: 0.0492, Accuracy: 98.44%\nEpoch [12/50], Step [900/1305], Loss: 0.0451, Accuracy: 98.44%\nEpoch [12/50], Step [930/1305], Loss: 0.0464, Accuracy: 98.44%\nEpoch [12/50], Step [960/1305], Loss: 0.0301, Accuracy: 100.00%\nEpoch [12/50], Step [990/1305], Loss: 0.0175, Accuracy: 100.00%\nEpoch [12/50], Step [1020/1305], Loss: 0.0335, Accuracy: 100.00%\nEpoch [12/50], Step [1050/1305], Loss: 0.0358, Accuracy: 100.00%\nEpoch [12/50], Step [1080/1305], Loss: 0.1202, Accuracy: 98.44%\nEpoch [12/50], Step [1110/1305], Loss: 0.0564, Accuracy: 98.44%\nEpoch [12/50], Step [1140/1305], Loss: 0.0996, Accuracy: 95.31%\nEpoch [12/50], Step [1170/1305], Loss: 0.0561, Accuracy: 98.44%\nEpoch [12/50], Step [1200/1305], Loss: 0.0382, Accuracy: 98.44%\nEpoch [12/50], Step [1230/1305], Loss: 0.1165, Accuracy: 96.88%\nEpoch [12/50], Step [1260/1305], Loss: 0.0093, Accuracy: 100.00%\nEpoch [12/50], Step [1290/1305], Loss: 0.0111, Accuracy: 100.00%\nStart validation #12\nValidation #12  Accuracy: 100.00%  Average Loss: 0.0105\nBest performance at epoch: 12\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f749bb24f6454b699ed9bd86adac2ee2"}},"metadata":{}},{"name":"stdout","text":"Epoch [13/50], Step [30/1305], Loss: 0.0415, Accuracy: 98.44%\nEpoch [13/50], Step [60/1305], Loss: 0.0374, Accuracy: 98.44%\nEpoch [13/50], Step [90/1305], Loss: 0.1296, Accuracy: 95.31%\nEpoch [13/50], Step [120/1305], Loss: 0.1217, Accuracy: 96.88%\nEpoch [13/50], Step [150/1305], Loss: 0.0308, Accuracy: 98.44%\nEpoch [13/50], Step [180/1305], Loss: 0.1640, Accuracy: 93.75%\nEpoch [13/50], Step [210/1305], Loss: 0.0845, Accuracy: 96.88%\nEpoch [13/50], Step [240/1305], Loss: 0.1698, Accuracy: 96.88%\nEpoch [13/50], Step [270/1305], Loss: 0.0784, Accuracy: 96.88%\nEpoch [13/50], Step [300/1305], Loss: 0.2012, Accuracy: 96.88%\nEpoch [13/50], Step [330/1305], Loss: 0.0482, Accuracy: 98.44%\nEpoch [13/50], Step [360/1305], Loss: 0.1160, Accuracy: 98.44%\nEpoch [13/50], Step [390/1305], Loss: 0.0923, Accuracy: 98.44%\nEpoch [13/50], Step [420/1305], Loss: 0.0531, Accuracy: 98.44%\nEpoch [13/50], Step [450/1305], Loss: 0.0304, Accuracy: 100.00%\nEpoch [13/50], Step [480/1305], Loss: 0.0898, Accuracy: 96.88%\nEpoch [13/50], Step [510/1305], Loss: 0.0158, Accuracy: 100.00%\nEpoch [13/50], Step [540/1305], Loss: 0.0250, Accuracy: 98.44%\nEpoch [13/50], Step [570/1305], Loss: 0.0233, Accuracy: 100.00%\nEpoch [13/50], Step [600/1305], Loss: 0.0037, Accuracy: 100.00%\nEpoch [13/50], Step [630/1305], Loss: 0.0114, Accuracy: 100.00%\nEpoch [13/50], Step [660/1305], Loss: 0.0726, Accuracy: 96.88%\nEpoch [13/50], Step [690/1305], Loss: 0.0134, Accuracy: 100.00%\nEpoch [13/50], Step [720/1305], Loss: 0.0371, Accuracy: 98.44%\nEpoch [13/50], Step [750/1305], Loss: 0.0354, Accuracy: 98.44%\nEpoch [13/50], Step [780/1305], Loss: 0.0187, Accuracy: 98.44%\nEpoch [13/50], Step [810/1305], Loss: 0.0748, Accuracy: 96.88%\nEpoch [13/50], Step [840/1305], Loss: 0.0760, Accuracy: 98.44%\nEpoch [13/50], Step [870/1305], Loss: 0.0982, Accuracy: 95.31%\nEpoch [13/50], Step [900/1305], Loss: 0.0444, Accuracy: 98.44%\nEpoch [13/50], Step [930/1305], Loss: 0.0056, Accuracy: 100.00%\nEpoch [13/50], Step [960/1305], Loss: 0.0553, Accuracy: 96.88%\nEpoch [13/50], Step [990/1305], Loss: 0.0213, Accuracy: 100.00%\nEpoch [13/50], Step [1020/1305], Loss: 0.1574, Accuracy: 96.88%\nEpoch [13/50], Step [1050/1305], Loss: 0.0385, Accuracy: 98.44%\nEpoch [13/50], Step [1080/1305], Loss: 0.0231, Accuracy: 100.00%\nEpoch [13/50], Step [1110/1305], Loss: 0.0385, Accuracy: 100.00%\nEpoch [13/50], Step [1140/1305], Loss: 0.0384, Accuracy: 98.44%\nEpoch [13/50], Step [1170/1305], Loss: 0.0435, Accuracy: 100.00%\nEpoch [13/50], Step [1200/1305], Loss: 0.0655, Accuracy: 98.44%\nEpoch [13/50], Step [1230/1305], Loss: 0.0859, Accuracy: 96.88%\nEpoch [13/50], Step [1260/1305], Loss: 0.0131, Accuracy: 100.00%\nEpoch [13/50], Step [1290/1305], Loss: 0.0044, Accuracy: 100.00%\nStart validation #13\nValidation #13  Accuracy: 100.00%  Average Loss: 0.0229\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9d770a637f34abcb5a1e76f9dac3ea2"}},"metadata":{}},{"name":"stdout","text":"Epoch [14/50], Step [30/1305], Loss: 0.0089, Accuracy: 100.00%\nEpoch [14/50], Step [60/1305], Loss: 0.0387, Accuracy: 98.44%\nEpoch [14/50], Step [90/1305], Loss: 0.1043, Accuracy: 96.88%\nEpoch [14/50], Step [120/1305], Loss: 0.0405, Accuracy: 100.00%\nEpoch [14/50], Step [150/1305], Loss: 0.0446, Accuracy: 98.44%\nEpoch [14/50], Step [180/1305], Loss: 0.0421, Accuracy: 100.00%\nEpoch [14/50], Step [210/1305], Loss: 0.1125, Accuracy: 96.88%\nEpoch [14/50], Step [240/1305], Loss: 0.0275, Accuracy: 98.44%\nEpoch [14/50], Step [270/1305], Loss: 0.0095, Accuracy: 100.00%\nEpoch [14/50], Step [300/1305], Loss: 0.0076, Accuracy: 100.00%\nEpoch [14/50], Step [330/1305], Loss: 0.0898, Accuracy: 96.88%\nEpoch [14/50], Step [360/1305], Loss: 0.0709, Accuracy: 98.44%\nEpoch [14/50], Step [390/1305], Loss: 0.0213, Accuracy: 100.00%\nEpoch [14/50], Step [420/1305], Loss: 0.0128, Accuracy: 100.00%\nEpoch [14/50], Step [450/1305], Loss: 0.0081, Accuracy: 100.00%\nEpoch [14/50], Step [480/1305], Loss: 0.0775, Accuracy: 98.44%\nEpoch [14/50], Step [510/1305], Loss: 0.0646, Accuracy: 98.44%\nEpoch [14/50], Step [540/1305], Loss: 0.1146, Accuracy: 96.88%\nEpoch [14/50], Step [570/1305], Loss: 0.1050, Accuracy: 96.88%\nEpoch [14/50], Step [600/1305], Loss: 0.0087, Accuracy: 100.00%\nEpoch [14/50], Step [630/1305], Loss: 0.0111, Accuracy: 100.00%\nEpoch [14/50], Step [660/1305], Loss: 0.0074, Accuracy: 100.00%\nEpoch [14/50], Step [690/1305], Loss: 0.0127, Accuracy: 100.00%\nEpoch [14/50], Step [720/1305], Loss: 0.0123, Accuracy: 100.00%\nEpoch [14/50], Step [750/1305], Loss: 0.0279, Accuracy: 98.44%\nEpoch [14/50], Step [780/1305], Loss: 0.1233, Accuracy: 96.88%\nEpoch [14/50], Step [810/1305], Loss: 0.0859, Accuracy: 98.44%\nEpoch [14/50], Step [840/1305], Loss: 0.1006, Accuracy: 96.88%\nEpoch [14/50], Step [870/1305], Loss: 0.1749, Accuracy: 98.44%\nEpoch [14/50], Step [900/1305], Loss: 0.2791, Accuracy: 92.19%\nEpoch [14/50], Step [930/1305], Loss: 0.0397, Accuracy: 98.44%\nEpoch [14/50], Step [960/1305], Loss: 0.0367, Accuracy: 98.44%\nEpoch [14/50], Step [990/1305], Loss: 0.2046, Accuracy: 96.88%\nEpoch [14/50], Step [1020/1305], Loss: 0.0551, Accuracy: 98.44%\nEpoch [14/50], Step [1050/1305], Loss: 0.0244, Accuracy: 100.00%\nEpoch [14/50], Step [1080/1305], Loss: 0.0638, Accuracy: 98.44%\nEpoch [14/50], Step [1110/1305], Loss: 0.0112, Accuracy: 100.00%\nEpoch [14/50], Step [1140/1305], Loss: 0.0264, Accuracy: 100.00%\nEpoch [14/50], Step [1170/1305], Loss: 0.1307, Accuracy: 98.44%\nEpoch [14/50], Step [1200/1305], Loss: 0.0907, Accuracy: 98.44%\nEpoch [14/50], Step [1230/1305], Loss: 0.0135, Accuracy: 100.00%\nEpoch [14/50], Step [1260/1305], Loss: 0.1546, Accuracy: 98.44%\nEpoch [14/50], Step [1290/1305], Loss: 0.1122, Accuracy: 96.88%\nStart validation #14\nValidation #14  Accuracy: 100.00%  Average Loss: 0.0034\nBest performance at epoch: 14\nSave model in ./saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ae243a07484522a5226c14d8ca82f9"}},"metadata":{}},{"name":"stdout","text":"Epoch [15/50], Step [30/1305], Loss: 0.1306, Accuracy: 96.88%\nEpoch [15/50], Step [60/1305], Loss: 0.0443, Accuracy: 98.44%\nEpoch [15/50], Step [90/1305], Loss: 0.0027, Accuracy: 100.00%\nEpoch [15/50], Step [120/1305], Loss: 0.0128, Accuracy: 100.00%\nEpoch [15/50], Step [150/1305], Loss: 0.0266, Accuracy: 100.00%\nEpoch [15/50], Step [180/1305], Loss: 0.0193, Accuracy: 100.00%\nEpoch [15/50], Step [210/1305], Loss: 0.0493, Accuracy: 98.44%\nEpoch [15/50], Step [240/1305], Loss: 0.0771, Accuracy: 98.44%\nEpoch [15/50], Step [270/1305], Loss: 0.0451, Accuracy: 96.88%\nEpoch [15/50], Step [300/1305], Loss: 0.0816, Accuracy: 98.44%\nEpoch [15/50], Step [330/1305], Loss: 0.0340, Accuracy: 98.44%\nEpoch [15/50], Step [360/1305], Loss: 0.0206, Accuracy: 100.00%\nEpoch [15/50], Step [390/1305], Loss: 0.0430, Accuracy: 98.44%\nEpoch [15/50], Step [420/1305], Loss: 0.0890, Accuracy: 96.88%\nEpoch [15/50], Step [450/1305], Loss: 0.0460, Accuracy: 98.44%\nEpoch [15/50], Step [480/1305], Loss: 0.0472, Accuracy: 98.44%\nEpoch [15/50], Step [510/1305], Loss: 0.0260, Accuracy: 98.44%\nEpoch [15/50], Step [540/1305], Loss: 0.0795, Accuracy: 96.88%\nEpoch [15/50], Step [570/1305], Loss: 0.0170, Accuracy: 98.44%\nEpoch [15/50], Step [600/1305], Loss: 0.0561, Accuracy: 95.31%\nEpoch [15/50], Step [630/1305], Loss: 0.0110, Accuracy: 100.00%\nEpoch [15/50], Step [660/1305], Loss: 0.0595, Accuracy: 96.88%\nEpoch [15/50], Step [690/1305], Loss: 0.0357, Accuracy: 100.00%\nEpoch [15/50], Step [720/1305], Loss: 0.0783, Accuracy: 96.88%\nEpoch [15/50], Step [750/1305], Loss: 0.1217, Accuracy: 96.88%\nEpoch [15/50], Step [780/1305], Loss: 0.0272, Accuracy: 100.00%\nEpoch [15/50], Step [810/1305], Loss: 0.1075, Accuracy: 98.44%\nEpoch [15/50], Step [840/1305], Loss: 0.0486, Accuracy: 98.44%\nEpoch [15/50], Step [870/1305], Loss: 0.0775, Accuracy: 96.88%\nEpoch [15/50], Step [900/1305], Loss: 0.0614, Accuracy: 98.44%\nEpoch [15/50], Step [930/1305], Loss: 0.0595, Accuracy: 98.44%\nEpoch [15/50], Step [960/1305], Loss: 0.0194, Accuracy: 100.00%\nEpoch [15/50], Step [990/1305], Loss: 0.0056, Accuracy: 100.00%\nEpoch [15/50], Step [1020/1305], Loss: 0.0490, Accuracy: 100.00%\nEpoch [15/50], Step [1050/1305], Loss: 0.0110, Accuracy: 100.00%\nEpoch [15/50], Step [1080/1305], Loss: 0.0959, Accuracy: 98.44%\nEpoch [15/50], Step [1110/1305], Loss: 0.0633, Accuracy: 98.44%\nEpoch [15/50], Step [1140/1305], Loss: 0.0769, Accuracy: 98.44%\nEpoch [15/50], Step [1170/1305], Loss: 0.0258, Accuracy: 100.00%\nEpoch [15/50], Step [1200/1305], Loss: 0.0113, Accuracy: 100.00%\nEpoch [15/50], Step [1230/1305], Loss: 0.1417, Accuracy: 96.88%\nEpoch [15/50], Step [1260/1305], Loss: 0.0500, Accuracy: 98.44%\nEpoch [15/50], Step [1290/1305], Loss: 0.0386, Accuracy: 98.44%\nStart validation #15\nValidation #15  Accuracy: 100.00%  Average Loss: 0.0539\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e7fbd36e9764c47a6297ed0cf88f9b1"}},"metadata":{}},{"name":"stdout","text":"Epoch [16/50], Step [30/1305], Loss: 0.0426, Accuracy: 100.00%\nEpoch [16/50], Step [60/1305], Loss: 0.0693, Accuracy: 98.44%\nEpoch [16/50], Step [90/1305], Loss: 0.0493, Accuracy: 98.44%\nEpoch [16/50], Step [120/1305], Loss: 0.0436, Accuracy: 96.88%\nEpoch [16/50], Step [150/1305], Loss: 0.0137, Accuracy: 100.00%\nEpoch [16/50], Step [180/1305], Loss: 0.0234, Accuracy: 100.00%\nEpoch [16/50], Step [210/1305], Loss: 0.0131, Accuracy: 100.00%\nEpoch [16/50], Step [240/1305], Loss: 0.0607, Accuracy: 98.44%\nEpoch [16/50], Step [270/1305], Loss: 0.0550, Accuracy: 96.88%\nEpoch [16/50], Step [300/1305], Loss: 0.0315, Accuracy: 100.00%\nEpoch [16/50], Step [330/1305], Loss: 0.0477, Accuracy: 96.88%\nEpoch [16/50], Step [360/1305], Loss: 0.0221, Accuracy: 100.00%\nEpoch [16/50], Step [390/1305], Loss: 0.0390, Accuracy: 98.44%\nEpoch [16/50], Step [420/1305], Loss: 0.0244, Accuracy: 98.44%\nEpoch [16/50], Step [450/1305], Loss: 0.0458, Accuracy: 96.88%\nEpoch [16/50], Step [480/1305], Loss: 0.0129, Accuracy: 100.00%\nEpoch [16/50], Step [510/1305], Loss: 0.1075, Accuracy: 98.44%\nEpoch [16/50], Step [540/1305], Loss: 0.0112, Accuracy: 100.00%\nEpoch [16/50], Step [570/1305], Loss: 0.0767, Accuracy: 98.44%\nEpoch [16/50], Step [600/1305], Loss: 0.0315, Accuracy: 100.00%\nEpoch [16/50], Step [630/1305], Loss: 0.0403, Accuracy: 98.44%\nEpoch [16/50], Step [660/1305], Loss: 0.1219, Accuracy: 95.31%\nEpoch [16/50], Step [690/1305], Loss: 0.0255, Accuracy: 100.00%\nEpoch [16/50], Step [720/1305], Loss: 0.0276, Accuracy: 98.44%\nEpoch [16/50], Step [750/1305], Loss: 0.1082, Accuracy: 96.88%\nEpoch [16/50], Step [780/1305], Loss: 0.0410, Accuracy: 100.00%\nEpoch [16/50], Step [810/1305], Loss: 0.0729, Accuracy: 98.44%\nEpoch [16/50], Step [840/1305], Loss: 0.0248, Accuracy: 100.00%\nEpoch [16/50], Step [870/1305], Loss: 0.1646, Accuracy: 92.19%\nEpoch [16/50], Step [900/1305], Loss: 0.0992, Accuracy: 96.88%\nEpoch [16/50], Step [930/1305], Loss: 0.1333, Accuracy: 96.88%\nEpoch [16/50], Step [960/1305], Loss: 0.0881, Accuracy: 98.44%\nEpoch [16/50], Step [990/1305], Loss: 0.0609, Accuracy: 98.44%\nEpoch [16/50], Step [1020/1305], Loss: 0.0332, Accuracy: 100.00%\nEpoch [16/50], Step [1050/1305], Loss: 0.0338, Accuracy: 98.44%\nEpoch [16/50], Step [1080/1305], Loss: 0.0380, Accuracy: 100.00%\nEpoch [16/50], Step [1110/1305], Loss: 0.0404, Accuracy: 98.44%\nEpoch [16/50], Step [1140/1305], Loss: 0.0437, Accuracy: 98.44%\nEpoch [16/50], Step [1170/1305], Loss: 0.0259, Accuracy: 100.00%\nEpoch [16/50], Step [1200/1305], Loss: 0.0344, Accuracy: 98.44%\nEpoch [16/50], Step [1230/1305], Loss: 0.1025, Accuracy: 96.88%\nEpoch [16/50], Step [1260/1305], Loss: 0.0092, Accuracy: 100.00%\nEpoch [16/50], Step [1290/1305], Loss: 0.0911, Accuracy: 98.44%\nStart validation #16\nValidation #16  Accuracy: 100.00%  Average Loss: 0.0210\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86f6508397bb4a8aba7997796542ba99"}},"metadata":{}},{"name":"stdout","text":"Epoch [17/50], Step [30/1305], Loss: 0.0370, Accuracy: 100.00%\nEpoch [17/50], Step [60/1305], Loss: 0.0415, Accuracy: 98.44%\nEpoch [17/50], Step [90/1305], Loss: 0.0230, Accuracy: 100.00%\nEpoch [17/50], Step [120/1305], Loss: 0.0252, Accuracy: 100.00%\nEpoch [17/50], Step [150/1305], Loss: 0.0205, Accuracy: 98.44%\nEpoch [17/50], Step [180/1305], Loss: 0.0507, Accuracy: 96.88%\nEpoch [17/50], Step [210/1305], Loss: 0.0280, Accuracy: 100.00%\nEpoch [17/50], Step [240/1305], Loss: 0.0428, Accuracy: 98.44%\nEpoch [17/50], Step [270/1305], Loss: 0.0102, Accuracy: 100.00%\nEpoch [17/50], Step [300/1305], Loss: 0.0439, Accuracy: 98.44%\nEpoch [17/50], Step [330/1305], Loss: 0.0463, Accuracy: 98.44%\nEpoch [17/50], Step [360/1305], Loss: 0.0211, Accuracy: 100.00%\nEpoch [17/50], Step [390/1305], Loss: 0.2398, Accuracy: 98.44%\nEpoch [17/50], Step [420/1305], Loss: 0.0469, Accuracy: 98.44%\nEpoch [17/50], Step [450/1305], Loss: 0.0390, Accuracy: 100.00%\nEpoch [17/50], Step [480/1305], Loss: 0.0211, Accuracy: 100.00%\nEpoch [17/50], Step [510/1305], Loss: 0.0156, Accuracy: 100.00%\nEpoch [17/50], Step [540/1305], Loss: 0.0025, Accuracy: 100.00%\nEpoch [17/50], Step [570/1305], Loss: 0.0222, Accuracy: 98.44%\nEpoch [17/50], Step [600/1305], Loss: 0.0652, Accuracy: 98.44%\nEpoch [17/50], Step [630/1305], Loss: 0.0994, Accuracy: 96.88%\nEpoch [17/50], Step [660/1305], Loss: 0.0490, Accuracy: 98.44%\nEpoch [17/50], Step [690/1305], Loss: 0.0219, Accuracy: 100.00%\nEpoch [17/50], Step [720/1305], Loss: 0.1049, Accuracy: 96.88%\nEpoch [17/50], Step [750/1305], Loss: 0.0798, Accuracy: 95.31%\nEpoch [17/50], Step [780/1305], Loss: 0.0076, Accuracy: 100.00%\nEpoch [17/50], Step [810/1305], Loss: 0.0681, Accuracy: 98.44%\nEpoch [17/50], Step [840/1305], Loss: 0.0150, Accuracy: 100.00%\nEpoch [17/50], Step [870/1305], Loss: 0.0347, Accuracy: 100.00%\nEpoch [17/50], Step [900/1305], Loss: 0.0873, Accuracy: 96.88%\nEpoch [17/50], Step [930/1305], Loss: 0.0049, Accuracy: 100.00%\nEpoch [17/50], Step [960/1305], Loss: 0.0645, Accuracy: 98.44%\nEpoch [17/50], Step [990/1305], Loss: 0.0251, Accuracy: 100.00%\nEpoch [17/50], Step [1020/1305], Loss: 0.0396, Accuracy: 98.44%\nEpoch [17/50], Step [1050/1305], Loss: 0.0117, Accuracy: 100.00%\nEpoch [17/50], Step [1080/1305], Loss: 0.0683, Accuracy: 98.44%\nEpoch [17/50], Step [1110/1305], Loss: 0.0310, Accuracy: 100.00%\nEpoch [17/50], Step [1140/1305], Loss: 0.0194, Accuracy: 100.00%\nEpoch [17/50], Step [1170/1305], Loss: 0.0530, Accuracy: 98.44%\nEpoch [17/50], Step [1200/1305], Loss: 0.0035, Accuracy: 100.00%\nEpoch [17/50], Step [1230/1305], Loss: 0.2094, Accuracy: 93.75%\nEpoch [17/50], Step [1260/1305], Loss: 0.1137, Accuracy: 96.88%\nEpoch [17/50], Step [1290/1305], Loss: 0.1065, Accuracy: 95.31%\nStart validation #17\nValidation #17  Accuracy: 100.00%  Average Loss: 0.0314\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc78e960e9cd459bb29bbf4440997391"}},"metadata":{}},{"name":"stdout","text":"Epoch [18/50], Step [30/1305], Loss: 0.0470, Accuracy: 98.44%\nEpoch [18/50], Step [60/1305], Loss: 0.1153, Accuracy: 96.88%\nEpoch [18/50], Step [90/1305], Loss: 0.0463, Accuracy: 96.88%\nEpoch [18/50], Step [120/1305], Loss: 0.0326, Accuracy: 98.44%\nEpoch [18/50], Step [150/1305], Loss: 0.0138, Accuracy: 100.00%\nEpoch [18/50], Step [180/1305], Loss: 0.0211, Accuracy: 100.00%\nEpoch [18/50], Step [210/1305], Loss: 0.0133, Accuracy: 100.00%\nEpoch [18/50], Step [240/1305], Loss: 0.0455, Accuracy: 96.88%\nEpoch [18/50], Step [270/1305], Loss: 0.0326, Accuracy: 100.00%\nEpoch [18/50], Step [300/1305], Loss: 0.0493, Accuracy: 98.44%\nEpoch [18/50], Step [330/1305], Loss: 0.0066, Accuracy: 100.00%\nEpoch [18/50], Step [360/1305], Loss: 0.0137, Accuracy: 100.00%\nEpoch [18/50], Step [390/1305], Loss: 0.0453, Accuracy: 100.00%\nEpoch [18/50], Step [420/1305], Loss: 0.0089, Accuracy: 100.00%\nEpoch [18/50], Step [450/1305], Loss: 0.1516, Accuracy: 96.88%\nEpoch [18/50], Step [480/1305], Loss: 0.0051, Accuracy: 100.00%\nEpoch [18/50], Step [510/1305], Loss: 0.1360, Accuracy: 95.31%\nEpoch [18/50], Step [540/1305], Loss: 0.0549, Accuracy: 98.44%\nEpoch [18/50], Step [570/1305], Loss: 0.0842, Accuracy: 96.88%\nEpoch [18/50], Step [600/1305], Loss: 0.0360, Accuracy: 100.00%\nEpoch [18/50], Step [630/1305], Loss: 0.1272, Accuracy: 96.88%\nEpoch [18/50], Step [660/1305], Loss: 0.0130, Accuracy: 100.00%\nEpoch [18/50], Step [690/1305], Loss: 0.0143, Accuracy: 100.00%\nEpoch [18/50], Step [720/1305], Loss: 0.0111, Accuracy: 100.00%\nEpoch [18/50], Step [750/1305], Loss: 0.0474, Accuracy: 100.00%\nEpoch [18/50], Step [780/1305], Loss: 0.0542, Accuracy: 100.00%\nEpoch [18/50], Step [810/1305], Loss: 0.0524, Accuracy: 98.44%\nEpoch [18/50], Step [840/1305], Loss: 0.0263, Accuracy: 98.44%\nEpoch [18/50], Step [870/1305], Loss: 0.1794, Accuracy: 95.31%\nEpoch [18/50], Step [900/1305], Loss: 0.1289, Accuracy: 98.44%\nEpoch [18/50], Step [930/1305], Loss: 0.0910, Accuracy: 98.44%\nEpoch [18/50], Step [960/1305], Loss: 0.0523, Accuracy: 98.44%\nEpoch [18/50], Step [990/1305], Loss: 0.0068, Accuracy: 100.00%\nEpoch [18/50], Step [1020/1305], Loss: 0.0799, Accuracy: 96.88%\nEpoch [18/50], Step [1050/1305], Loss: 0.0504, Accuracy: 98.44%\nEpoch [18/50], Step [1080/1305], Loss: 0.0172, Accuracy: 100.00%\nEpoch [18/50], Step [1110/1305], Loss: 0.0647, Accuracy: 96.88%\nEpoch [18/50], Step [1140/1305], Loss: 0.0059, Accuracy: 100.00%\nEpoch [18/50], Step [1170/1305], Loss: 0.0546, Accuracy: 98.44%\nEpoch [18/50], Step [1200/1305], Loss: 0.0472, Accuracy: 98.44%\nEpoch [18/50], Step [1230/1305], Loss: 0.0094, Accuracy: 100.00%\nEpoch [18/50], Step [1260/1305], Loss: 0.0375, Accuracy: 100.00%\nEpoch [18/50], Step [1290/1305], Loss: 0.0679, Accuracy: 96.88%\nStart validation #18\nValidation #18  Accuracy: 100.00%  Average Loss: 0.0112\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffa19b32e2f2492eaaa3d3e8f4fe6f44"}},"metadata":{}},{"name":"stdout","text":"Epoch [19/50], Step [30/1305], Loss: 0.0186, Accuracy: 100.00%\nEpoch [19/50], Step [60/1305], Loss: 0.0081, Accuracy: 100.00%\nEpoch [19/50], Step [90/1305], Loss: 0.0804, Accuracy: 98.44%\nEpoch [19/50], Step [120/1305], Loss: 0.0126, Accuracy: 100.00%\nEpoch [19/50], Step [150/1305], Loss: 0.0665, Accuracy: 98.44%\nEpoch [19/50], Step [180/1305], Loss: 0.0734, Accuracy: 98.44%\nEpoch [19/50], Step [210/1305], Loss: 0.0218, Accuracy: 100.00%\nEpoch [19/50], Step [240/1305], Loss: 0.4150, Accuracy: 95.31%\nEpoch [19/50], Step [270/1305], Loss: 0.0160, Accuracy: 100.00%\nEpoch [19/50], Step [300/1305], Loss: 0.0284, Accuracy: 98.44%\nEpoch [19/50], Step [330/1305], Loss: 0.0209, Accuracy: 100.00%\nEpoch [19/50], Step [360/1305], Loss: 0.0126, Accuracy: 100.00%\nEpoch [19/50], Step [390/1305], Loss: 0.0434, Accuracy: 98.44%\nEpoch [19/50], Step [420/1305], Loss: 0.0996, Accuracy: 98.44%\nEpoch [19/50], Step [450/1305], Loss: 0.0491, Accuracy: 98.44%\nEpoch [19/50], Step [480/1305], Loss: 0.2237, Accuracy: 96.88%\nEpoch [19/50], Step [510/1305], Loss: 0.0134, Accuracy: 100.00%\nEpoch [19/50], Step [540/1305], Loss: 0.0204, Accuracy: 100.00%\nEpoch [19/50], Step [570/1305], Loss: 0.0627, Accuracy: 98.44%\nEpoch [19/50], Step [600/1305], Loss: 0.0168, Accuracy: 100.00%\nEpoch [19/50], Step [630/1305], Loss: 0.0223, Accuracy: 100.00%\nEpoch [19/50], Step [660/1305], Loss: 0.1309, Accuracy: 98.44%\nEpoch [19/50], Step [690/1305], Loss: 0.0819, Accuracy: 96.88%\nEpoch [19/50], Step [720/1305], Loss: 0.0025, Accuracy: 100.00%\nEpoch [19/50], Step [750/1305], Loss: 0.0624, Accuracy: 96.88%\nEpoch [19/50], Step [780/1305], Loss: 0.0609, Accuracy: 96.88%\nEpoch [19/50], Step [810/1305], Loss: 0.0080, Accuracy: 100.00%\nEpoch [19/50], Step [840/1305], Loss: 0.0676, Accuracy: 96.88%\nEpoch [19/50], Step [870/1305], Loss: 0.0108, Accuracy: 100.00%\nEpoch [19/50], Step [900/1305], Loss: 0.0155, Accuracy: 100.00%\nEpoch [19/50], Step [930/1305], Loss: 0.0217, Accuracy: 100.00%\nEpoch [19/50], Step [960/1305], Loss: 0.1373, Accuracy: 98.44%\nEpoch [19/50], Step [990/1305], Loss: 0.1654, Accuracy: 96.88%\nEpoch [19/50], Step [1020/1305], Loss: 0.0824, Accuracy: 98.44%\nEpoch [19/50], Step [1050/1305], Loss: 0.0012, Accuracy: 100.00%\nEpoch [19/50], Step [1080/1305], Loss: 0.0525, Accuracy: 98.44%\nEpoch [19/50], Step [1110/1305], Loss: 0.1082, Accuracy: 98.44%\nEpoch [19/50], Step [1140/1305], Loss: 0.0303, Accuracy: 100.00%\nEpoch [19/50], Step [1170/1305], Loss: 0.1139, Accuracy: 98.44%\nEpoch [19/50], Step [1200/1305], Loss: 0.0395, Accuracy: 98.44%\nEpoch [19/50], Step [1230/1305], Loss: 0.0417, Accuracy: 96.88%\nEpoch [19/50], Step [1260/1305], Loss: 0.0717, Accuracy: 98.44%\nEpoch [19/50], Step [1290/1305], Loss: 0.0162, Accuracy: 100.00%\nStart validation #19\nValidation #19  Accuracy: 100.00%  Average Loss: 0.0270\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9751e4594eca424e893ed4ab3f31f086"}},"metadata":{}},{"name":"stdout","text":"Epoch [20/50], Step [30/1305], Loss: 0.0221, Accuracy: 100.00%\nEpoch [20/50], Step [60/1305], Loss: 0.0760, Accuracy: 96.88%\nEpoch [20/50], Step [90/1305], Loss: 0.0300, Accuracy: 98.44%\nEpoch [20/50], Step [120/1305], Loss: 0.1147, Accuracy: 95.31%\nEpoch [20/50], Step [150/1305], Loss: 0.0148, Accuracy: 100.00%\nEpoch [20/50], Step [180/1305], Loss: 0.0412, Accuracy: 96.88%\nEpoch [20/50], Step [210/1305], Loss: 0.0251, Accuracy: 98.44%\nEpoch [20/50], Step [240/1305], Loss: 0.0509, Accuracy: 98.44%\nEpoch [20/50], Step [270/1305], Loss: 0.0593, Accuracy: 96.88%\nEpoch [20/50], Step [300/1305], Loss: 0.0129, Accuracy: 100.00%\nEpoch [20/50], Step [330/1305], Loss: 0.0274, Accuracy: 100.00%\nEpoch [20/50], Step [360/1305], Loss: 0.0236, Accuracy: 100.00%\nEpoch [20/50], Step [390/1305], Loss: 0.0365, Accuracy: 98.44%\nEpoch [20/50], Step [420/1305], Loss: 0.0382, Accuracy: 98.44%\nEpoch [20/50], Step [450/1305], Loss: 0.1114, Accuracy: 96.88%\nEpoch [20/50], Step [480/1305], Loss: 0.0056, Accuracy: 100.00%\nEpoch [20/50], Step [510/1305], Loss: 0.0568, Accuracy: 96.88%\nEpoch [20/50], Step [540/1305], Loss: 0.0657, Accuracy: 98.44%\nEpoch [20/50], Step [570/1305], Loss: 0.0081, Accuracy: 100.00%\nEpoch [20/50], Step [600/1305], Loss: 0.0323, Accuracy: 98.44%\nEpoch [20/50], Step [630/1305], Loss: 0.2084, Accuracy: 95.31%\nEpoch [20/50], Step [660/1305], Loss: 0.0047, Accuracy: 100.00%\nEpoch [20/50], Step [690/1305], Loss: 0.0275, Accuracy: 98.44%\nEpoch [20/50], Step [720/1305], Loss: 0.0288, Accuracy: 98.44%\nEpoch [20/50], Step [750/1305], Loss: 0.0122, Accuracy: 100.00%\nEpoch [20/50], Step [780/1305], Loss: 0.0096, Accuracy: 100.00%\nEpoch [20/50], Step [810/1305], Loss: 0.0503, Accuracy: 98.44%\nEpoch [20/50], Step [840/1305], Loss: 0.0035, Accuracy: 100.00%\nEpoch [20/50], Step [870/1305], Loss: 0.0540, Accuracy: 96.88%\nEpoch [20/50], Step [900/1305], Loss: 0.0848, Accuracy: 96.88%\nEpoch [20/50], Step [930/1305], Loss: 0.0399, Accuracy: 100.00%\nEpoch [20/50], Step [960/1305], Loss: 0.0557, Accuracy: 96.88%\nEpoch [20/50], Step [990/1305], Loss: 0.0377, Accuracy: 100.00%\nEpoch [20/50], Step [1020/1305], Loss: 0.0271, Accuracy: 100.00%\nEpoch [20/50], Step [1050/1305], Loss: 0.1038, Accuracy: 96.88%\nEpoch [20/50], Step [1080/1305], Loss: 0.0403, Accuracy: 100.00%\nEpoch [20/50], Step [1110/1305], Loss: 0.1254, Accuracy: 98.44%\nEpoch [20/50], Step [1140/1305], Loss: 0.0441, Accuracy: 96.88%\nEpoch [20/50], Step [1170/1305], Loss: 0.0324, Accuracy: 98.44%\nEpoch [20/50], Step [1200/1305], Loss: 0.0562, Accuracy: 96.88%\nEpoch [20/50], Step [1230/1305], Loss: 0.0352, Accuracy: 98.44%\nEpoch [20/50], Step [1260/1305], Loss: 0.0487, Accuracy: 96.88%\nEpoch [20/50], Step [1290/1305], Loss: 0.0163, Accuracy: 100.00%\nStart validation #20\nValidation #20  Accuracy: 100.00%  Average Loss: 0.0173\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97fd9da891f4d55ab32ea11c7346f1a"}},"metadata":{}},{"name":"stdout","text":"Epoch [21/50], Step [30/1305], Loss: 0.0640, Accuracy: 98.44%\nEpoch [21/50], Step [60/1305], Loss: 0.0354, Accuracy: 96.88%\nEpoch [21/50], Step [90/1305], Loss: 0.0045, Accuracy: 100.00%\nEpoch [21/50], Step [120/1305], Loss: 0.0096, Accuracy: 100.00%\nEpoch [21/50], Step [150/1305], Loss: 0.0017, Accuracy: 100.00%\nEpoch [21/50], Step [180/1305], Loss: 0.0114, Accuracy: 100.00%\nEpoch [21/50], Step [210/1305], Loss: 0.0896, Accuracy: 96.88%\nEpoch [21/50], Step [240/1305], Loss: 0.0095, Accuracy: 100.00%\nEpoch [21/50], Step [270/1305], Loss: 0.0741, Accuracy: 98.44%\nEpoch [21/50], Step [300/1305], Loss: 0.0607, Accuracy: 96.88%\nEpoch [21/50], Step [330/1305], Loss: 0.0559, Accuracy: 98.44%\nEpoch [21/50], Step [360/1305], Loss: 0.0208, Accuracy: 100.00%\nEpoch [21/50], Step [390/1305], Loss: 0.1427, Accuracy: 96.88%\nEpoch [21/50], Step [420/1305], Loss: 0.1206, Accuracy: 96.88%\nEpoch [21/50], Step [450/1305], Loss: 0.0338, Accuracy: 100.00%\nEpoch [21/50], Step [480/1305], Loss: 0.0267, Accuracy: 98.44%\nEpoch [21/50], Step [510/1305], Loss: 0.0254, Accuracy: 98.44%\nEpoch [21/50], Step [540/1305], Loss: 0.0111, Accuracy: 100.00%\nEpoch [21/50], Step [570/1305], Loss: 0.0162, Accuracy: 100.00%\nEpoch [21/50], Step [600/1305], Loss: 0.0100, Accuracy: 100.00%\nEpoch [21/50], Step [630/1305], Loss: 0.0506, Accuracy: 98.44%\nEpoch [21/50], Step [660/1305], Loss: 0.0829, Accuracy: 98.44%\nEpoch [21/50], Step [690/1305], Loss: 0.0202, Accuracy: 100.00%\nEpoch [21/50], Step [720/1305], Loss: 0.0806, Accuracy: 98.44%\nEpoch [21/50], Step [750/1305], Loss: 0.0779, Accuracy: 98.44%\nEpoch [21/50], Step [780/1305], Loss: 0.0310, Accuracy: 100.00%\nEpoch [21/50], Step [810/1305], Loss: 0.0060, Accuracy: 100.00%\nEpoch [21/50], Step [840/1305], Loss: 0.0269, Accuracy: 98.44%\nEpoch [21/50], Step [870/1305], Loss: 0.0087, Accuracy: 100.00%\nEpoch [21/50], Step [900/1305], Loss: 0.0083, Accuracy: 100.00%\nEpoch [21/50], Step [930/1305], Loss: 0.0048, Accuracy: 100.00%\nEpoch [21/50], Step [960/1305], Loss: 0.1456, Accuracy: 98.44%\nEpoch [21/50], Step [990/1305], Loss: 0.0101, Accuracy: 100.00%\nEpoch [21/50], Step [1020/1305], Loss: 0.0079, Accuracy: 100.00%\nEpoch [21/50], Step [1050/1305], Loss: 0.0329, Accuracy: 98.44%\nEpoch [21/50], Step [1080/1305], Loss: 0.0107, Accuracy: 100.00%\nEpoch [21/50], Step [1110/1305], Loss: 0.0837, Accuracy: 96.88%\nEpoch [21/50], Step [1140/1305], Loss: 0.0389, Accuracy: 98.44%\nEpoch [21/50], Step [1170/1305], Loss: 0.0313, Accuracy: 98.44%\nEpoch [21/50], Step [1200/1305], Loss: 0.0048, Accuracy: 100.00%\nEpoch [21/50], Step [1230/1305], Loss: 0.0108, Accuracy: 100.00%\nEpoch [21/50], Step [1260/1305], Loss: 0.0102, Accuracy: 100.00%\nEpoch [21/50], Step [1290/1305], Loss: 0.0183, Accuracy: 100.00%\nStart validation #21\nValidation #21  Accuracy: 96.88%  Average Loss: 0.0288\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b217a70a2634cd482dbdc1adb3dd332"}},"metadata":{}},{"name":"stdout","text":"Epoch [22/50], Step [30/1305], Loss: 0.0024, Accuracy: 100.00%\nEpoch [22/50], Step [60/1305], Loss: 0.0310, Accuracy: 98.44%\nEpoch [22/50], Step [90/1305], Loss: 0.0980, Accuracy: 93.75%\nEpoch [22/50], Step [120/1305], Loss: 0.1692, Accuracy: 96.88%\nEpoch [22/50], Step [150/1305], Loss: 0.0338, Accuracy: 100.00%\nEpoch [22/50], Step [180/1305], Loss: 0.0831, Accuracy: 98.44%\nEpoch [22/50], Step [210/1305], Loss: 0.0786, Accuracy: 98.44%\nEpoch [22/50], Step [240/1305], Loss: 0.0052, Accuracy: 100.00%\nEpoch [22/50], Step [270/1305], Loss: 0.0677, Accuracy: 98.44%\nEpoch [22/50], Step [300/1305], Loss: 0.0239, Accuracy: 100.00%\nEpoch [22/50], Step [330/1305], Loss: 0.0189, Accuracy: 98.44%\nEpoch [22/50], Step [360/1305], Loss: 0.0292, Accuracy: 98.44%\nEpoch [22/50], Step [390/1305], Loss: 0.0172, Accuracy: 100.00%\nEpoch [22/50], Step [420/1305], Loss: 0.0376, Accuracy: 98.44%\nEpoch [22/50], Step [450/1305], Loss: 0.0293, Accuracy: 98.44%\nEpoch [22/50], Step [480/1305], Loss: 0.0371, Accuracy: 98.44%\nEpoch [22/50], Step [510/1305], Loss: 0.0218, Accuracy: 98.44%\nEpoch [22/50], Step [540/1305], Loss: 0.0642, Accuracy: 98.44%\nEpoch [22/50], Step [570/1305], Loss: 0.0279, Accuracy: 98.44%\nEpoch [22/50], Step [600/1305], Loss: 0.0317, Accuracy: 100.00%\nEpoch [22/50], Step [630/1305], Loss: 0.0452, Accuracy: 98.44%\nEpoch [22/50], Step [660/1305], Loss: 0.0544, Accuracy: 98.44%\nEpoch [22/50], Step [690/1305], Loss: 0.0273, Accuracy: 100.00%\nEpoch [22/50], Step [720/1305], Loss: 0.0320, Accuracy: 98.44%\nEpoch [22/50], Step [750/1305], Loss: 0.0115, Accuracy: 100.00%\nEpoch [22/50], Step [780/1305], Loss: 0.0315, Accuracy: 100.00%\nEpoch [22/50], Step [810/1305], Loss: 0.0767, Accuracy: 96.88%\nEpoch [22/50], Step [840/1305], Loss: 0.0715, Accuracy: 96.88%\nEpoch [22/50], Step [870/1305], Loss: 0.0713, Accuracy: 98.44%\nEpoch [22/50], Step [900/1305], Loss: 0.0056, Accuracy: 100.00%\nEpoch [22/50], Step [930/1305], Loss: 0.0438, Accuracy: 98.44%\nEpoch [22/50], Step [960/1305], Loss: 0.0896, Accuracy: 95.31%\nEpoch [22/50], Step [990/1305], Loss: 0.0437, Accuracy: 100.00%\nEpoch [22/50], Step [1020/1305], Loss: 0.0695, Accuracy: 98.44%\nEpoch [22/50], Step [1050/1305], Loss: 0.0170, Accuracy: 98.44%\nEpoch [22/50], Step [1080/1305], Loss: 0.0092, Accuracy: 100.00%\nEpoch [22/50], Step [1110/1305], Loss: 0.0270, Accuracy: 100.00%\nEpoch [22/50], Step [1140/1305], Loss: 0.0405, Accuracy: 98.44%\nEpoch [22/50], Step [1170/1305], Loss: 0.0506, Accuracy: 98.44%\nEpoch [22/50], Step [1200/1305], Loss: 0.0094, Accuracy: 100.00%\nEpoch [22/50], Step [1230/1305], Loss: 0.0103, Accuracy: 100.00%\nEpoch [22/50], Step [1260/1305], Loss: 0.0825, Accuracy: 96.88%\nEpoch [22/50], Step [1290/1305], Loss: 0.0288, Accuracy: 98.44%\nStart validation #22\nValidation #22  Accuracy: 100.00%  Average Loss: 0.0250\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"415aefad9f2644b1ad63c48b8eda585e"}},"metadata":{}},{"name":"stdout","text":"Epoch [23/50], Step [30/1305], Loss: 0.1226, Accuracy: 98.44%\nEpoch [23/50], Step [60/1305], Loss: 0.0854, Accuracy: 98.44%\nEpoch [23/50], Step [90/1305], Loss: 0.0038, Accuracy: 100.00%\nEpoch [23/50], Step [120/1305], Loss: 0.0310, Accuracy: 98.44%\nEpoch [23/50], Step [150/1305], Loss: 0.0051, Accuracy: 100.00%\nEpoch [23/50], Step [180/1305], Loss: 0.0190, Accuracy: 100.00%\nEpoch [23/50], Step [210/1305], Loss: 0.0414, Accuracy: 98.44%\nEpoch [23/50], Step [240/1305], Loss: 0.0067, Accuracy: 100.00%\nEpoch [23/50], Step [270/1305], Loss: 0.1065, Accuracy: 98.44%\nEpoch [23/50], Step [300/1305], Loss: 0.0576, Accuracy: 98.44%\nEpoch [23/50], Step [330/1305], Loss: 0.0073, Accuracy: 100.00%\nEpoch [23/50], Step [360/1305], Loss: 0.0816, Accuracy: 98.44%\nEpoch [23/50], Step [390/1305], Loss: 0.0306, Accuracy: 100.00%\nEpoch [23/50], Step [420/1305], Loss: 0.0726, Accuracy: 98.44%\nEpoch [23/50], Step [450/1305], Loss: 0.0058, Accuracy: 100.00%\nEpoch [23/50], Step [480/1305], Loss: 0.0040, Accuracy: 100.00%\nEpoch [23/50], Step [510/1305], Loss: 0.0088, Accuracy: 100.00%\nEpoch [23/50], Step [540/1305], Loss: 0.0484, Accuracy: 96.88%\nEpoch [23/50], Step [570/1305], Loss: 0.1236, Accuracy: 98.44%\nEpoch [23/50], Step [600/1305], Loss: 0.0140, Accuracy: 100.00%\nEpoch [23/50], Step [630/1305], Loss: 0.0495, Accuracy: 98.44%\nEpoch [23/50], Step [660/1305], Loss: 0.0271, Accuracy: 98.44%\nEpoch [23/50], Step [690/1305], Loss: 0.0170, Accuracy: 100.00%\nEpoch [23/50], Step [720/1305], Loss: 0.0295, Accuracy: 100.00%\nEpoch [23/50], Step [750/1305], Loss: 0.0221, Accuracy: 100.00%\nEpoch [23/50], Step [780/1305], Loss: 0.0370, Accuracy: 98.44%\nEpoch [23/50], Step [810/1305], Loss: 0.0069, Accuracy: 100.00%\nEpoch [23/50], Step [840/1305], Loss: 0.0457, Accuracy: 100.00%\nEpoch [23/50], Step [870/1305], Loss: 0.1148, Accuracy: 95.31%\nEpoch [23/50], Step [900/1305], Loss: 0.0586, Accuracy: 98.44%\nEpoch [23/50], Step [930/1305], Loss: 0.1041, Accuracy: 98.44%\nEpoch [23/50], Step [960/1305], Loss: 0.0568, Accuracy: 98.44%\nEpoch [23/50], Step [990/1305], Loss: 0.0347, Accuracy: 98.44%\nEpoch [23/50], Step [1020/1305], Loss: 0.0519, Accuracy: 98.44%\nEpoch [23/50], Step [1050/1305], Loss: 0.0520, Accuracy: 98.44%\nEpoch [23/50], Step [1080/1305], Loss: 0.0219, Accuracy: 100.00%\nEpoch [23/50], Step [1110/1305], Loss: 0.0127, Accuracy: 100.00%\nEpoch [23/50], Step [1140/1305], Loss: 0.0589, Accuracy: 96.88%\nEpoch [23/50], Step [1170/1305], Loss: 0.0087, Accuracy: 100.00%\nEpoch [23/50], Step [1200/1305], Loss: 0.0074, Accuracy: 100.00%\nEpoch [23/50], Step [1230/1305], Loss: 0.0223, Accuracy: 100.00%\nEpoch [23/50], Step [1260/1305], Loss: 0.0577, Accuracy: 98.44%\nEpoch [23/50], Step [1290/1305], Loss: 0.0767, Accuracy: 98.44%\nStart validation #23\nValidation #23  Accuracy: 100.00%  Average Loss: 0.0311\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f033a6a9c6d5415d814c1b93613a50cd"}},"metadata":{}},{"name":"stdout","text":"Epoch [24/50], Step [30/1305], Loss: 0.0160, Accuracy: 100.00%\nEpoch [24/50], Step [60/1305], Loss: 0.0116, Accuracy: 100.00%\nEpoch [24/50], Step [90/1305], Loss: 0.0409, Accuracy: 98.44%\nEpoch [24/50], Step [120/1305], Loss: 0.0107, Accuracy: 100.00%\nEpoch [24/50], Step [150/1305], Loss: 0.0245, Accuracy: 100.00%\nEpoch [24/50], Step [180/1305], Loss: 0.0373, Accuracy: 98.44%\nEpoch [24/50], Step [210/1305], Loss: 0.0400, Accuracy: 98.44%\nEpoch [24/50], Step [240/1305], Loss: 0.0176, Accuracy: 100.00%\nEpoch [24/50], Step [270/1305], Loss: 0.0009, Accuracy: 100.00%\nEpoch [24/50], Step [300/1305], Loss: 0.0098, Accuracy: 100.00%\nEpoch [24/50], Step [330/1305], Loss: 0.0155, Accuracy: 98.44%\nEpoch [24/50], Step [360/1305], Loss: 0.0110, Accuracy: 100.00%\nEpoch [24/50], Step [390/1305], Loss: 0.0033, Accuracy: 100.00%\nEpoch [24/50], Step [420/1305], Loss: 0.0153, Accuracy: 100.00%\nEpoch [24/50], Step [450/1305], Loss: 0.0061, Accuracy: 100.00%\nEpoch [24/50], Step [480/1305], Loss: 0.0316, Accuracy: 100.00%\nEpoch [24/50], Step [510/1305], Loss: 0.0692, Accuracy: 96.88%\nEpoch [24/50], Step [540/1305], Loss: 0.0177, Accuracy: 100.00%\nEpoch [24/50], Step [570/1305], Loss: 0.0068, Accuracy: 100.00%\nEpoch [24/50], Step [600/1305], Loss: 0.0080, Accuracy: 100.00%\nEpoch [24/50], Step [630/1305], Loss: 0.0130, Accuracy: 100.00%\nEpoch [24/50], Step [660/1305], Loss: 0.0227, Accuracy: 100.00%\nEpoch [24/50], Step [690/1305], Loss: 0.0475, Accuracy: 98.44%\nEpoch [24/50], Step [720/1305], Loss: 0.0328, Accuracy: 98.44%\nEpoch [24/50], Step [750/1305], Loss: 0.0730, Accuracy: 98.44%\nEpoch [24/50], Step [780/1305], Loss: 0.0480, Accuracy: 98.44%\nEpoch [24/50], Step [810/1305], Loss: 0.0046, Accuracy: 100.00%\nEpoch [24/50], Step [840/1305], Loss: 0.0157, Accuracy: 100.00%\nEpoch [24/50], Step [870/1305], Loss: 0.0389, Accuracy: 98.44%\nEpoch [24/50], Step [900/1305], Loss: 0.0148, Accuracy: 100.00%\nEpoch [24/50], Step [930/1305], Loss: 0.0743, Accuracy: 96.88%\nEpoch [24/50], Step [960/1305], Loss: 0.0618, Accuracy: 98.44%\nEpoch [24/50], Step [990/1305], Loss: 0.0095, Accuracy: 100.00%\nEpoch [24/50], Step [1020/1305], Loss: 0.0305, Accuracy: 98.44%\nEpoch [24/50], Step [1050/1305], Loss: 0.0106, Accuracy: 100.00%\nEpoch [24/50], Step [1080/1305], Loss: 0.0104, Accuracy: 100.00%\nEpoch [24/50], Step [1110/1305], Loss: 0.0990, Accuracy: 96.88%\nEpoch [24/50], Step [1140/1305], Loss: 0.0796, Accuracy: 98.44%\nEpoch [24/50], Step [1170/1305], Loss: 0.1061, Accuracy: 95.31%\nEpoch [24/50], Step [1200/1305], Loss: 0.0394, Accuracy: 98.44%\nEpoch [24/50], Step [1230/1305], Loss: 0.0672, Accuracy: 98.44%\nEpoch [24/50], Step [1260/1305], Loss: 0.0566, Accuracy: 98.44%\nEpoch [24/50], Step [1290/1305], Loss: 0.0035, Accuracy: 100.00%\nStart validation #24\nValidation #24  Accuracy: 100.00%  Average Loss: 0.0391\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03c3a2a359c046b68960653d0c438e7e"}},"metadata":{}},{"name":"stdout","text":"Epoch [25/50], Step [30/1305], Loss: 0.0209, Accuracy: 100.00%\nEpoch [25/50], Step [60/1305], Loss: 0.0361, Accuracy: 98.44%\nEpoch [25/50], Step [90/1305], Loss: 0.0130, Accuracy: 100.00%\nEpoch [25/50], Step [120/1305], Loss: 0.0444, Accuracy: 96.88%\nEpoch [25/50], Step [150/1305], Loss: 0.0016, Accuracy: 100.00%\nEpoch [25/50], Step [180/1305], Loss: 0.0099, Accuracy: 100.00%\nEpoch [25/50], Step [210/1305], Loss: 0.0588, Accuracy: 98.44%\nEpoch [25/50], Step [240/1305], Loss: 0.0053, Accuracy: 100.00%\nEpoch [25/50], Step [270/1305], Loss: 0.0320, Accuracy: 98.44%\nEpoch [25/50], Step [300/1305], Loss: 0.0694, Accuracy: 98.44%\nEpoch [25/50], Step [330/1305], Loss: 0.0354, Accuracy: 98.44%\nEpoch [25/50], Step [360/1305], Loss: 0.0838, Accuracy: 98.44%\nEpoch [25/50], Step [390/1305], Loss: 0.0516, Accuracy: 98.44%\nEpoch [25/50], Step [420/1305], Loss: 0.0177, Accuracy: 100.00%\nEpoch [25/50], Step [450/1305], Loss: 0.0234, Accuracy: 100.00%\nEpoch [25/50], Step [480/1305], Loss: 0.0221, Accuracy: 98.44%\nEpoch [25/50], Step [510/1305], Loss: 0.0312, Accuracy: 98.44%\nEpoch [25/50], Step [540/1305], Loss: 0.0508, Accuracy: 96.88%\nEpoch [25/50], Step [570/1305], Loss: 0.0464, Accuracy: 98.44%\nEpoch [25/50], Step [600/1305], Loss: 0.0243, Accuracy: 100.00%\nEpoch [25/50], Step [630/1305], Loss: 0.0014, Accuracy: 100.00%\nEpoch [25/50], Step [660/1305], Loss: 0.0020, Accuracy: 100.00%\nEpoch [25/50], Step [690/1305], Loss: 0.0327, Accuracy: 98.44%\nEpoch [25/50], Step [720/1305], Loss: 0.1836, Accuracy: 96.88%\nEpoch [25/50], Step [750/1305], Loss: 0.0545, Accuracy: 98.44%\nEpoch [25/50], Step [780/1305], Loss: 0.0712, Accuracy: 96.88%\nEpoch [25/50], Step [810/1305], Loss: 0.1341, Accuracy: 98.44%\nEpoch [25/50], Step [840/1305], Loss: 0.0334, Accuracy: 100.00%\nEpoch [25/50], Step [870/1305], Loss: 0.0523, Accuracy: 98.44%\nEpoch [25/50], Step [900/1305], Loss: 0.0048, Accuracy: 100.00%\nEpoch [25/50], Step [930/1305], Loss: 0.1256, Accuracy: 95.31%\nEpoch [25/50], Step [960/1305], Loss: 0.0106, Accuracy: 100.00%\nEpoch [25/50], Step [990/1305], Loss: 0.0044, Accuracy: 100.00%\nEpoch [25/50], Step [1020/1305], Loss: 0.0784, Accuracy: 96.88%\nEpoch [25/50], Step [1050/1305], Loss: 0.0097, Accuracy: 100.00%\nEpoch [25/50], Step [1080/1305], Loss: 0.0998, Accuracy: 98.44%\nEpoch [25/50], Step [1110/1305], Loss: 0.0608, Accuracy: 98.44%\nEpoch [25/50], Step [1140/1305], Loss: 0.0667, Accuracy: 96.88%\nEpoch [25/50], Step [1170/1305], Loss: 0.1000, Accuracy: 98.44%\nEpoch [25/50], Step [1200/1305], Loss: 0.0874, Accuracy: 96.88%\nEpoch [25/50], Step [1230/1305], Loss: 0.0408, Accuracy: 98.44%\nEpoch [25/50], Step [1260/1305], Loss: 0.0278, Accuracy: 98.44%\nEpoch [25/50], Step [1290/1305], Loss: 0.0140, Accuracy: 100.00%\nStart validation #25\nValidation #25  Accuracy: 100.00%  Average Loss: 0.0070\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6bcd8c061c040c0a85bad2fb2b0b54c"}},"metadata":{}},{"name":"stdout","text":"Epoch [26/50], Step [30/1305], Loss: 0.0321, Accuracy: 100.00%\nEpoch [26/50], Step [60/1305], Loss: 0.0542, Accuracy: 96.88%\nEpoch [26/50], Step [90/1305], Loss: 0.0335, Accuracy: 98.44%\nEpoch [26/50], Step [120/1305], Loss: 0.0172, Accuracy: 100.00%\nEpoch [26/50], Step [150/1305], Loss: 0.0082, Accuracy: 100.00%\nEpoch [26/50], Step [180/1305], Loss: 0.1185, Accuracy: 96.88%\nEpoch [26/50], Step [210/1305], Loss: 0.0312, Accuracy: 96.88%\nEpoch [26/50], Step [240/1305], Loss: 0.0092, Accuracy: 100.00%\nEpoch [26/50], Step [270/1305], Loss: 0.0112, Accuracy: 100.00%\nEpoch [26/50], Step [300/1305], Loss: 0.0047, Accuracy: 100.00%\nEpoch [26/50], Step [330/1305], Loss: 0.0569, Accuracy: 98.44%\nEpoch [26/50], Step [360/1305], Loss: 0.0335, Accuracy: 98.44%\nEpoch [26/50], Step [390/1305], Loss: 0.0606, Accuracy: 98.44%\nEpoch [26/50], Step [420/1305], Loss: 0.0082, Accuracy: 100.00%\nEpoch [26/50], Step [450/1305], Loss: 0.0034, Accuracy: 100.00%\nEpoch [26/50], Step [480/1305], Loss: 0.0065, Accuracy: 100.00%\nEpoch [26/50], Step [510/1305], Loss: 0.0558, Accuracy: 96.88%\nEpoch [26/50], Step [540/1305], Loss: 0.0095, Accuracy: 100.00%\nEpoch [26/50], Step [570/1305], Loss: 0.0188, Accuracy: 100.00%\nEpoch [26/50], Step [600/1305], Loss: 0.0393, Accuracy: 98.44%\nEpoch [26/50], Step [630/1305], Loss: 0.1030, Accuracy: 96.88%\nEpoch [26/50], Step [660/1305], Loss: 0.0404, Accuracy: 98.44%\nEpoch [26/50], Step [690/1305], Loss: 0.0452, Accuracy: 98.44%\nEpoch [26/50], Step [720/1305], Loss: 0.0118, Accuracy: 100.00%\nEpoch [26/50], Step [750/1305], Loss: 0.0408, Accuracy: 96.88%\nEpoch [26/50], Step [780/1305], Loss: 0.0678, Accuracy: 96.88%\nEpoch [26/50], Step [810/1305], Loss: 0.0384, Accuracy: 98.44%\nEpoch [26/50], Step [840/1305], Loss: 0.0443, Accuracy: 100.00%\nEpoch [26/50], Step [870/1305], Loss: 0.0054, Accuracy: 100.00%\nEpoch [26/50], Step [900/1305], Loss: 0.0074, Accuracy: 100.00%\nEpoch [26/50], Step [930/1305], Loss: 0.0458, Accuracy: 98.44%\nEpoch [26/50], Step [960/1305], Loss: 0.0196, Accuracy: 98.44%\nEpoch [26/50], Step [990/1305], Loss: 0.0070, Accuracy: 100.00%\nEpoch [26/50], Step [1020/1305], Loss: 0.0044, Accuracy: 100.00%\nEpoch [26/50], Step [1050/1305], Loss: 0.0564, Accuracy: 98.44%\nEpoch [26/50], Step [1080/1305], Loss: 0.0235, Accuracy: 98.44%\nEpoch [26/50], Step [1110/1305], Loss: 0.0138, Accuracy: 100.00%\nEpoch [26/50], Step [1140/1305], Loss: 0.0277, Accuracy: 98.44%\nEpoch [26/50], Step [1170/1305], Loss: 0.0308, Accuracy: 98.44%\nEpoch [26/50], Step [1200/1305], Loss: 0.0281, Accuracy: 98.44%\nEpoch [26/50], Step [1230/1305], Loss: 0.0325, Accuracy: 100.00%\nEpoch [26/50], Step [1260/1305], Loss: 0.0585, Accuracy: 98.44%\nEpoch [26/50], Step [1290/1305], Loss: 0.0351, Accuracy: 98.44%\nStart validation #26\nValidation #26  Accuracy: 96.88%  Average Loss: 0.0290\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7185896a838747f89d00f320d109cc9c"}},"metadata":{}},{"name":"stdout","text":"Epoch [27/50], Step [30/1305], Loss: 0.0139, Accuracy: 100.00%\nEpoch [27/50], Step [60/1305], Loss: 0.0148, Accuracy: 100.00%\nEpoch [27/50], Step [90/1305], Loss: 0.0559, Accuracy: 96.88%\nEpoch [27/50], Step [120/1305], Loss: 0.0141, Accuracy: 100.00%\nEpoch [27/50], Step [150/1305], Loss: 0.0065, Accuracy: 100.00%\nEpoch [27/50], Step [180/1305], Loss: 0.0135, Accuracy: 100.00%\nEpoch [27/50], Step [210/1305], Loss: 0.0286, Accuracy: 98.44%\nEpoch [27/50], Step [240/1305], Loss: 0.0381, Accuracy: 96.88%\nEpoch [27/50], Step [270/1305], Loss: 0.0293, Accuracy: 100.00%\nEpoch [27/50], Step [300/1305], Loss: 0.0152, Accuracy: 100.00%\nEpoch [27/50], Step [330/1305], Loss: 0.0171, Accuracy: 100.00%\nEpoch [27/50], Step [360/1305], Loss: 0.0302, Accuracy: 100.00%\nEpoch [27/50], Step [390/1305], Loss: 0.0083, Accuracy: 100.00%\nEpoch [27/50], Step [420/1305], Loss: 0.0240, Accuracy: 100.00%\nEpoch [27/50], Step [450/1305], Loss: 0.0143, Accuracy: 100.00%\nEpoch [27/50], Step [480/1305], Loss: 0.1182, Accuracy: 96.88%\nEpoch [27/50], Step [510/1305], Loss: 0.0326, Accuracy: 98.44%\nEpoch [27/50], Step [540/1305], Loss: 0.0010, Accuracy: 100.00%\nEpoch [27/50], Step [570/1305], Loss: 0.0541, Accuracy: 98.44%\nEpoch [27/50], Step [600/1305], Loss: 0.0157, Accuracy: 100.00%\nEpoch [27/50], Step [630/1305], Loss: 0.0741, Accuracy: 98.44%\nEpoch [27/50], Step [660/1305], Loss: 0.0239, Accuracy: 100.00%\nEpoch [27/50], Step [690/1305], Loss: 0.0088, Accuracy: 100.00%\nEpoch [27/50], Step [720/1305], Loss: 0.0604, Accuracy: 96.88%\nEpoch [27/50], Step [750/1305], Loss: 0.0546, Accuracy: 98.44%\nEpoch [27/50], Step [780/1305], Loss: 0.0268, Accuracy: 100.00%\nEpoch [27/50], Step [810/1305], Loss: 0.0305, Accuracy: 100.00%\nEpoch [27/50], Step [840/1305], Loss: 0.0047, Accuracy: 100.00%\nEpoch [27/50], Step [870/1305], Loss: 0.0266, Accuracy: 100.00%\nEpoch [27/50], Step [900/1305], Loss: 0.0176, Accuracy: 100.00%\nEpoch [27/50], Step [930/1305], Loss: 0.0032, Accuracy: 100.00%\nEpoch [27/50], Step [960/1305], Loss: 0.0680, Accuracy: 98.44%\nEpoch [27/50], Step [990/1305], Loss: 0.0293, Accuracy: 98.44%\nEpoch [27/50], Step [1020/1305], Loss: 0.0038, Accuracy: 100.00%\nEpoch [27/50], Step [1050/1305], Loss: 0.1324, Accuracy: 95.31%\nEpoch [27/50], Step [1080/1305], Loss: 0.0427, Accuracy: 98.44%\nEpoch [27/50], Step [1110/1305], Loss: 0.0132, Accuracy: 100.00%\nEpoch [27/50], Step [1140/1305], Loss: 0.1104, Accuracy: 95.31%\nEpoch [27/50], Step [1170/1305], Loss: 0.0397, Accuracy: 100.00%\nEpoch [27/50], Step [1200/1305], Loss: 0.0229, Accuracy: 100.00%\nEpoch [27/50], Step [1230/1305], Loss: 0.1496, Accuracy: 95.31%\nEpoch [27/50], Step [1260/1305], Loss: 0.0571, Accuracy: 96.88%\nEpoch [27/50], Step [1290/1305], Loss: 0.0506, Accuracy: 96.88%\nStart validation #27\nValidation #27  Accuracy: 100.00%  Average Loss: 0.0164\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b9498037d504b5cb6a4fbeb755c7d68"}},"metadata":{}},{"name":"stdout","text":"Epoch [28/50], Step [30/1305], Loss: 0.0157, Accuracy: 100.00%\nEpoch [28/50], Step [60/1305], Loss: 0.0058, Accuracy: 100.00%\nEpoch [28/50], Step [90/1305], Loss: 0.0621, Accuracy: 96.88%\nEpoch [28/50], Step [120/1305], Loss: 0.0217, Accuracy: 100.00%\nEpoch [28/50], Step [150/1305], Loss: 0.0276, Accuracy: 98.44%\nEpoch [28/50], Step [180/1305], Loss: 0.1302, Accuracy: 95.31%\nEpoch [28/50], Step [210/1305], Loss: 0.0260, Accuracy: 98.44%\nEpoch [28/50], Step [240/1305], Loss: 0.0248, Accuracy: 100.00%\nEpoch [28/50], Step [270/1305], Loss: 0.0054, Accuracy: 100.00%\nEpoch [28/50], Step [300/1305], Loss: 0.0371, Accuracy: 98.44%\nEpoch [28/50], Step [330/1305], Loss: 0.1460, Accuracy: 96.88%\nEpoch [28/50], Step [360/1305], Loss: 0.0026, Accuracy: 100.00%\nEpoch [28/50], Step [390/1305], Loss: 0.0528, Accuracy: 98.44%\nEpoch [28/50], Step [420/1305], Loss: 0.0041, Accuracy: 100.00%\nEpoch [28/50], Step [450/1305], Loss: 0.0197, Accuracy: 100.00%\nEpoch [28/50], Step [480/1305], Loss: 0.0029, Accuracy: 100.00%\nEpoch [28/50], Step [510/1305], Loss: 0.0229, Accuracy: 100.00%\nEpoch [28/50], Step [540/1305], Loss: 0.0199, Accuracy: 100.00%\nEpoch [28/50], Step [570/1305], Loss: 0.0210, Accuracy: 100.00%\nEpoch [28/50], Step [600/1305], Loss: 0.0179, Accuracy: 100.00%\nEpoch [28/50], Step [630/1305], Loss: 0.0192, Accuracy: 98.44%\nEpoch [28/50], Step [660/1305], Loss: 0.0043, Accuracy: 100.00%\nEpoch [28/50], Step [690/1305], Loss: 0.0467, Accuracy: 96.88%\nEpoch [28/50], Step [720/1305], Loss: 0.0787, Accuracy: 98.44%\nEpoch [28/50], Step [750/1305], Loss: 0.0670, Accuracy: 98.44%\nEpoch [28/50], Step [780/1305], Loss: 0.0243, Accuracy: 98.44%\nEpoch [28/50], Step [810/1305], Loss: 0.0161, Accuracy: 100.00%\nEpoch [28/50], Step [840/1305], Loss: 0.0156, Accuracy: 100.00%\nEpoch [28/50], Step [870/1305], Loss: 0.0373, Accuracy: 98.44%\nEpoch [28/50], Step [900/1305], Loss: 0.0173, Accuracy: 100.00%\nEpoch [28/50], Step [930/1305], Loss: 0.0183, Accuracy: 100.00%\nEpoch [28/50], Step [960/1305], Loss: 0.0836, Accuracy: 96.88%\nEpoch [28/50], Step [990/1305], Loss: 0.0269, Accuracy: 98.44%\nEpoch [28/50], Step [1020/1305], Loss: 0.0227, Accuracy: 98.44%\nEpoch [28/50], Step [1050/1305], Loss: 0.0008, Accuracy: 100.00%\nEpoch [28/50], Step [1080/1305], Loss: 0.0034, Accuracy: 100.00%\nEpoch [28/50], Step [1110/1305], Loss: 0.0322, Accuracy: 100.00%\nEpoch [28/50], Step [1140/1305], Loss: 0.0241, Accuracy: 98.44%\nEpoch [28/50], Step [1170/1305], Loss: 0.0425, Accuracy: 98.44%\nEpoch [28/50], Step [1200/1305], Loss: 0.0009, Accuracy: 100.00%\nEpoch [28/50], Step [1230/1305], Loss: 0.0438, Accuracy: 98.44%\nEpoch [28/50], Step [1260/1305], Loss: 0.0745, Accuracy: 98.44%\nEpoch [28/50], Step [1290/1305], Loss: 0.0041, Accuracy: 100.00%\nStart validation #28\nValidation #28  Accuracy: 100.00%  Average Loss: 0.0158\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fca5a158f33491e9b4d10800b2c0eaf"}},"metadata":{}},{"name":"stdout","text":"Epoch [29/50], Step [30/1305], Loss: 0.0143, Accuracy: 100.00%\nEpoch [29/50], Step [60/1305], Loss: 0.0671, Accuracy: 96.88%\nEpoch [29/50], Step [90/1305], Loss: 0.0061, Accuracy: 100.00%\nEpoch [29/50], Step [120/1305], Loss: 0.0137, Accuracy: 100.00%\nEpoch [29/50], Step [150/1305], Loss: 0.0147, Accuracy: 100.00%\nEpoch [29/50], Step [180/1305], Loss: 0.0055, Accuracy: 100.00%\nEpoch [29/50], Step [210/1305], Loss: 0.0256, Accuracy: 98.44%\nEpoch [29/50], Step [240/1305], Loss: 0.0652, Accuracy: 98.44%\nEpoch [29/50], Step [270/1305], Loss: 0.0178, Accuracy: 100.00%\nEpoch [29/50], Step [300/1305], Loss: 0.0083, Accuracy: 100.00%\nEpoch [29/50], Step [330/1305], Loss: 0.0545, Accuracy: 98.44%\nEpoch [29/50], Step [360/1305], Loss: 0.0320, Accuracy: 98.44%\nEpoch [29/50], Step [390/1305], Loss: 0.0366, Accuracy: 98.44%\nEpoch [29/50], Step [420/1305], Loss: 0.2677, Accuracy: 98.44%\nEpoch [29/50], Step [450/1305], Loss: 0.0070, Accuracy: 100.00%\nEpoch [29/50], Step [480/1305], Loss: 0.0113, Accuracy: 100.00%\nEpoch [29/50], Step [510/1305], Loss: 0.0047, Accuracy: 100.00%\nEpoch [29/50], Step [540/1305], Loss: 0.0197, Accuracy: 98.44%\nEpoch [29/50], Step [570/1305], Loss: 0.0130, Accuracy: 100.00%\nEpoch [29/50], Step [600/1305], Loss: 0.0179, Accuracy: 100.00%\nEpoch [29/50], Step [630/1305], Loss: 0.0900, Accuracy: 95.31%\nEpoch [29/50], Step [660/1305], Loss: 0.0038, Accuracy: 100.00%\nEpoch [29/50], Step [690/1305], Loss: 0.0148, Accuracy: 100.00%\nEpoch [29/50], Step [720/1305], Loss: 0.0434, Accuracy: 98.44%\nEpoch [29/50], Step [750/1305], Loss: 0.0329, Accuracy: 98.44%\nEpoch [29/50], Step [780/1305], Loss: 0.0025, Accuracy: 100.00%\nEpoch [29/50], Step [810/1305], Loss: 0.0045, Accuracy: 100.00%\nEpoch [29/50], Step [840/1305], Loss: 0.0661, Accuracy: 98.44%\nEpoch [29/50], Step [870/1305], Loss: 0.1203, Accuracy: 96.88%\nEpoch [29/50], Step [900/1305], Loss: 0.0648, Accuracy: 98.44%\nEpoch [29/50], Step [930/1305], Loss: 0.0195, Accuracy: 100.00%\nEpoch [29/50], Step [960/1305], Loss: 0.0477, Accuracy: 98.44%\nEpoch [29/50], Step [990/1305], Loss: 0.0025, Accuracy: 100.00%\nEpoch [29/50], Step [1020/1305], Loss: 0.0203, Accuracy: 100.00%\nEpoch [29/50], Step [1050/1305], Loss: 0.0375, Accuracy: 98.44%\nEpoch [29/50], Step [1080/1305], Loss: 0.0489, Accuracy: 98.44%\nEpoch [29/50], Step [1110/1305], Loss: 0.0049, Accuracy: 100.00%\nEpoch [29/50], Step [1140/1305], Loss: 0.0253, Accuracy: 100.00%\nEpoch [29/50], Step [1170/1305], Loss: 0.0550, Accuracy: 98.44%\nEpoch [29/50], Step [1200/1305], Loss: 0.0041, Accuracy: 100.00%\nEpoch [29/50], Step [1230/1305], Loss: 0.0827, Accuracy: 98.44%\nEpoch [29/50], Step [1260/1305], Loss: 0.0525, Accuracy: 98.44%\nEpoch [29/50], Step [1290/1305], Loss: 0.0212, Accuracy: 100.00%\nStart validation #29\nValidation #29  Accuracy: 100.00%  Average Loss: 0.0233\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d59d2550bc4c99bfaf3bca2f241926"}},"metadata":{}},{"name":"stdout","text":"Epoch [30/50], Step [30/1305], Loss: 0.0188, Accuracy: 100.00%\nEpoch [30/50], Step [60/1305], Loss: 0.0085, Accuracy: 100.00%\nEpoch [30/50], Step [90/1305], Loss: 0.0959, Accuracy: 98.44%\nEpoch [30/50], Step [120/1305], Loss: 0.0229, Accuracy: 100.00%\nEpoch [30/50], Step [150/1305], Loss: 0.0134, Accuracy: 100.00%\nEpoch [30/50], Step [180/1305], Loss: 0.0208, Accuracy: 98.44%\nEpoch [30/50], Step [210/1305], Loss: 0.1396, Accuracy: 98.44%\nEpoch [30/50], Step [240/1305], Loss: 0.0010, Accuracy: 100.00%\nEpoch [30/50], Step [270/1305], Loss: 0.0166, Accuracy: 100.00%\nEpoch [30/50], Step [300/1305], Loss: 0.0006, Accuracy: 100.00%\nEpoch [30/50], Step [330/1305], Loss: 0.0012, Accuracy: 100.00%\nEpoch [30/50], Step [360/1305], Loss: 0.0379, Accuracy: 100.00%\nEpoch [30/50], Step [390/1305], Loss: 0.0044, Accuracy: 100.00%\nEpoch [30/50], Step [420/1305], Loss: 0.0436, Accuracy: 96.88%\nEpoch [30/50], Step [450/1305], Loss: 0.0204, Accuracy: 100.00%\nEpoch [30/50], Step [480/1305], Loss: 0.0094, Accuracy: 100.00%\nEpoch [30/50], Step [510/1305], Loss: 0.0219, Accuracy: 100.00%\nEpoch [30/50], Step [540/1305], Loss: 0.0061, Accuracy: 100.00%\nEpoch [30/50], Step [570/1305], Loss: 0.0258, Accuracy: 100.00%\nEpoch [30/50], Step [600/1305], Loss: 0.0149, Accuracy: 100.00%\nEpoch [30/50], Step [630/1305], Loss: 0.0151, Accuracy: 98.44%\nEpoch [30/50], Step [660/1305], Loss: 0.0031, Accuracy: 100.00%\nEpoch [30/50], Step [690/1305], Loss: 0.0106, Accuracy: 100.00%\nEpoch [30/50], Step [720/1305], Loss: 0.0398, Accuracy: 98.44%\nEpoch [30/50], Step [750/1305], Loss: 0.0086, Accuracy: 100.00%\nEpoch [30/50], Step [780/1305], Loss: 0.0761, Accuracy: 95.31%\nEpoch [30/50], Step [810/1305], Loss: 0.0634, Accuracy: 98.44%\nEpoch [30/50], Step [840/1305], Loss: 0.0074, Accuracy: 100.00%\nEpoch [30/50], Step [870/1305], Loss: 0.0152, Accuracy: 100.00%\nEpoch [30/50], Step [900/1305], Loss: 0.0337, Accuracy: 98.44%\nEpoch [30/50], Step [930/1305], Loss: 0.0259, Accuracy: 100.00%\nEpoch [30/50], Step [960/1305], Loss: 0.1304, Accuracy: 95.31%\nEpoch [30/50], Step [990/1305], Loss: 0.0057, Accuracy: 100.00%\nEpoch [30/50], Step [1020/1305], Loss: 0.0035, Accuracy: 100.00%\nEpoch [30/50], Step [1050/1305], Loss: 0.0009, Accuracy: 100.00%\nEpoch [30/50], Step [1080/1305], Loss: 0.0374, Accuracy: 100.00%\nEpoch [30/50], Step [1110/1305], Loss: 0.1019, Accuracy: 95.31%\nEpoch [30/50], Step [1140/1305], Loss: 0.0205, Accuracy: 100.00%\nEpoch [30/50], Step [1170/1305], Loss: 0.0187, Accuracy: 100.00%\nEpoch [30/50], Step [1200/1305], Loss: 0.0154, Accuracy: 100.00%\nEpoch [30/50], Step [1230/1305], Loss: 0.0244, Accuracy: 98.44%\nEpoch [30/50], Step [1260/1305], Loss: 0.0726, Accuracy: 96.88%\nEpoch [30/50], Step [1290/1305], Loss: 0.0214, Accuracy: 100.00%\nStart validation #30\nValidation #30  Accuracy: 96.88%  Average Loss: 0.0258\nBest epoch does not appear. Previous best epoch:0, A number of epochs remain until early stop: 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"in epoch: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9ef95f068304c5fab83a59c0ca96033"}},"metadata":{}},{"name":"stdout","text":"Epoch [31/50], Step [30/1305], Loss: 0.1090, Accuracy: 96.88%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minception_transfer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[14], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, model, data_loader, criterion, optimizer, scheduler, val_every, device, saved_dir, writer)\u001b[0m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Saving train loss\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m _, argmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (labels \u001b[38;5;241m==\u001b[39m argmax)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nX1 = np.linspace(0, num_epochs, 500)\nplt.subplot(1,2,1)\nplt.ylabel('Loss')\nplt.plot(X1, train_loss_list, label = 'Train')\nplt.plot(X1, val_loss_list, label = 'Validation')\nplt.subplot(1,2,2)\nplt.ylabel('Accuracy')\nX2 = np.linspace(1, num_epochs, num_epochs)\nplt.plot(X2, train_accuracy_list, label = 'Train')\nplt.plot(X2, val_accuracy_list, label = 'Validation')\n# plt.savefig('graph.png',facecolor = 'w')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zip all outcomes","metadata":{}},{"cell_type":"code","source":"import shutil\nshutil.make_archive('OUTPUT', 'zip', '/kaggle/working/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'OUTPUT.zip') # 여기에 zip파일 이름 넣기","metadata":{},"execution_count":null,"outputs":[]}]}